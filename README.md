# ICDE2025
Hello everyone! This is the implementation repository for the paper "A Compositional Approach to Generative Modeling of Network Paths." The repository mainly contains two folders, each corresponding to the two experimental scenarios described in the paper.

## Experiment1_path_on_urban_road_network
This section describes the first experiment, including the experimental setup, dataset, and experimental code.

### Experimental Environment  
Our method is implemented in Python and trained using an Nvidia A40 GPU. All experiments are run on the Ubuntu 20.04 operating system with an Intel Xeon Gold 6330 CPU.  

Python third-party dependency file: `Experiment1_path_on_urban_road_network/code/requirements.txt`

### Datasets
In the article, we conducted a comprehensive evaluation of our algorithm on two real-world datasets, which are from Shenzhen and Porto, respectively. Below is a brief description of the two datasets:

**Shenzhen**.   (Zhang et al. 2015)  released this dataset containing approximately 510k dense trajectories generated by  ~14k taxi cabs in Shenzhen, China, which can be downloaded at [https://people.cs.rutgers.edu/](https://people.cs.rutgers.edu/)˜dz220/Data.html.  

**Porto**. This dataset  describes trajectories performed by 442 taxis running in the city of Porto, Portugal l (Moreira-Matias et al. 2013) . Each taxi reports its location every 15s. This dataset is used for the  Trajectory Prediction Challenge@ ECML/PKDD 2015.

Due to space constraints and to facilitate easier replication of our work, we have included representative subsets of the two datasets in the Experiment1_path_on_urban_road_network.

<u>Data path:</u> /root/Experiment1_path_on_urban_road_network/datasets/raw_data_under_noise

### Experiment Code  
---

#### Preprocessing 
As described in Figure 3 of the article in Methodology - Vectorization and Linear Decoder, we convert the raw data into corresponding vectorized representations.  

<u>Data path:</u> /root/Experiment1_path_on_urban_road_network/datasets/Vectorized_data

<u>Input:</u> Raw data e.g.   `tra_datasetfutian5_5_3892_p0.npy`

<u>Output:</u> Vectorized file e.g. `T_tensortra_datasetfutian5_5_3892_p0.pth  `

<u>Code path</u>: `Experiment1_path_on_urban_road_network/code/generate_tensor.py` 

Example of usage:

```bash
python generate_tensor.py -n futian 
```

---

#### Model Training  
<u>Code path</u>: `Experiment1_path_on_urban_road_network/code/main.py`

Example of usage:

```bash
python main.py -n futian -p 0
```

---

#### Model Evaluation  
#### Numerical results (result of table1)  
The evaluation results of the proposed method will be directly output during the training process `Experiment1_path_on_urban_road_network/code/main.py`.  

#### Comparison Methods
1) GDP (Shi et al. 2024)  is a diffusion-based model for path planning and generation that learns path patterns while incorporating road network constraints, which can be considered the state-of-the-art method in road network trajectory generation. 

The code comes from the authors' repository: [https://github.com/dingyuan-shi/Graph-Diffusion-Planning](https://github.com/dingyuan-shi/Graph-Diffusion-Planning)  

<u>Code path</u>: Experiment1_path_on_urban_road_network/code/comparision_method/Graph-Diffusion-Planning-main

2) MTNet (Wang et al. 2022) is a deep generative model which employs a knowledge-based meta-learning module to learn generalized distribution patterns from skewed trajectory data.

The code is from the repository of the paper's authors: [https://github.com/wangyong01/MTNet_Code](https://github.com/wangyong01/MTNet_Code)  

<u>Code path</u>: Experiment1_path_on_urban_road_network/code/comparision_method/MTNet

3) Binary VAE. This basic binary version VAE is identical to the VAE component in our framework to ensure a fair comparison. It directly learns the distribution of vectorized trajectory data and generates datasets accordingly.

#### Denoising （Numerical result of figure 5）
<u>Code path</u>: Experiment1_path_on_urban_road_network/code/recover_fix_D.py 

Example of usage:

```bash
python recover_fix_D.py -n futian -p 0
```

## Experiment2_moe_path
This section describes the second experiment. 

### Experimental Environment  
Our method is implemented in Python and trained using an Nvidia A800 GPU. 

### Experiment setup

#### Dataset
1. Download the dataset from [MMLU-Pro](https://github.com/TIGER-AI-Lab/MMLU-Pro) and put it in the `Experiment2_moe_path/mmlu/code/TIGER-Lab/MMLU-Pro/data` (already included in the repository)
2. Download the dataset from [Infinity-Instruct](https://huggingface.co/datasets/BAAI/Infinity-Instruct), and preprocess the Infinity-Instruct dataset by running the following command:
```bash
python Experiment2_moe_path/Infinity-Instruct/code/get_data.py
```

#### Moe Mask
1. For MMLU-Pro, put the moe mask in: **Experiment2_moe_path/mmlu/phi_mask**
2. For Infinity-Instruct, put the moe mask in: **Experiment2_moe_path/Infinity-Instruct/phi_mask**

### Model
Download the model from [Phi-3.5-MoE-instruct](https://huggingface.co/microsoft/Phi-3.5-MoE-instruct) and put it in **Experiment2_moe_path/model**

### Run
1. For MMLU-Pro, run the following command:
```bash
bash Experiment2_moe_path/mmlu/code/eval_moe_phi_final_task1.sh
bash Experiment2_moe_path/mmlu/code/eval_moe_phi_final_task2.sh
```

**The result is in the `Experiment2_moe_path/mmlu/code/results` folder.**

2. For Infinity-Instruct, run the following command:
```bash
bash Experiment2_moe_path/Infinity-Instruct/code/eval_moe_phi_final_task1.sh
bash Experiment2_moe_path/Infinity-Instruct/code/eval_moe_phi_final_task2.sh
```

**The result is in the `Experiment2_moe_path/Infinity-Instruct/code/results` folder.**

### Result analysis
1. Run the code `Experiment2_moe_path/analysis_result.ipynb` to get the visual result.

The result is shown as follows:

![result](Experiment2_moe_path/comparison_plot_high_res.png)

![Task2](Experiment2_moe_path/performance_degradation_matrix.png)


# Reference
Zhang, Desheng, Juanjuan Zhao, Fan Zhang, and Tian He. “UrbanCPS: A Cyber-Physical System Based on Multi-Source Big Infrastructure Data for Heterogeneous Model Integration.” In _Proceedings of the ACM/IEEE Sixth International Conference on Cyber-Physical Systems_, 238–47. ICCPS ’15. New York, NY, USA: Association for Computing Machinery, 2015. [https://doi.org/10.1145/2735960.2735985](https://doi.org/10.1145/2735960.2735985).

Shi, Dingyuan, Yongxin Tong, Zimu Zhou, Ke Xu, Zheng Wang, and Jieping Ye. “GRAPH-CONSTRAINED DIFFUSION FOR END-TO-END PATH PLANNING,” 2024.

Wang, Yong, Guoliang Li, Kaiyu Li, and Haitao Yuan. “A Deep Generative Model for Trajectory Modeling and Utilization.” _Proceedings of the VLDB Endowment_ 16, no. 4 (December 2022): 973–85. [https://doi.org/10.14778/3574245.3574277](https://doi.org/10.14778/3574245.3574277).















