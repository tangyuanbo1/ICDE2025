{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-23 02:23:19,254\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "import argparse\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='2, 7'\n",
    "import torch\n",
    "import random\n",
    "import transformers\n",
    "import time\n",
    "import re\n",
    "from vllm import LLM, SamplingParams\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import sys\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "class args:\n",
    "    model = \"/data/naifanzhang/model/LLM-Research/Phi-3.5-MoE-instruct\"\n",
    "    gpu_util = 0.9\n",
    "    moe_path=\"/data/naifanzhang/exp/moe_drop/expert_cnt_class1_remove0.pth\"\n",
    "\n",
    "\n",
    "choices = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\"]\n",
    "max_model_length = 4096\n",
    "max_new_tokens = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1812333/2447363447.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(\"/data/naifanzhang/moe_purning/mmlu/phi_mask/final/computer_science_ours16_global.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"/data/naifanzhang/moe_purning/mmlu/phi_mask/final/computer_science_ours16_global.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"/data/naifanzhang/model/LLM-Research/Phi-3.5-MoE-instruct\"\n",
    "llm = LLM(model=model, gpu_memory_utilization=float(args.gpu_util),\n",
    "                tensor_parallel_size=torch.cuda.device_count(),\n",
    "                max_model_len=max_model_length,\n",
    "                trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = llm.llm_engine.model_executor.driver_worker.model_runner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型中共有 32 层包含block_sparse_moe\n"
     ]
    }
   ],
   "source": [
    "# 统计有多少层包含block_sparse_moe\n",
    "moe_layer_count = 0\n",
    "for layer in base_model.model.layers:\n",
    "    if hasattr(layer, 'block_sparse_moe'):\n",
    "        moe_layer_count += 1\n",
    "print(f\"模型中共有 {moe_layer_count} 层包含block_sparse_moe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2579352/170493118.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(args.moe_path).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(args.moe_path).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ont_mask = torch.ones([32,16])\n",
    "# 保存为pth文件\n",
    "torch.save(all_ont_mask, \"/data/naifanzhang/exp/moe_drop/all_one_mask_phi.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ont_mask = torch.zeros([32,16])\n",
    "all_ont_mask[:,0] = 1\n",
    "all_ont_mask[:,1] = 1\n",
    "# all_ont_mask[:,0] = 0\n",
    "# all_ont_mask[:,0] = 0\n",
    "# all_ont_mask[:,0] = 0\n",
    "torch.save(all_ont_mask, \"/data/naifanzhang/exp/moe_drop/all_one_mask_phi.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2634403/854855094.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(\"/data/naifanzhang/exp/moe_drop/all_one_mask_phi.pth\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"/data/naifanzhang/exp/moe_drop/all_one_mask_phi.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import MethodType\n",
    "from typing import Optional\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def new_forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "    # NOTE: hidden_states can have either 1D or 2D shape.\n",
    "    layer_expert_mask = getattr(self, 'current_expert_masks', None)\n",
    "    print(f\"layer_expert_mask is {layer_expert_mask}\")\n",
    "    orig_shape = hidden_states.shape\n",
    "    hidden_states = hidden_states.view(-1, self.hidden_size)\n",
    "    # router_logits: (num_tokens, n_experts)\n",
    "    router_logits, _ = self.gate(hidden_states)\n",
    "    print(f\"router_logits is {router_logits}\")\n",
    "    print(f\"router_logits shape is {router_logits.shape}\")\n",
    "    if layer_expert_mask is not None:\n",
    "        # 创建与router_logits相同shape的mask\n",
    "        expert_mask = torch.zeros_like(router_logits, dtype=torch.bool)\n",
    "        # 根据layer_expert_mask设置允许的专家\n",
    "        expert_mask[:, layer_expert_mask] = True\n",
    "        router_logits = router_logits.masked_fill(~expert_mask, float('-inf'))\n",
    "    print(f\"After mask router_logits is {router_logits}\")\n",
    "    print(f\"After mask router_logits shape is {router_logits.shape}\")\n",
    "\n",
    "    final_hidden_states = self.experts(hidden_states, router_logits)\n",
    "    return final_hidden_states.view(orig_shape)\n",
    "\n",
    "def forward_with_expert_masks(self, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        expert_masks: List[torch.Tensor]，每个元素对应一个MoE层的mask\n",
    "    \"\"\"\n",
    "    # 从LLM实例获取expert_masks\n",
    "    # 这里的self指代的是MixtralForCausalLM模型实例\n",
    "    # 因为forward_with_expert_masks方法是通过MethodType绑定到MixtralForCausalLM模型上的\n",
    "    # 可以通过打印self的类型来验证\n",
    "    print(f\"self type in forward_with_expert_masks is: {type(self)}\")\n",
    "    expert_masks = getattr(self, 'current_expert_masks', None)\n",
    "    print(f\"forward_with_expert_masks in self.current_expert_masks is {expert_masks}\")\n",
    "            \n",
    "    moe_layer_idx = 0\n",
    "    for idx, layer in enumerate(self.model.layers):\n",
    "        if hasattr(layer, 'block_sparse_moe'):\n",
    "            print(f\"layer type in forward_with_expert_masks is: {type(layer)}\")\n",
    "            # 为每个MoE层设置对应的expert_mask\n",
    "            layer.block_sparse_moe.current_expert_masks = expert_masks[moe_layer_idx] if expert_masks is not None else None\n",
    "            #print(f\"Moe block {idx} mask is: {layer.block_sparse_moe.current_expert_mask}\")\n",
    "            moe_layer_idx += 1\n",
    "    \n",
    "    outputs = self.original_forward(*args, **kwargs)\n",
    "    return outputs\n",
    "\n",
    "def modify_moe_layers(model):\n",
    "    if hasattr(model, 'model_runner'):\n",
    "        model.model_runner = model.model_runner\n",
    "    print(f\"--------------------------------\")\n",
    "    print(f\"In Moe Model Top current_expert_masks is {model.current_expert_masks}\")\n",
    "\n",
    "    # 修改每个MoE层\n",
    "    for layer in model.model.layers:\n",
    "        if hasattr(layer, 'block_sparse_moe'):\n",
    "            moe_layer = layer.block_sparse_moe\n",
    "            moe_layer.forward = MethodType(new_forward, moe_layer)\n",
    "    \n",
    "    model.original_forward = model.forward\n",
    "    model.forward = MethodType(forward_with_expert_masks, model)\n",
    "\n",
    "class ExpertMaskLLM(LLM):\n",
    "    \"\"\"扩展LLM类以支持expert masks\"\"\"\n",
    "    def __init__(self, expert_masks=None, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        #self.current_expert_masks = None\n",
    "        self.llm_engine.model_executor.driver_worker.model_runner.model.current_expert_masks = expert_masks\n",
    "        self.current_expert_masks = expert_masks\n",
    "        print(self.llm_engine.model_executor.driver_worker.model_runner.model)\n",
    "        modify_moe_layers(self.llm_engine.model_executor.driver_worker.model_runner.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_expert_masks(moe_path):\n",
    "    expert_mask= torch.load(moe_path)\n",
    "    num_layers = len(expert_mask)\n",
    "    expert_masks = []\n",
    "    for layer_idx in range(num_layers):\n",
    "        active_experts = torch.nonzero(expert_mask[layer_idx]).squeeze()\n",
    "        expert_masks.append(active_experts)\n",
    "    return expert_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2569301/3556500580.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  expert_mask= torch.load(moe_path)\n"
     ]
    }
   ],
   "source": [
    "expert_masks = load_expert_masks(args.moe_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_params = SamplingParams(temperature=0, max_tokens=max_new_tokens,\n",
    "                                    stop=[\"Question:\"])\n",
    "\n",
    "moe_path= \"/data/naifanzhang/exp/moe_drop/expert_cnt_class1_remove36.pth\"\n",
    "expert_mask= torch.load(moe_path)\n",
    "num_layers = len(expert_mask)\n",
    "expert_masks = []\n",
    "for layer_idx in range(num_layers):\n",
    "    active_experts = torch.nonzero(expert_mask[layer_idx]).squeeze()\n",
    "    expert_masks.append(active_experts)\n",
    "\n",
    "model=\"/data/naifanzhang/model/LLM-Research/Phi-3.5-MoE-instruct\"\n",
    "llm = ExpertMaskLLM(model=model, gpu_memory_utilization=float(args.gpu_util),\n",
    "                tensor_parallel_size=torch.cuda.device_count(),\n",
    "                max_model_len=max_model_length,\n",
    "                trust_remote_code=True,\n",
    "                expert_masks=expert_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-17 14:48:00 config.py:107] Replacing legacy 'type' key with 'rope_type'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-17 14:48:05 config.py:905] Defaulting to use mp for distributed inference\n",
      "INFO 11-17 14:48:05 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='/data/naifanzhang/model/LLM-Research/Phi-3.5-MoE-instruct', speculative_config=None, tokenizer='/data/naifanzhang/model/LLM-Research/Phi-3.5-MoE-instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/data/naifanzhang/model/LLM-Research/Phi-3.5-MoE-instruct, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "WARNING 11-17 14:48:06 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 56 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 11-17 14:48:06 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager\n",
      "INFO 11-17 14:48:06 selector.py:247] Cannot use FlashAttention-2 backend due to sliding window.\n",
      "INFO 11-17 14:48:06 selector.py:115] Using XFormers backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m INFO 11-17 14:48:06 selector.py:247] Cannot use FlashAttention-2 backend due to sliding window.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m INFO 11-17 14:48:06 selector.py:115] Using XFormers backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m /home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m   @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m /home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:211: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_fwd\")\n",
      "/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "  @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n",
      "/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:344: FutureWarning: `torch.library.impl_abstract` was renamed to `torch.library.register_fake`. Please use that instead; we will remove `torch.library.impl_abstract` in a future version of PyTorch.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m   @torch.library.impl_abstract(\"xformers_flash::flash_bwd\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m INFO 11-17 14:48:21 multiproc_worker_utils.py:215] Worker ready; awaiting tasks\n",
      "INFO 11-17 14:48:26 utils.py:1008] Found nccl from library libnccl.so.2\n",
      "INFO 11-17 14:48:26 pynccl.py:63] vLLM is using nccl==2.20.5\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m INFO 11-17 14:48:26 utils.py:1008] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m INFO 11-17 14:48:26 pynccl.py:63] vLLM is using nccl==2.20.5\n",
      "INFO 11-17 14:48:26 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /home/naifanzhang/.cache/vllm/gpu_p2p_access_cache_for_2, 4.json\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m INFO 11-17 14:48:26 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /home/naifanzhang/.cache/vllm/gpu_p2p_access_cache_for_2, 4.json\n",
      "INFO 11-17 14:48:26 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7546c27199c0>, local_subscribe_port=57259, remote_subscribe_port=None)\n",
      "INFO 11-17 14:48:26 model_runner.py:1056] Starting to load model /data/naifanzhang/model/LLM-Research/Phi-3.5-MoE-instruct...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m INFO 11-17 14:48:26 model_runner.py:1056] Starting to load model /data/naifanzhang/model/LLM-Research/Phi-3.5-MoE-instruct...\n",
      "INFO 11-17 14:48:27 selector.py:247] Cannot use FlashAttention-2 backend due to sliding window.\n",
      "INFO 11-17 14:48:27 selector.py:115] Using XFormers backend.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m INFO 11-17 14:48:27 selector.py:247] Cannot use FlashAttention-2 backend due to sliding window.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m INFO 11-17 14:48:27 selector.py:115] Using XFormers backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   0% Completed | 0/17 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229] Exception in worker VllmWorkerProcess while processing method load_model.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229] Traceback (most recent call last):\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/vllm/executor/multiproc_worker_utils.py\", line 223, in _run_worker_process\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     output = executor(*args, **kwargs)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/vllm/worker/worker.py\", line 183, in load_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     self.model_runner.load_model()\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/vllm/worker/model_runner.py\", line 1058, in load_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     self.model = get_model(model_config=self.model_config,\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/vllm/model_executor/model_loader/__init__.py\", line 19, in get_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     return loader.load_model(model_config=model_config,\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py\", line 398, in load_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     model = _initialize_model(model_config, self.load_config,\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py\", line 175, in _initialize_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     return build_model(\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/vllm/model_executor/model_loader/loader.py\", line 160, in build_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     return model_class(config=hf_config,\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/vllm/model_executor/models/phimoe.py\", line 546, in __init__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     self.model = PhiMoEModel(config,\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/vllm/model_executor/models/phimoe.py\", line 457, in __init__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     self.start_layer, self.end_layer, self.layers = make_layers(\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/vllm/model_executor/models/utils.py\", line 419, in make_layers\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     [PPMissingLayer() for _ in range(start_layer)] + [\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/vllm/model_executor/models/utils.py\", line 420, in <listcomp>\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     maybe_offload_to_cpu(layer_fn(prefix=f\"{prefix}.{idx}\"))\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/vllm/model_executor/models/phimoe.py\", line 459, in <lambda>\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     lambda prefix: PhiMoEDecoderLayer(config, cache_config,\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/vllm/model_executor/models/phimoe.py\", line 391, in __init__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     self.block_sparse_moe = PhiMoE(\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/vllm/model_executor/models/phimoe.py\", line 265, in __init__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     self.experts = FusedMoE(\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/vllm/model_executor/layers/fused_moe/layer.py\", line 215, in __init__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     self.quant_method.create_weights(\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/vllm/model_executor/layers/fused_moe/layer.py\", line 48, in create_weights\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     w13_weight = torch.nn.Parameter(torch.empty(num_experts,\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]   File \"/home/naifanzhang/.conda/envs/eedi/lib/python3.10/site-packages/torch/utils/_device.py\", line 79, in __torch_function__\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229]     return func(*args, **kwargs)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=2570813)\u001b[0;0m ERROR 11-17 14:48:27 multiproc_worker_utils.py:229] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 800.00 MiB. GPU 1 has a total capacity of 79.15 GiB of which 664.12 MiB is free. Process 2419576 has 75.16 GiB memory in use. Including non-PyTorch memory, this process has 3.31 GiB memory in use. Of the allocated memory 2.67 GiB is allocated by PyTorch, and 31.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading safetensors checkpoint shards:   6% Completed | 1/17 [00:00<00:13,  1.17it/s]\n",
      "Loading safetensors checkpoint shards:  12% Completed | 2/17 [00:01<00:12,  1.20it/s]\n",
      "Loading safetensors checkpoint shards:  18% Completed | 3/17 [00:02<00:12,  1.16it/s]\n",
      "Loading safetensors checkpoint shards:  24% Completed | 4/17 [00:03<00:11,  1.14it/s]\n",
      "Loading safetensors checkpoint shards:  29% Completed | 5/17 [00:04<00:09,  1.21it/s]\n",
      "Loading safetensors checkpoint shards:  35% Completed | 6/17 [00:05<00:09,  1.16it/s]\n",
      "Loading safetensors checkpoint shards:  41% Completed | 7/17 [00:06<00:08,  1.14it/s]\n",
      "Loading safetensors checkpoint shards:  47% Completed | 8/17 [00:06<00:07,  1.18it/s]\n",
      "Loading safetensors checkpoint shards:  53% Completed | 9/17 [00:07<00:07,  1.14it/s]\n",
      "Loading safetensors checkpoint shards:  59% Completed | 10/17 [00:08<00:06,  1.08it/s]\n",
      "Loading safetensors checkpoint shards:  65% Completed | 11/17 [00:09<00:05,  1.06it/s]\n",
      "Loading safetensors checkpoint shards:  71% Completed | 12/17 [00:10<00:04,  1.01it/s]\n",
      "Loading safetensors checkpoint shards:  76% Completed | 13/17 [00:11<00:03,  1.02it/s]\n",
      "Loading safetensors checkpoint shards:  82% Completed | 14/17 [00:12<00:02,  1.03it/s]\n",
      "Loading safetensors checkpoint shards:  88% Completed | 15/17 [00:13<00:01,  1.07it/s]\n",
      "Loading safetensors checkpoint shards:  94% Completed | 16/17 [00:14<00:00,  1.11it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 17/17 [00:15<00:00,  1.08it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 17/17 [00:15<00:00,  1.10it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-17 14:48:43 model_runner.py:1067] Loading model weights took 39.0659 GB\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 800.00 MiB. GPU 1 has a total capacity of 79.15 GiB of which 664.12 MiB is free. Process 2419576 has 75.16 GiB memory in use. Including non-PyTorch memory, this process has 3.31 GiB memory in use. Of the allocated memory 2.67 GiB is allocated by PyTorch, and 31.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/data/naifanzhang/model/LLM-Research/Phi-3.5-MoE-instruct\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m llm \u001b[38;5;241m=\u001b[39m \u001b[43mExpertMaskLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpu_util\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtensor_parallel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mmax_model_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_model_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43mexpert_masks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpert_masks\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 70\u001b[0m, in \u001b[0;36mExpertMaskLLM.__init__\u001b[0;34m(self, expert_masks, *args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, expert_masks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m#self.current_expert_masks = None\u001b[39;00m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine\u001b[38;5;241m.\u001b[39mmodel_executor\u001b[38;5;241m.\u001b[39mdriver_worker\u001b[38;5;241m.\u001b[39mmodel_runner\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mcurrent_expert_masks \u001b[38;5;241m=\u001b[39m expert_masks\n",
      "File \u001b[0;32m~/.conda/envs/eedi/lib/python3.10/site-packages/vllm/entrypoints/llm.py:177\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_context_len_to_capture, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, mm_processor_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable_log_stats\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    154\u001b[0m engine_args \u001b[38;5;241m=\u001b[39m EngineArgs(\n\u001b[1;32m    155\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    156\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    176\u001b[0m )\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mLLMEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUsageContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_counter \u001b[38;5;241m=\u001b[39m Counter()\n",
      "File \u001b[0;32m~/.conda/envs/eedi/lib/python3.10/site-packages/vllm/engine/llm_engine.py:573\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args, usage_context, stat_loggers)\u001b[0m\n\u001b[1;32m    571\u001b[0m executor_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_executor_cls(engine_config)\n\u001b[1;32m    572\u001b[0m \u001b[38;5;66;03m# Create the LLM engine.\u001b[39;00m\n\u001b[0;32m--> 573\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
      "File \u001b[0;32m~/.conda/envs/eedi/lib/python3.10/site-packages/vllm/engine/llm_engine.py:334\u001b[0m, in \u001b[0;36mLLMEngine.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, speculative_config, decoding_config, observability_config, prompt_adapter_config, executor_class, log_stats, usage_context, stat_loggers, input_registry, use_cached_outputs)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_registry \u001b[38;5;241m=\u001b[39m input_registry\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_processor \u001b[38;5;241m=\u001b[39m input_registry\u001b[38;5;241m.\u001b[39mcreate_input_processor(\n\u001b[1;32m    332\u001b[0m     model_config)\n\u001b[0;32m--> 334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_executor \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeculative_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeculative_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_adapter_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_adapter_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobservability_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservability_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39membedding_mode:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_kv_caches()\n",
      "File \u001b[0;32m~/.conda/envs/eedi/lib/python3.10/site-packages/vllm/executor/distributed_gpu_executor.py:26\u001b[0m, in \u001b[0;36mDistributedGPUExecutor.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Updated by implementations that require additional args to be passed\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# to the _run_workers execute_model call\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_execute_model_run_workers_kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/eedi/lib/python3.10/site-packages/vllm/executor/executor_base.py:47\u001b[0m, in \u001b[0;36mExecutorBase.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, speculative_config, prompt_adapter_config, observability_config)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_adapter_config \u001b[38;5;241m=\u001b[39m prompt_adapter_config\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;241m=\u001b[39m observability_config\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/eedi/lib/python3.10/site-packages/vllm/executor/multiproc_gpu_executor.py:111\u001b[0m, in \u001b[0;36mMultiprocessingGPUExecutor._init_executor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_worker(\n\u001b[1;32m    109\u001b[0m     distributed_init_method\u001b[38;5;241m=\u001b[39mdistributed_init_method)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_workers(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_device\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mload_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmax_concurrent_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\n\u001b[1;32m    113\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmax_parallel_loading_workers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/eedi/lib/python3.10/site-packages/vllm/executor/multiproc_gpu_executor.py:196\u001b[0m, in \u001b[0;36mMultiprocessingGPUExecutor._run_workers\u001b[0;34m(self, method, async_run_tensor_parallel_workers_only, max_concurrent_workers, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m driver_worker_output \u001b[38;5;241m=\u001b[39m driver_worker_method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Get the results of the workers.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [driver_worker_output\n\u001b[0;32m--> 196\u001b[0m         ] \u001b[38;5;241m+\u001b[39m [output\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m worker_outputs]\n",
      "File \u001b[0;32m~/.conda/envs/eedi/lib/python3.10/site-packages/vllm/executor/multiproc_gpu_executor.py:196\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    192\u001b[0m driver_worker_output \u001b[38;5;241m=\u001b[39m driver_worker_method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Get the results of the workers.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [driver_worker_output\n\u001b[0;32m--> 196\u001b[0m         ] \u001b[38;5;241m+\u001b[39m [\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m worker_outputs]\n",
      "File \u001b[0;32m~/.conda/envs/eedi/lib/python3.10/site-packages/vllm/executor/multiproc_worker_utils.py:54\u001b[0m, in \u001b[0;36mResultFuture.get\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mexception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mexception\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 800.00 MiB. GPU 1 has a total capacity of 79.15 GiB of which 664.12 MiB is free. Process 2419576 has 75.16 GiB memory in use. Including non-PyTorch memory, this process has 3.31 GiB memory in use. Of the allocated memory 2.67 GiB is allocated by PyTorch, and 31.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "model=\"/data/naifanzhang/model/LLM-Research/Phi-3.5-MoE-instruct\"\n",
    "llm = ExpertMaskLLM(model=model, gpu_memory_utilization=float(args.gpu_util),\n",
    "                tensor_parallel_size=torch.cuda.device_count(),\n",
    "                max_model_len=max_model_length,\n",
    "                trust_remote_code=True,\n",
    "                expert_masks=expert_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralForCausalLM'>\n",
      "forward_with_expert_masks in self.current_expert_masks is [tensor([0, 1, 2, 3, 4]), tensor([1, 5, 6, 7]), tensor([1, 2, 3, 4, 6, 7]), tensor([1, 3, 4, 5, 6, 7]), tensor([0, 1, 4, 6, 7]), tensor([0, 1, 3, 4, 5, 7]), tensor([1, 5, 6, 7]), tensor([2, 3, 4, 6]), tensor([0, 1, 2, 5, 6]), tensor([1, 2, 5, 6, 7]), tensor([0, 1, 2, 3, 4, 5]), tensor([0, 1, 4, 5, 6]), tensor([2, 3, 4, 5, 6]), tensor([1, 4, 5, 6, 7]), tensor([0, 1, 3, 5, 6]), tensor([0, 4, 5, 6, 7]), tensor([1, 2, 3, 4, 5]), tensor([0, 1, 3, 4, 5, 7]), tensor([0, 2, 3, 4, 5]), tensor([2, 4, 5, 7]), tensor([0, 2, 5, 7]), tensor([1, 3, 5, 6, 7]), tensor([0, 3, 5, 6, 7]), tensor([4, 5, 6, 7]), tensor([0, 1, 3, 4, 5, 6]), tensor([0, 1, 4, 5]), tensor([1, 2, 3, 4, 5, 7]), tensor([0, 1, 2, 5, 7]), tensor([1, 3, 4, 5, 7]), tensor([0, 1, 2, 4, 5, 6, 7]), tensor([0, 1, 2, 5, 6, 7]), tensor([0, 1, 2, 3, 4])]\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer type in forward_with_expert_masks is: <class 'vllm.model_executor.models.mixtral.MixtralDecoderLayer'>\n",
      "layer_expert_mask is tensor([0, 1, 2, 3, 4])\n",
      "router_logits is tensor([[-0.2285,  0.9180, -0.0889, -0.0496, -0.3535,  0.3223, -0.0713, -0.1631],\n",
      "        [-0.4062, -1.2344,  0.7227,  1.1406, -0.2910,  0.3223,  0.6719, -0.2539],\n",
      "        [-0.3145, -0.5859,  2.5000, -0.8984, -0.9336, -0.0942, -0.2520,  0.6055],\n",
      "        [-0.7422, -1.5000, -0.3789, -0.6797,  0.7266,  0.7539,  2.9844, -0.3418],\n",
      "        [-1.1484, -0.6797,  2.0625,  0.3047, -0.1494, -0.1021,  0.0291, -0.3926],\n",
      "        [-0.2988,  1.0391,  0.5938, -0.5312, -0.7812,  1.0234, -0.5625, -0.1992],\n",
      "        [-0.1562, -0.7969,  0.4434, -0.0535, -0.4375, -0.1099, -0.5234,  1.2344],\n",
      "        [ 1.5547,  1.4219, -1.0938, -0.5703, -0.4395, -1.0469, -0.4961,  0.6836],\n",
      "        [-0.2285,  0.9180, -0.0889, -0.0496, -0.3535,  0.3223, -0.0713, -0.1631],\n",
      "        [-0.4062, -1.2344,  0.7227,  1.1406, -0.2910,  0.3223,  0.6719, -0.2539],\n",
      "        [-0.3145, -0.5859,  2.5000, -0.8984, -0.9336, -0.0942, -0.2520,  0.6055],\n",
      "        [-0.7422, -1.5000, -0.3789, -0.6797,  0.7266,  0.7539,  2.9844, -0.3418],\n",
      "        [-1.1484, -0.6797,  2.0625,  0.3047, -0.1494, -0.1021,  0.0291, -0.3926],\n",
      "        [-0.2988,  1.0391,  0.5938, -0.5312, -0.7812,  1.0234, -0.5625, -0.1992],\n",
      "        [ 0.3887, -1.1562,  0.2246, -0.1943, -0.4434, -0.0552, -0.5938,  1.5078],\n",
      "        [ 1.6875,  1.6641, -1.1953, -0.6758, -0.4688, -1.1406, -0.7148,  0.8320]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[-0.2285,  0.9180, -0.0889, -0.0496, -0.3535,    -inf,    -inf,    -inf],\n",
      "        [-0.4062, -1.2344,  0.7227,  1.1406, -0.2910,    -inf,    -inf,    -inf],\n",
      "        [-0.3145, -0.5859,  2.5000, -0.8984, -0.9336,    -inf,    -inf,    -inf],\n",
      "        [-0.7422, -1.5000, -0.3789, -0.6797,  0.7266,    -inf,    -inf,    -inf],\n",
      "        [-1.1484, -0.6797,  2.0625,  0.3047, -0.1494,    -inf,    -inf,    -inf],\n",
      "        [-0.2988,  1.0391,  0.5938, -0.5312, -0.7812,    -inf,    -inf,    -inf],\n",
      "        [-0.1562, -0.7969,  0.4434, -0.0535, -0.4375,    -inf,    -inf,    -inf],\n",
      "        [ 1.5547,  1.4219, -1.0938, -0.5703, -0.4395,    -inf,    -inf,    -inf],\n",
      "        [-0.2285,  0.9180, -0.0889, -0.0496, -0.3535,    -inf,    -inf,    -inf],\n",
      "        [-0.4062, -1.2344,  0.7227,  1.1406, -0.2910,    -inf,    -inf,    -inf],\n",
      "        [-0.3145, -0.5859,  2.5000, -0.8984, -0.9336,    -inf,    -inf,    -inf],\n",
      "        [-0.7422, -1.5000, -0.3789, -0.6797,  0.7266,    -inf,    -inf,    -inf],\n",
      "        [-1.1484, -0.6797,  2.0625,  0.3047, -0.1494,    -inf,    -inf,    -inf],\n",
      "        [-0.2988,  1.0391,  0.5938, -0.5312, -0.7812,    -inf,    -inf,    -inf],\n",
      "        [ 0.3887, -1.1562,  0.2246, -0.1943, -0.4434,    -inf,    -inf,    -inf],\n",
      "        [ 1.6875,  1.6641, -1.1953, -0.6758, -0.4688,    -inf,    -inf,    -inf]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([1, 5, 6, 7])\n",
      "router_logits is tensor([[-1.1953e+00, -1.0078e+00, -1.2891e+00,  3.3438e+00,  6.7871e-02,\n",
      "         -8.8672e-01, -1.0234e+00, -1.4141e+00],\n",
      "        [ 6.3672e-01, -9.6094e-01,  8.5547e-01,  2.5977e-01, -1.0156e+00,\n",
      "          3.4570e-01,  8.6719e-01, -9.3750e-02],\n",
      "        [-9.0234e-01, -1.5703e+00,  3.9453e-01,  5.2734e-01, -7.5000e-01,\n",
      "          2.0156e+00, -2.3438e-01,  1.1484e+00],\n",
      "        [-6.0156e-01, -2.1250e+00,  9.2969e-01,  6.9922e-01, -1.1094e+00,\n",
      "         -1.4922e+00,  2.6562e+00,  1.7891e+00],\n",
      "        [-5.6641e-01,  5.0391e-01,  1.4688e+00, -2.0312e-01,  2.1973e-03,\n",
      "         -4.9609e-01, -6.7188e-01, -1.4746e-01],\n",
      "        [ 6.7188e-01,  3.0273e-01,  9.5215e-02, -3.0029e-02, -2.4902e-01,\n",
      "         -9.6094e-01,  3.5938e-01, -2.4292e-02],\n",
      "        [-3.8086e-01, -9.5312e-01,  2.7148e-01,  1.6992e-01, -4.1016e-01,\n",
      "          1.1719e+00, -1.0986e-01,  4.6484e-01],\n",
      "        [ 1.7969e+00, -2.3926e-01, -9.4238e-02, -1.0010e-02, -1.6406e-01,\n",
      "         -1.0078e+00,  8.3984e-01, -8.2812e-01],\n",
      "        [-1.1953e+00, -1.0078e+00, -1.2891e+00,  3.3438e+00,  6.7871e-02,\n",
      "         -8.8672e-01, -1.0234e+00, -1.4141e+00],\n",
      "        [ 6.3672e-01, -9.6094e-01,  8.5547e-01,  2.5977e-01, -1.0156e+00,\n",
      "          3.4570e-01,  8.6719e-01, -9.3750e-02],\n",
      "        [-9.0234e-01, -1.5703e+00,  3.9453e-01,  5.2734e-01, -7.5000e-01,\n",
      "          2.0156e+00, -2.3438e-01,  1.1484e+00],\n",
      "        [-6.0156e-01, -2.1250e+00,  9.2969e-01,  6.9922e-01, -1.1094e+00,\n",
      "         -1.4922e+00,  2.6562e+00,  1.7891e+00],\n",
      "        [-5.6641e-01,  5.0391e-01,  1.4688e+00, -2.0312e-01,  2.1973e-03,\n",
      "         -4.9609e-01, -6.7188e-01, -1.4746e-01],\n",
      "        [ 6.7188e-01,  3.0273e-01,  9.5215e-02, -3.0029e-02, -2.4902e-01,\n",
      "         -9.6094e-01,  3.5938e-01, -2.4292e-02],\n",
      "        [-1.2793e-01, -8.3594e-01,  6.6406e-02, -5.9082e-02, -4.4727e-01,\n",
      "          1.1016e+00,  1.8164e-01,  4.4336e-01],\n",
      "        [ 1.6562e+00, -2.7539e-01, -5.0781e-02, -8.4229e-03, -1.8750e-01,\n",
      "         -1.0234e+00,  1.0625e+00, -8.2812e-01]], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[   -inf, -1.0078,    -inf,    -inf,    -inf, -0.8867, -1.0234, -1.4141],\n",
      "        [   -inf, -0.9609,    -inf,    -inf,    -inf,  0.3457,  0.8672, -0.0938],\n",
      "        [   -inf, -1.5703,    -inf,    -inf,    -inf,  2.0156, -0.2344,  1.1484],\n",
      "        [   -inf, -2.1250,    -inf,    -inf,    -inf, -1.4922,  2.6562,  1.7891],\n",
      "        [   -inf,  0.5039,    -inf,    -inf,    -inf, -0.4961, -0.6719, -0.1475],\n",
      "        [   -inf,  0.3027,    -inf,    -inf,    -inf, -0.9609,  0.3594, -0.0243],\n",
      "        [   -inf, -0.9531,    -inf,    -inf,    -inf,  1.1719, -0.1099,  0.4648],\n",
      "        [   -inf, -0.2393,    -inf,    -inf,    -inf, -1.0078,  0.8398, -0.8281],\n",
      "        [   -inf, -1.0078,    -inf,    -inf,    -inf, -0.8867, -1.0234, -1.4141],\n",
      "        [   -inf, -0.9609,    -inf,    -inf,    -inf,  0.3457,  0.8672, -0.0938],\n",
      "        [   -inf, -1.5703,    -inf,    -inf,    -inf,  2.0156, -0.2344,  1.1484],\n",
      "        [   -inf, -2.1250,    -inf,    -inf,    -inf, -1.4922,  2.6562,  1.7891],\n",
      "        [   -inf,  0.5039,    -inf,    -inf,    -inf, -0.4961, -0.6719, -0.1475],\n",
      "        [   -inf,  0.3027,    -inf,    -inf,    -inf, -0.9609,  0.3594, -0.0243],\n",
      "        [   -inf, -0.8359,    -inf,    -inf,    -inf,  1.1016,  0.1816,  0.4434],\n",
      "        [   -inf, -0.2754,    -inf,    -inf,    -inf, -1.0234,  1.0625, -0.8281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([1, 2, 3, 4, 6, 7])\n",
      "router_logits is tensor([[-0.0198,  0.0211, -0.1680, -0.0249,  0.0603, -0.0161, -0.0247,  0.0579],\n",
      "        [-0.6914,  0.2051,  0.8906,  1.0391,  0.4102, -0.4648, -0.4648, -1.0156],\n",
      "        [-0.3555, -1.1719, -0.2676,  0.8477, -0.6602,  0.1045,  2.2656, -0.3418],\n",
      "        [ 2.2188,  0.2910, -1.2891, -0.8203, -0.8477,  1.0781, -0.4512,  0.1299],\n",
      "        [-0.5156,  1.8438, -0.9922, -0.3809,  0.8398, -0.4668, -1.0469,  0.5586],\n",
      "        [-0.2002, -0.5430,  1.4297, -0.1738, -1.3750,  0.5469, -0.0352,  0.7734],\n",
      "        [ 2.0781, -0.5703,  0.0615,  0.0757, -0.2852,  0.7031, -1.2109, -0.9492],\n",
      "        [ 0.6094, -0.8281, -0.6484,  0.0145,  1.0859, -0.3652,  0.0889,  0.4922],\n",
      "        [-0.0198,  0.0211, -0.1680, -0.0249,  0.0603, -0.0161, -0.0247,  0.0579],\n",
      "        [-0.6914,  0.2051,  0.8906,  1.0391,  0.4102, -0.4648, -0.4648, -1.0156],\n",
      "        [-0.3555, -1.1719, -0.2676,  0.8477, -0.6602,  0.1045,  2.2656, -0.3418],\n",
      "        [ 2.2188,  0.2910, -1.2891, -0.8203, -0.8477,  1.0781, -0.4512,  0.1299],\n",
      "        [-0.5156,  1.8438, -0.9922, -0.3809,  0.8398, -0.4668, -1.0469,  0.5586],\n",
      "        [-0.2002, -0.5430,  1.4297, -0.1738, -1.3750,  0.5469, -0.0352,  0.7734],\n",
      "        [ 2.4688, -0.6211, -0.6914, -0.5820,  0.0850,  1.3750, -1.2578, -0.6719],\n",
      "        [ 0.7383, -0.6211, -0.7031, -0.1680,  1.1797, -0.3926, -0.1777,  0.5273]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[   -inf,  0.0211, -0.1680, -0.0249,  0.0603,    -inf, -0.0247,  0.0579],\n",
      "        [   -inf,  0.2051,  0.8906,  1.0391,  0.4102,    -inf, -0.4648, -1.0156],\n",
      "        [   -inf, -1.1719, -0.2676,  0.8477, -0.6602,    -inf,  2.2656, -0.3418],\n",
      "        [   -inf,  0.2910, -1.2891, -0.8203, -0.8477,    -inf, -0.4512,  0.1299],\n",
      "        [   -inf,  1.8438, -0.9922, -0.3809,  0.8398,    -inf, -1.0469,  0.5586],\n",
      "        [   -inf, -0.5430,  1.4297, -0.1738, -1.3750,    -inf, -0.0352,  0.7734],\n",
      "        [   -inf, -0.5703,  0.0615,  0.0757, -0.2852,    -inf, -1.2109, -0.9492],\n",
      "        [   -inf, -0.8281, -0.6484,  0.0145,  1.0859,    -inf,  0.0889,  0.4922],\n",
      "        [   -inf,  0.0211, -0.1680, -0.0249,  0.0603,    -inf, -0.0247,  0.0579],\n",
      "        [   -inf,  0.2051,  0.8906,  1.0391,  0.4102,    -inf, -0.4648, -1.0156],\n",
      "        [   -inf, -1.1719, -0.2676,  0.8477, -0.6602,    -inf,  2.2656, -0.3418],\n",
      "        [   -inf,  0.2910, -1.2891, -0.8203, -0.8477,    -inf, -0.4512,  0.1299],\n",
      "        [   -inf,  1.8438, -0.9922, -0.3809,  0.8398,    -inf, -1.0469,  0.5586],\n",
      "        [   -inf, -0.5430,  1.4297, -0.1738, -1.3750,    -inf, -0.0352,  0.7734],\n",
      "        [   -inf, -0.6211, -0.6914, -0.5820,  0.0850,    -inf, -1.2578, -0.6719],\n",
      "        [   -inf, -0.6211, -0.7031, -0.1680,  1.1797,    -inf, -0.1777,  0.5273]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([1, 3, 4, 5, 6, 7])\n",
      "router_logits is tensor([[-0.0898,  0.1445, -0.0557, -0.0408, -0.0854, -0.1436,  0.0630,  0.0214],\n",
      "        [ 0.0123, -1.0234, -1.1094,  2.0156, -0.8164,  1.6094, -0.8867,  0.4863],\n",
      "        [ 1.9922,  1.3828, -1.2734,  0.3613, -0.6523, -0.6484, -0.5898, -0.6680],\n",
      "        [ 0.0261,  1.6484, -1.8516, -0.2451, -0.7344, -1.0078,  0.6094,  1.4922],\n",
      "        [ 0.2275,  0.3477,  0.7188,  0.0430, -0.1523, -1.4219, -0.6562,  1.0000],\n",
      "        [-0.3926, -0.2734, -0.4570,  0.9766,  1.9766, -1.5781, -0.4258,  0.4512],\n",
      "        [ 0.1719, -1.6641,  0.3926,  0.5117,  0.1235, -1.3906,  2.2031, -0.2148],\n",
      "        [ 0.6602, -1.1953, -0.4023,  1.9141,  0.8516, -0.3867, -0.4473, -0.6367],\n",
      "        [-0.0898,  0.1445, -0.0557, -0.0408, -0.0854, -0.1436,  0.0630,  0.0214],\n",
      "        [ 0.0123, -1.0234, -1.1094,  2.0156, -0.8164,  1.6094, -0.8867,  0.4863],\n",
      "        [ 1.9922,  1.3828, -1.2734,  0.3613, -0.6523, -0.6484, -0.5898, -0.6680],\n",
      "        [ 0.0261,  1.6484, -1.8516, -0.2451, -0.7344, -1.0078,  0.6094,  1.4922],\n",
      "        [ 0.2275,  0.3477,  0.7188,  0.0430, -0.1523, -1.4219, -0.6562,  1.0000],\n",
      "        [-0.3926, -0.2734, -0.4570,  0.9766,  1.9766, -1.5781, -0.4258,  0.4512],\n",
      "        [ 0.4121, -0.7383, -0.2578, -0.3379, -0.2080, -0.9062,  1.3672,  0.6250],\n",
      "        [ 0.7383, -1.2969, -0.4668,  1.8906,  0.8945, -0.4141, -0.2656, -0.7539]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[   -inf,  0.1445,    -inf, -0.0408, -0.0854, -0.1436,  0.0630,  0.0214],\n",
      "        [   -inf, -1.0234,    -inf,  2.0156, -0.8164,  1.6094, -0.8867,  0.4863],\n",
      "        [   -inf,  1.3828,    -inf,  0.3613, -0.6523, -0.6484, -0.5898, -0.6680],\n",
      "        [   -inf,  1.6484,    -inf, -0.2451, -0.7344, -1.0078,  0.6094,  1.4922],\n",
      "        [   -inf,  0.3477,    -inf,  0.0430, -0.1523, -1.4219, -0.6562,  1.0000],\n",
      "        [   -inf, -0.2734,    -inf,  0.9766,  1.9766, -1.5781, -0.4258,  0.4512],\n",
      "        [   -inf, -1.6641,    -inf,  0.5117,  0.1235, -1.3906,  2.2031, -0.2148],\n",
      "        [   -inf, -1.1953,    -inf,  1.9141,  0.8516, -0.3867, -0.4473, -0.6367],\n",
      "        [   -inf,  0.1445,    -inf, -0.0408, -0.0854, -0.1436,  0.0630,  0.0214],\n",
      "        [   -inf, -1.0234,    -inf,  2.0156, -0.8164,  1.6094, -0.8867,  0.4863],\n",
      "        [   -inf,  1.3828,    -inf,  0.3613, -0.6523, -0.6484, -0.5898, -0.6680],\n",
      "        [   -inf,  1.6484,    -inf, -0.2451, -0.7344, -1.0078,  0.6094,  1.4922],\n",
      "        [   -inf,  0.3477,    -inf,  0.0430, -0.1523, -1.4219, -0.6562,  1.0000],\n",
      "        [   -inf, -0.2734,    -inf,  0.9766,  1.9766, -1.5781, -0.4258,  0.4512],\n",
      "        [   -inf, -0.7383,    -inf, -0.3379, -0.2080, -0.9062,  1.3672,  0.6250],\n",
      "        [   -inf, -1.2969,    -inf,  1.8906,  0.8945, -0.4141, -0.2656, -0.7539]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 1, 4, 6, 7])\n",
      "router_logits is tensor([[ 0.0170, -0.1318, -0.0481,  0.0708, -0.1924, -0.0781, -0.0588,  0.0859],\n",
      "        [ 1.0859, -0.2422, -0.2158, -0.1748, -0.3809, -0.3574,  0.1787,  0.4004],\n",
      "        [ 2.2344, -0.4727, -0.0732, -0.9727, -0.2793, -0.3125,  0.0388, -0.0277],\n",
      "        [ 0.3652, -0.2793, -0.7656,  1.3047, -0.3828, -0.1235,  0.7812, -0.8008],\n",
      "        [-0.5312, -0.7812, -0.3105,  0.0371,  2.3125, -0.0679, -0.4395, -0.3906],\n",
      "        [-0.3320, -1.6484,  0.0664,  0.2598,  0.4805, -0.6172, -0.6328,  2.2344],\n",
      "        [-0.7305,  1.6797, -0.2490, -0.7539,  1.3047, -0.7305, -0.7969,  0.2773],\n",
      "        [ 0.2461,  0.7578, -0.2734, -0.9219, -0.2773,  1.9375, -0.8086, -0.4766],\n",
      "        [ 0.0170, -0.1318, -0.0481,  0.0708, -0.1924, -0.0781, -0.0588,  0.0859],\n",
      "        [ 1.0859, -0.2422, -0.2158, -0.1748, -0.3809, -0.3574,  0.1787,  0.4004],\n",
      "        [ 2.2344, -0.4727, -0.0732, -0.9727, -0.2793, -0.3125,  0.0388, -0.0277],\n",
      "        [ 0.3652, -0.2793, -0.7656,  1.3047, -0.3828, -0.1235,  0.7812, -0.8008],\n",
      "        [-0.5312, -0.7812, -0.3105,  0.0371,  2.3125, -0.0679, -0.4395, -0.3906],\n",
      "        [-0.3320, -1.6484,  0.0664,  0.2598,  0.4805, -0.6172, -0.6328,  2.2344],\n",
      "        [-0.4707,  1.1562, -0.5078, -0.6367,  1.6328, -0.7227, -0.9297,  0.3047],\n",
      "        [ 0.3301,  0.6836, -0.2246, -0.9297, -0.3340,  1.7344, -0.8281, -0.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[ 0.0170, -0.1318,    -inf,    -inf, -0.1924,    -inf, -0.0588,  0.0859],\n",
      "        [ 1.0859, -0.2422,    -inf,    -inf, -0.3809,    -inf,  0.1787,  0.4004],\n",
      "        [ 2.2344, -0.4727,    -inf,    -inf, -0.2793,    -inf,  0.0388, -0.0277],\n",
      "        [ 0.3652, -0.2793,    -inf,    -inf, -0.3828,    -inf,  0.7812, -0.8008],\n",
      "        [-0.5312, -0.7812,    -inf,    -inf,  2.3125,    -inf, -0.4395, -0.3906],\n",
      "        [-0.3320, -1.6484,    -inf,    -inf,  0.4805,    -inf, -0.6328,  2.2344],\n",
      "        [-0.7305,  1.6797,    -inf,    -inf,  1.3047,    -inf, -0.7969,  0.2773],\n",
      "        [ 0.2461,  0.7578,    -inf,    -inf, -0.2773,    -inf, -0.8086, -0.4766],\n",
      "        [ 0.0170, -0.1318,    -inf,    -inf, -0.1924,    -inf, -0.0588,  0.0859],\n",
      "        [ 1.0859, -0.2422,    -inf,    -inf, -0.3809,    -inf,  0.1787,  0.4004],\n",
      "        [ 2.2344, -0.4727,    -inf,    -inf, -0.2793,    -inf,  0.0388, -0.0277],\n",
      "        [ 0.3652, -0.2793,    -inf,    -inf, -0.3828,    -inf,  0.7812, -0.8008],\n",
      "        [-0.5312, -0.7812,    -inf,    -inf,  2.3125,    -inf, -0.4395, -0.3906],\n",
      "        [-0.3320, -1.6484,    -inf,    -inf,  0.4805,    -inf, -0.6328,  2.2344],\n",
      "        [-0.4707,  1.1562,    -inf,    -inf,  1.6328,    -inf, -0.9297,  0.3047],\n",
      "        [ 0.3301,  0.6836,    -inf,    -inf, -0.3340,    -inf, -0.8281, -0.2812]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 1, 3, 4, 5, 7])\n",
      "router_logits is tensor([[-2.2852e-01, -1.2793e-01, -1.7383e-01, -1.2085e-02, -8.3496e-02,\n",
      "         -5.7983e-04, -2.3535e-01,  4.1962e-04],\n",
      "        [-2.3340e-01,  4.3164e-01, -2.9297e-01, -3.9258e-01,  6.9141e-01,\n",
      "         -4.0820e-01,  8.1641e-01, -4.0283e-02],\n",
      "        [ 1.9688e+00, -8.5938e-01, -3.9648e-01, -1.1250e+00,  4.4922e-01,\n",
      "          3.2471e-02,  8.7109e-01, -5.9375e-01],\n",
      "        [ 9.0332e-03, -7.9688e-01, -9.9219e-01, -4.4922e-01, -6.2891e-01,\n",
      "          1.8828e+00,  1.0547e+00,  1.5625e-01],\n",
      "        [-3.6621e-02, -4.7852e-01, -1.2031e+00, -1.3438e+00,  1.8359e+00,\n",
      "          2.6562e+00, -1.2266e+00, -3.8477e-01],\n",
      "        [ 5.2734e-01, -9.4922e-01, -1.2812e+00, -8.2812e-01,  2.0938e+00,\n",
      "          1.5469e+00, -6.6797e-01, -5.5469e-01],\n",
      "        [-1.6699e-01, -1.5625e-01, -5.4688e-01, -1.1875e+00, -8.8379e-02,\n",
      "          4.0820e-01,  7.7734e-01,  1.4297e+00],\n",
      "        [ 6.3672e-01, -9.5312e-01, -5.2734e-01,  4.0894e-03, -1.0400e-01,\n",
      "          1.7266e+00, -6.0547e-01,  4.0527e-02],\n",
      "        [-2.2852e-01, -1.2793e-01, -1.7383e-01, -1.2085e-02, -8.3496e-02,\n",
      "         -5.7983e-04, -2.3535e-01,  4.1962e-04],\n",
      "        [-2.3340e-01,  4.3164e-01, -2.9297e-01, -3.9258e-01,  6.9141e-01,\n",
      "         -4.0820e-01,  8.1641e-01, -4.0283e-02],\n",
      "        [ 1.9688e+00, -8.5938e-01, -3.9648e-01, -1.1250e+00,  4.4922e-01,\n",
      "          3.2471e-02,  8.7109e-01, -5.9375e-01],\n",
      "        [ 9.0332e-03, -7.9688e-01, -9.9219e-01, -4.4922e-01, -6.2891e-01,\n",
      "          1.8828e+00,  1.0547e+00,  1.5625e-01],\n",
      "        [-3.6621e-02, -4.7852e-01, -1.2031e+00, -1.3438e+00,  1.8359e+00,\n",
      "          2.6562e+00, -1.2266e+00, -3.8477e-01],\n",
      "        [ 5.2734e-01, -9.4922e-01, -1.2812e+00, -8.2812e-01,  2.0938e+00,\n",
      "          1.5469e+00, -6.6797e-01, -5.5469e-01],\n",
      "        [ 2.1094e+00, -2.4512e-01, -4.5117e-01, -5.9375e-01, -1.4844e-01,\n",
      "         -3.8281e-01, -4.2188e-01,  2.9883e-01],\n",
      "        [ 7.3438e-01, -9.0234e-01, -5.1172e-01, -1.3574e-01, -2.1777e-01,\n",
      "          1.8594e+00, -6.5234e-01,  3.1006e-02]], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[-2.2852e-01, -1.2793e-01,        -inf, -1.2085e-02, -8.3496e-02,\n",
      "         -5.7983e-04,        -inf,  4.1962e-04],\n",
      "        [-2.3340e-01,  4.3164e-01,        -inf, -3.9258e-01,  6.9141e-01,\n",
      "         -4.0820e-01,        -inf, -4.0283e-02],\n",
      "        [ 1.9688e+00, -8.5938e-01,        -inf, -1.1250e+00,  4.4922e-01,\n",
      "          3.2471e-02,        -inf, -5.9375e-01],\n",
      "        [ 9.0332e-03, -7.9688e-01,        -inf, -4.4922e-01, -6.2891e-01,\n",
      "          1.8828e+00,        -inf,  1.5625e-01],\n",
      "        [-3.6621e-02, -4.7852e-01,        -inf, -1.3438e+00,  1.8359e+00,\n",
      "          2.6562e+00,        -inf, -3.8477e-01],\n",
      "        [ 5.2734e-01, -9.4922e-01,        -inf, -8.2812e-01,  2.0938e+00,\n",
      "          1.5469e+00,        -inf, -5.5469e-01],\n",
      "        [-1.6699e-01, -1.5625e-01,        -inf, -1.1875e+00, -8.8379e-02,\n",
      "          4.0820e-01,        -inf,  1.4297e+00],\n",
      "        [ 6.3672e-01, -9.5312e-01,        -inf,  4.0894e-03, -1.0400e-01,\n",
      "          1.7266e+00,        -inf,  4.0527e-02],\n",
      "        [-2.2852e-01, -1.2793e-01,        -inf, -1.2085e-02, -8.3496e-02,\n",
      "         -5.7983e-04,        -inf,  4.1962e-04],\n",
      "        [-2.3340e-01,  4.3164e-01,        -inf, -3.9258e-01,  6.9141e-01,\n",
      "         -4.0820e-01,        -inf, -4.0283e-02],\n",
      "        [ 1.9688e+00, -8.5938e-01,        -inf, -1.1250e+00,  4.4922e-01,\n",
      "          3.2471e-02,        -inf, -5.9375e-01],\n",
      "        [ 9.0332e-03, -7.9688e-01,        -inf, -4.4922e-01, -6.2891e-01,\n",
      "          1.8828e+00,        -inf,  1.5625e-01],\n",
      "        [-3.6621e-02, -4.7852e-01,        -inf, -1.3438e+00,  1.8359e+00,\n",
      "          2.6562e+00,        -inf, -3.8477e-01],\n",
      "        [ 5.2734e-01, -9.4922e-01,        -inf, -8.2812e-01,  2.0938e+00,\n",
      "          1.5469e+00,        -inf, -5.5469e-01],\n",
      "        [ 2.1094e+00, -2.4512e-01,        -inf, -5.9375e-01, -1.4844e-01,\n",
      "         -3.8281e-01,        -inf,  2.9883e-01],\n",
      "        [ 7.3438e-01, -9.0234e-01,        -inf, -1.3574e-01, -2.1777e-01,\n",
      "          1.8594e+00,        -inf,  3.1006e-02]], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([1, 5, 6, 7])\n",
      "router_logits is tensor([[-0.0708, -0.2246, -0.0869,  0.0352, -0.0732, -0.0708, -0.2324, -0.2715],\n",
      "        [-0.5273,  0.9688, -0.2559, -0.7461, -0.3984, -0.7461,  1.7109,  0.3418],\n",
      "        [ 0.0312, -0.2559,  1.7422, -0.3672,  1.0156, -0.8789, -0.3555, -0.3652],\n",
      "        [ 0.6211, -1.2188,  2.1250, -0.3262,  1.1562, -1.7891, -0.6211,  0.4219],\n",
      "        [ 1.1094, -0.5820,  0.1299, -0.8867, -1.7500, -1.0312,  0.8867,  1.7734],\n",
      "        [-0.0854,  1.0234,  0.3086, -1.5625, -0.6367,  1.2031, -0.7344,  0.6836],\n",
      "        [-1.0625,  0.7617, -0.6523, -1.5781,  0.0025,  1.5000,  0.8477,  0.6836],\n",
      "        [-0.1484, -1.4688,  0.4512, -1.7812, -0.2832,  1.5391,  0.2402,  1.2500],\n",
      "        [-0.0708, -0.2246, -0.0869,  0.0352, -0.0732, -0.0708, -0.2324, -0.2715],\n",
      "        [-0.5273,  0.9688, -0.2559, -0.7461, -0.3984, -0.7461,  1.7109,  0.3418],\n",
      "        [ 0.0312, -0.2559,  1.7422, -0.3672,  1.0156, -0.8789, -0.3555, -0.3652],\n",
      "        [ 0.6211, -1.2188,  2.1250, -0.3262,  1.1562, -1.7891, -0.6211,  0.4219],\n",
      "        [ 1.1094, -0.5820,  0.1299, -0.8867, -1.7500, -1.0312,  0.8867,  1.7734],\n",
      "        [-0.0854,  1.0234,  0.3086, -1.5625, -0.6367,  1.2031, -0.7344,  0.6836],\n",
      "        [-0.4023,  0.1543, -0.5117, -1.0312, -0.7461,  0.5156,  1.3203,  0.8320],\n",
      "        [-0.0459, -1.3750,  0.2773, -1.7344, -0.5703,  1.4219,  0.2949,  1.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[   -inf, -0.2246,    -inf,    -inf,    -inf, -0.0708, -0.2324, -0.2715],\n",
      "        [   -inf,  0.9688,    -inf,    -inf,    -inf, -0.7461,  1.7109,  0.3418],\n",
      "        [   -inf, -0.2559,    -inf,    -inf,    -inf, -0.8789, -0.3555, -0.3652],\n",
      "        [   -inf, -1.2188,    -inf,    -inf,    -inf, -1.7891, -0.6211,  0.4219],\n",
      "        [   -inf, -0.5820,    -inf,    -inf,    -inf, -1.0312,  0.8867,  1.7734],\n",
      "        [   -inf,  1.0234,    -inf,    -inf,    -inf,  1.2031, -0.7344,  0.6836],\n",
      "        [   -inf,  0.7617,    -inf,    -inf,    -inf,  1.5000,  0.8477,  0.6836],\n",
      "        [   -inf, -1.4688,    -inf,    -inf,    -inf,  1.5391,  0.2402,  1.2500],\n",
      "        [   -inf, -0.2246,    -inf,    -inf,    -inf, -0.0708, -0.2324, -0.2715],\n",
      "        [   -inf,  0.9688,    -inf,    -inf,    -inf, -0.7461,  1.7109,  0.3418],\n",
      "        [   -inf, -0.2559,    -inf,    -inf,    -inf, -0.8789, -0.3555, -0.3652],\n",
      "        [   -inf, -1.2188,    -inf,    -inf,    -inf, -1.7891, -0.6211,  0.4219],\n",
      "        [   -inf, -0.5820,    -inf,    -inf,    -inf, -1.0312,  0.8867,  1.7734],\n",
      "        [   -inf,  1.0234,    -inf,    -inf,    -inf,  1.2031, -0.7344,  0.6836],\n",
      "        [   -inf,  0.1543,    -inf,    -inf,    -inf,  0.5156,  1.3203,  0.8320],\n",
      "        [   -inf, -1.3750,    -inf,    -inf,    -inf,  1.4219,  0.2949,  1.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([2, 3, 4, 6])\n",
      "router_logits is tensor([[-0.1504, -0.0420, -0.1709,  0.3184, -0.0317,  0.3125, -0.0388,  0.0063],\n",
      "        [ 1.2109, -0.4629, -0.3672, -0.2910, -0.1836, -0.2637, -0.3906,  0.7539],\n",
      "        [-0.1299,  1.2109, -1.5547, -0.5391,  0.0211,  0.7461,  0.3438,  0.0304],\n",
      "        [ 0.0693,  0.8867, -1.6016,  0.2480, -0.3750,  1.0938, -0.6992,  0.5234],\n",
      "        [ 0.2217, -0.5547, -1.1641,  2.3125, -0.8516,  0.1533, -0.6406,  0.2197],\n",
      "        [-1.3594,  2.4062, -0.5820,  0.9531,  0.0786,  0.0718, -0.4219, -1.2500],\n",
      "        [-0.4551,  1.3516,  0.4258,  0.3242, -0.7344,  0.1895, -0.5469, -0.3203],\n",
      "        [-0.9609, -0.4980,  0.1016, -0.0432,  0.3359,  1.0234,  0.3594, -0.3418],\n",
      "        [-0.1504, -0.0420, -0.1709,  0.3184, -0.0317,  0.3125, -0.0388,  0.0063],\n",
      "        [ 1.2109, -0.4629, -0.3672, -0.2910, -0.1836, -0.2637, -0.3906,  0.7539],\n",
      "        [-0.1299,  1.2109, -1.5547, -0.5391,  0.0211,  0.7461,  0.3438,  0.0304],\n",
      "        [ 0.0693,  0.8867, -1.6016,  0.2480, -0.3750,  1.0938, -0.6992,  0.5234],\n",
      "        [ 0.2217, -0.5547, -1.1641,  2.3125, -0.8516,  0.1533, -0.6406,  0.2197],\n",
      "        [-1.3594,  2.4062, -0.5820,  0.9531,  0.0786,  0.0718, -0.4219, -1.2500],\n",
      "        [ 0.8555, -0.1523,  1.2578,  0.0165, -1.1328, -0.0060, -0.4004, -0.2715],\n",
      "        [-0.9180, -0.5156,  0.2578,  0.1172,  0.1895,  0.8672,  0.2578, -0.2969]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[   -inf,    -inf, -0.1709,  0.3184, -0.0317,    -inf, -0.0388,    -inf],\n",
      "        [   -inf,    -inf, -0.3672, -0.2910, -0.1836,    -inf, -0.3906,    -inf],\n",
      "        [   -inf,    -inf, -1.5547, -0.5391,  0.0211,    -inf,  0.3438,    -inf],\n",
      "        [   -inf,    -inf, -1.6016,  0.2480, -0.3750,    -inf, -0.6992,    -inf],\n",
      "        [   -inf,    -inf, -1.1641,  2.3125, -0.8516,    -inf, -0.6406,    -inf],\n",
      "        [   -inf,    -inf, -0.5820,  0.9531,  0.0786,    -inf, -0.4219,    -inf],\n",
      "        [   -inf,    -inf,  0.4258,  0.3242, -0.7344,    -inf, -0.5469,    -inf],\n",
      "        [   -inf,    -inf,  0.1016, -0.0432,  0.3359,    -inf,  0.3594,    -inf],\n",
      "        [   -inf,    -inf, -0.1709,  0.3184, -0.0317,    -inf, -0.0388,    -inf],\n",
      "        [   -inf,    -inf, -0.3672, -0.2910, -0.1836,    -inf, -0.3906,    -inf],\n",
      "        [   -inf,    -inf, -1.5547, -0.5391,  0.0211,    -inf,  0.3438,    -inf],\n",
      "        [   -inf,    -inf, -1.6016,  0.2480, -0.3750,    -inf, -0.6992,    -inf],\n",
      "        [   -inf,    -inf, -1.1641,  2.3125, -0.8516,    -inf, -0.6406,    -inf],\n",
      "        [   -inf,    -inf, -0.5820,  0.9531,  0.0786,    -inf, -0.4219,    -inf],\n",
      "        [   -inf,    -inf,  1.2578,  0.0165, -1.1328,    -inf, -0.4004,    -inf],\n",
      "        [   -inf,    -inf,  0.2578,  0.1172,  0.1895,    -inf,  0.2578,    -inf]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 1, 2, 5, 6])\n",
      "router_logits is tensor([[-0.0549, -0.2812,  0.1338, -0.0219,  0.2812, -0.1074, -0.0737,  0.3086],\n",
      "        [ 0.8789, -0.2021,  0.7188, -0.1416, -0.4707, -0.8945, -0.6484,  1.1172],\n",
      "        [ 0.2461, -0.4258, -0.3711, -0.3730, -0.2432,  1.1406,  0.7852, -0.5508],\n",
      "        [-0.2471, -0.7812, -0.7344,  0.5078, -0.6992, -0.4727,  2.5781,  0.1318],\n",
      "        [ 1.4141,  0.1416, -1.2578, -0.4863,  1.3906, -0.5352,  0.5938, -1.4453],\n",
      "        [ 2.2812, -0.4844, -1.3750, -0.7656, -0.0271,  1.8516,  0.7461, -1.9922],\n",
      "        [-0.1064, -0.2480,  0.7852, -1.4609,  0.2715, -0.0400,  1.0469, -0.0693],\n",
      "        [ 1.6719, -0.5078, -1.2422, -0.1982, -0.1777,  1.3359,  0.2793, -0.8477],\n",
      "        [-0.0549, -0.2812,  0.1338, -0.0219,  0.2812, -0.1074, -0.0737,  0.3086],\n",
      "        [ 0.8789, -0.2021,  0.7188, -0.1416, -0.4707, -0.8945, -0.6484,  1.1172],\n",
      "        [ 0.2461, -0.4258, -0.3711, -0.3730, -0.2432,  1.1406,  0.7852, -0.5508],\n",
      "        [-0.2471, -0.7812, -0.7344,  0.5078, -0.6992, -0.4727,  2.5781,  0.1318],\n",
      "        [ 1.4141,  0.1416, -1.2578, -0.4863,  1.3906, -0.5352,  0.5938, -1.4453],\n",
      "        [ 2.2812, -0.4844, -1.3750, -0.7656, -0.0271,  1.8516,  0.7461, -1.9922],\n",
      "        [-0.3750, -0.3008,  1.7031, -0.7031,  0.1826, -0.6875, -0.0859,  0.3242],\n",
      "        [ 1.5156, -0.6445, -0.8203, -0.1523, -0.0654,  1.2891, -0.2930, -0.5703]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[-0.0549, -0.2812,  0.1338,    -inf,    -inf, -0.1074, -0.0737,    -inf],\n",
      "        [ 0.8789, -0.2021,  0.7188,    -inf,    -inf, -0.8945, -0.6484,    -inf],\n",
      "        [ 0.2461, -0.4258, -0.3711,    -inf,    -inf,  1.1406,  0.7852,    -inf],\n",
      "        [-0.2471, -0.7812, -0.7344,    -inf,    -inf, -0.4727,  2.5781,    -inf],\n",
      "        [ 1.4141,  0.1416, -1.2578,    -inf,    -inf, -0.5352,  0.5938,    -inf],\n",
      "        [ 2.2812, -0.4844, -1.3750,    -inf,    -inf,  1.8516,  0.7461,    -inf],\n",
      "        [-0.1064, -0.2480,  0.7852,    -inf,    -inf, -0.0400,  1.0469,    -inf],\n",
      "        [ 1.6719, -0.5078, -1.2422,    -inf,    -inf,  1.3359,  0.2793,    -inf],\n",
      "        [-0.0549, -0.2812,  0.1338,    -inf,    -inf, -0.1074, -0.0737,    -inf],\n",
      "        [ 0.8789, -0.2021,  0.7188,    -inf,    -inf, -0.8945, -0.6484,    -inf],\n",
      "        [ 0.2461, -0.4258, -0.3711,    -inf,    -inf,  1.1406,  0.7852,    -inf],\n",
      "        [-0.2471, -0.7812, -0.7344,    -inf,    -inf, -0.4727,  2.5781,    -inf],\n",
      "        [ 1.4141,  0.1416, -1.2578,    -inf,    -inf, -0.5352,  0.5938,    -inf],\n",
      "        [ 2.2812, -0.4844, -1.3750,    -inf,    -inf,  1.8516,  0.7461,    -inf],\n",
      "        [-0.3750, -0.3008,  1.7031,    -inf,    -inf, -0.6875, -0.0859,    -inf],\n",
      "        [ 1.5156, -0.6445, -0.8203,    -inf,    -inf,  1.2891, -0.2930,    -inf]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([1, 2, 5, 6, 7])\n",
      "router_logits is tensor([[-0.0742,  0.1826,  0.0903, -0.1230,  0.1611, -0.0762,  0.1943,  0.2158],\n",
      "        [-0.6875,  0.0669,  0.5039, -0.2236, -0.0820,  0.1562, -0.0825,  0.3633],\n",
      "        [ 0.5273,  0.1143, -0.5547, -1.2812, -0.6250,  1.2344,  0.9062, -0.1934],\n",
      "        [ 0.4590,  0.2080, -1.2500, -1.6094, -0.4434,  1.6250,  1.7031, -0.5547],\n",
      "        [ 0.6719,  0.4316, -0.6992, -1.4141,  2.7188,  0.3262, -1.1172, -0.6602],\n",
      "        [ 2.9062, -0.8984, -1.3672, -1.0000,  2.6406,  0.0615, -0.5273, -1.3594],\n",
      "        [ 0.6211, -0.6680, -1.1250, -0.8906,  2.7188, -0.4316, -0.9922,  0.9766],\n",
      "        [ 1.3984, -0.3945, -1.4688, -1.6172,  1.1406,  1.7578,  0.8086, -1.6562],\n",
      "        [-0.0742,  0.1826,  0.0903, -0.1230,  0.1611, -0.0762,  0.1943,  0.2158],\n",
      "        [-0.6875,  0.0669,  0.5039, -0.2236, -0.0820,  0.1562, -0.0825,  0.3633],\n",
      "        [ 0.5273,  0.1143, -0.5547, -1.2812, -0.6250,  1.2344,  0.9062, -0.1934],\n",
      "        [ 0.4590,  0.2080, -1.2500, -1.6094, -0.4434,  1.6250,  1.7031, -0.5547],\n",
      "        [ 0.6719,  0.4316, -0.6992, -1.4141,  2.7188,  0.3262, -1.1172, -0.6602],\n",
      "        [ 2.9062, -0.8984, -1.3672, -1.0000,  2.6406,  0.0615, -0.5273, -1.3594],\n",
      "        [ 0.4121, -0.4102, -1.3203, -1.0156,  2.5938, -0.1118, -0.9570,  1.0000],\n",
      "        [ 1.1250, -0.3477, -1.3594, -1.5234,  1.0469,  1.7266,  0.7539, -1.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[   -inf,  0.1826,  0.0903,    -inf,    -inf, -0.0762,  0.1943,  0.2158],\n",
      "        [   -inf,  0.0669,  0.5039,    -inf,    -inf,  0.1562, -0.0825,  0.3633],\n",
      "        [   -inf,  0.1143, -0.5547,    -inf,    -inf,  1.2344,  0.9062, -0.1934],\n",
      "        [   -inf,  0.2080, -1.2500,    -inf,    -inf,  1.6250,  1.7031, -0.5547],\n",
      "        [   -inf,  0.4316, -0.6992,    -inf,    -inf,  0.3262, -1.1172, -0.6602],\n",
      "        [   -inf, -0.8984, -1.3672,    -inf,    -inf,  0.0615, -0.5273, -1.3594],\n",
      "        [   -inf, -0.6680, -1.1250,    -inf,    -inf, -0.4316, -0.9922,  0.9766],\n",
      "        [   -inf, -0.3945, -1.4688,    -inf,    -inf,  1.7578,  0.8086, -1.6562],\n",
      "        [   -inf,  0.1826,  0.0903,    -inf,    -inf, -0.0762,  0.1943,  0.2158],\n",
      "        [   -inf,  0.0669,  0.5039,    -inf,    -inf,  0.1562, -0.0825,  0.3633],\n",
      "        [   -inf,  0.1143, -0.5547,    -inf,    -inf,  1.2344,  0.9062, -0.1934],\n",
      "        [   -inf,  0.2080, -1.2500,    -inf,    -inf,  1.6250,  1.7031, -0.5547],\n",
      "        [   -inf,  0.4316, -0.6992,    -inf,    -inf,  0.3262, -1.1172, -0.6602],\n",
      "        [   -inf, -0.8984, -1.3672,    -inf,    -inf,  0.0615, -0.5273, -1.3594],\n",
      "        [   -inf, -0.4102, -1.3203,    -inf,    -inf, -0.1118, -0.9570,  1.0000],\n",
      "        [   -inf, -0.3477, -1.3594,    -inf,    -inf,  1.7266,  0.7539, -1.4375]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 1, 2, 3, 4, 5])\n",
      "router_logits is tensor([[-0.0815, -0.0737, -0.1836,  0.1670, -0.1226, -0.0160,  0.2246, -0.0830],\n",
      "        [ 0.7305, -0.6523,  0.4961, -0.5195,  0.1338, -0.2334,  0.5234, -0.4922],\n",
      "        [-0.1855, -1.2578,  0.3496, -0.4785,  1.1016, -0.6172, -0.3750,  1.1172],\n",
      "        [ 0.4707, -1.3594,  0.4844, -0.7422,  1.3281, -0.8555, -0.1475,  0.3184],\n",
      "        [-0.1118,  0.0776,  0.0552,  0.2559, -1.0156, -0.2344, -0.3555,  0.9648],\n",
      "        [ 0.1641, -0.3633, -0.9297, -0.5000,  1.5391, -0.9258, -1.4453,  2.1250],\n",
      "        [-0.5820,  1.9609, -0.1523,  0.8789, -1.4922, -0.4746, -0.9688,  0.1416],\n",
      "        [ 1.6719,  0.2432, -0.1426, -0.5000, -1.1250, -0.6719, -0.7656,  0.4805],\n",
      "        [-0.0815, -0.0737, -0.1836,  0.1670, -0.1226, -0.0160,  0.2246, -0.0830],\n",
      "        [ 0.7305, -0.6523,  0.4961, -0.5195,  0.1338, -0.2334,  0.5234, -0.4922],\n",
      "        [-0.1855, -1.2578,  0.3496, -0.4785,  1.1016, -0.6172, -0.3750,  1.1172],\n",
      "        [ 0.4707, -1.3594,  0.4844, -0.7422,  1.3281, -0.8555, -0.1475,  0.3184],\n",
      "        [-0.1118,  0.0776,  0.0552,  0.2559, -1.0156, -0.2344, -0.3555,  0.9648],\n",
      "        [ 0.1641, -0.3633, -0.9297, -0.5000,  1.5391, -0.9258, -1.4453,  2.1250],\n",
      "        [-0.7344,  1.6094, -0.4180,  0.8438, -0.9844, -0.3125, -0.8086,  0.2148],\n",
      "        [ 1.6016,  0.3164, -0.2051, -0.5273, -1.2344, -0.6758, -0.6289,  0.6133]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[-0.0815, -0.0737, -0.1836,  0.1670, -0.1226, -0.0160,    -inf,    -inf],\n",
      "        [ 0.7305, -0.6523,  0.4961, -0.5195,  0.1338, -0.2334,    -inf,    -inf],\n",
      "        [-0.1855, -1.2578,  0.3496, -0.4785,  1.1016, -0.6172,    -inf,    -inf],\n",
      "        [ 0.4707, -1.3594,  0.4844, -0.7422,  1.3281, -0.8555,    -inf,    -inf],\n",
      "        [-0.1118,  0.0776,  0.0552,  0.2559, -1.0156, -0.2344,    -inf,    -inf],\n",
      "        [ 0.1641, -0.3633, -0.9297, -0.5000,  1.5391, -0.9258,    -inf,    -inf],\n",
      "        [-0.5820,  1.9609, -0.1523,  0.8789, -1.4922, -0.4746,    -inf,    -inf],\n",
      "        [ 1.6719,  0.2432, -0.1426, -0.5000, -1.1250, -0.6719,    -inf,    -inf],\n",
      "        [-0.0815, -0.0737, -0.1836,  0.1670, -0.1226, -0.0160,    -inf,    -inf],\n",
      "        [ 0.7305, -0.6523,  0.4961, -0.5195,  0.1338, -0.2334,    -inf,    -inf],\n",
      "        [-0.1855, -1.2578,  0.3496, -0.4785,  1.1016, -0.6172,    -inf,    -inf],\n",
      "        [ 0.4707, -1.3594,  0.4844, -0.7422,  1.3281, -0.8555,    -inf,    -inf],\n",
      "        [-0.1118,  0.0776,  0.0552,  0.2559, -1.0156, -0.2344,    -inf,    -inf],\n",
      "        [ 0.1641, -0.3633, -0.9297, -0.5000,  1.5391, -0.9258,    -inf,    -inf],\n",
      "        [-0.7344,  1.6094, -0.4180,  0.8438, -0.9844, -0.3125,    -inf,    -inf],\n",
      "        [ 1.6016,  0.3164, -0.2051, -0.5273, -1.2344, -0.6758,    -inf,    -inf]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 1, 4, 5, 6])\n",
      "router_logits is tensor([[ 0.0400,  0.0371, -0.0474, -0.1182, -0.1885,  0.2598,  0.1455, -0.0938],\n",
      "        [-0.1982,  0.1846,  0.4824, -0.0815, -0.3535, -0.6289, -0.1025,  0.7891],\n",
      "        [ 0.8008, -0.2559, -0.2617, -1.3203, -1.2266, -1.2031,  1.9688,  0.3027],\n",
      "        [ 1.3516, -0.2139,  0.3750, -0.5039, -1.0938, -1.6172,  0.6641,  0.2295],\n",
      "        [-0.7578, -0.7930,  1.0781, -0.5781, -1.3828,  0.3457,  0.5117,  0.4473],\n",
      "        [ 1.6875,  0.5078,  0.7148, -0.0884, -1.4688, -1.1641,  0.5625, -1.3672],\n",
      "        [-0.5312, -0.4375,  1.5156, -0.7617, -0.9297,  0.0300, -0.3906, -0.1934],\n",
      "        [ 1.0078,  0.0552, -0.0186, -0.3633,  0.1357, -0.5625,  0.0879, -1.3203],\n",
      "        [ 0.0400,  0.0371, -0.0474, -0.1182, -0.1885,  0.2598,  0.1455, -0.0938],\n",
      "        [-0.1982,  0.1846,  0.4824, -0.0815, -0.3535, -0.6289, -0.1025,  0.7891],\n",
      "        [ 0.8008, -0.2559, -0.2617, -1.3203, -1.2266, -1.2031,  1.9688,  0.3027],\n",
      "        [ 1.3516, -0.2139,  0.3750, -0.5039, -1.0938, -1.6172,  0.6641,  0.2295],\n",
      "        [-0.7578, -0.7930,  1.0781, -0.5781, -1.3828,  0.3457,  0.5117,  0.4473],\n",
      "        [ 1.6875,  0.5078,  0.7148, -0.0884, -1.4688, -1.1641,  0.5625, -1.3672],\n",
      "        [-0.4590, -0.7617,  1.6406, -0.7344, -0.9141,  0.0713, -0.3848, -0.1260],\n",
      "        [ 0.8672,  0.1035, -0.2676, -0.5938,  0.2490, -0.4707,  0.1582, -1.1641]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[ 0.0400,  0.0371,    -inf,    -inf, -0.1885,  0.2598,  0.1455,    -inf],\n",
      "        [-0.1982,  0.1846,    -inf,    -inf, -0.3535, -0.6289, -0.1025,    -inf],\n",
      "        [ 0.8008, -0.2559,    -inf,    -inf, -1.2266, -1.2031,  1.9688,    -inf],\n",
      "        [ 1.3516, -0.2139,    -inf,    -inf, -1.0938, -1.6172,  0.6641,    -inf],\n",
      "        [-0.7578, -0.7930,    -inf,    -inf, -1.3828,  0.3457,  0.5117,    -inf],\n",
      "        [ 1.6875,  0.5078,    -inf,    -inf, -1.4688, -1.1641,  0.5625,    -inf],\n",
      "        [-0.5312, -0.4375,    -inf,    -inf, -0.9297,  0.0300, -0.3906,    -inf],\n",
      "        [ 1.0078,  0.0552,    -inf,    -inf,  0.1357, -0.5625,  0.0879,    -inf],\n",
      "        [ 0.0400,  0.0371,    -inf,    -inf, -0.1885,  0.2598,  0.1455,    -inf],\n",
      "        [-0.1982,  0.1846,    -inf,    -inf, -0.3535, -0.6289, -0.1025,    -inf],\n",
      "        [ 0.8008, -0.2559,    -inf,    -inf, -1.2266, -1.2031,  1.9688,    -inf],\n",
      "        [ 1.3516, -0.2139,    -inf,    -inf, -1.0938, -1.6172,  0.6641,    -inf],\n",
      "        [-0.7578, -0.7930,    -inf,    -inf, -1.3828,  0.3457,  0.5117,    -inf],\n",
      "        [ 1.6875,  0.5078,    -inf,    -inf, -1.4688, -1.1641,  0.5625,    -inf],\n",
      "        [-0.4590, -0.7617,    -inf,    -inf, -0.9141,  0.0713, -0.3848,    -inf],\n",
      "        [ 0.8672,  0.1035,    -inf,    -inf,  0.2490, -0.4707,  0.1582,    -inf]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([2, 3, 4, 5, 6])\n",
      "router_logits is tensor([[ 0.5859,  0.0659, -0.1001,  0.2070,  0.5352,  0.1201,  0.1641,  0.6133],\n",
      "        [ 0.2910,  0.3008, -0.5430,  0.1138, -0.1367, -0.1260, -0.8125,  1.0078],\n",
      "        [-0.6133,  0.5508,  0.0608,  0.8164, -0.2021, -0.5977, -0.4102,  0.2520],\n",
      "        [-0.4766,  0.3789, -0.3711,  0.8047, -0.4805, -0.4629,  0.1758,  0.4766],\n",
      "        [-0.0084, -0.5898, -0.2500,  0.3223,  1.1016,  0.4629, -1.3438, -0.9375],\n",
      "        [-0.3711,  1.4766,  0.2236, -0.1030, -0.1758, -0.5391, -0.6641, -0.9609],\n",
      "        [ 1.7031,  0.0513, -0.8242, -0.7500, -0.0693, -0.1719, -0.8594, -0.3398],\n",
      "        [-0.2910, -0.3848, -0.8555,  1.1328,  0.6211, -0.0811, -1.3359,  0.0791],\n",
      "        [ 0.5859,  0.0659, -0.1001,  0.2070,  0.5352,  0.1201,  0.1641,  0.6133],\n",
      "        [ 0.2910,  0.3008, -0.5430,  0.1138, -0.1367, -0.1260, -0.8125,  1.0078],\n",
      "        [-0.6133,  0.5508,  0.0608,  0.8164, -0.2021, -0.5977, -0.4102,  0.2520],\n",
      "        [-0.4766,  0.3789, -0.3711,  0.8047, -0.4805, -0.4629,  0.1758,  0.4766],\n",
      "        [-0.0084, -0.5898, -0.2500,  0.3223,  1.1016,  0.4629, -1.3438, -0.9375],\n",
      "        [-0.3711,  1.4766,  0.2236, -0.1030, -0.1758, -0.5391, -0.6641, -0.9609],\n",
      "        [ 1.5156, -0.1035, -0.7070, -0.8750,  0.2324, -0.1553, -0.8281, -0.3223],\n",
      "        [-0.3477, -0.2490, -0.9531,  1.1406,  0.6758, -0.0103, -1.2656, -0.4688]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[   -inf,    -inf, -0.1001,  0.2070,  0.5352,  0.1201,  0.1641,    -inf],\n",
      "        [   -inf,    -inf, -0.5430,  0.1138, -0.1367, -0.1260, -0.8125,    -inf],\n",
      "        [   -inf,    -inf,  0.0608,  0.8164, -0.2021, -0.5977, -0.4102,    -inf],\n",
      "        [   -inf,    -inf, -0.3711,  0.8047, -0.4805, -0.4629,  0.1758,    -inf],\n",
      "        [   -inf,    -inf, -0.2500,  0.3223,  1.1016,  0.4629, -1.3438,    -inf],\n",
      "        [   -inf,    -inf,  0.2236, -0.1030, -0.1758, -0.5391, -0.6641,    -inf],\n",
      "        [   -inf,    -inf, -0.8242, -0.7500, -0.0693, -0.1719, -0.8594,    -inf],\n",
      "        [   -inf,    -inf, -0.8555,  1.1328,  0.6211, -0.0811, -1.3359,    -inf],\n",
      "        [   -inf,    -inf, -0.1001,  0.2070,  0.5352,  0.1201,  0.1641,    -inf],\n",
      "        [   -inf,    -inf, -0.5430,  0.1138, -0.1367, -0.1260, -0.8125,    -inf],\n",
      "        [   -inf,    -inf,  0.0608,  0.8164, -0.2021, -0.5977, -0.4102,    -inf],\n",
      "        [   -inf,    -inf, -0.3711,  0.8047, -0.4805, -0.4629,  0.1758,    -inf],\n",
      "        [   -inf,    -inf, -0.2500,  0.3223,  1.1016,  0.4629, -1.3438,    -inf],\n",
      "        [   -inf,    -inf,  0.2236, -0.1030, -0.1758, -0.5391, -0.6641,    -inf],\n",
      "        [   -inf,    -inf, -0.7070, -0.8750,  0.2324, -0.1553, -0.8281,    -inf],\n",
      "        [   -inf,    -inf, -0.9531,  1.1406,  0.6758, -0.0103, -1.2656,    -inf]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([1, 4, 5, 6, 7])\n",
      "router_logits is tensor([[-0.0172,  0.2246,  0.0525,  0.2539, -0.2812,  0.0542,  0.0427,  0.0074],\n",
      "        [ 0.2988, -0.7891,  0.2910, -0.4570,  0.4277,  0.1797, -0.3242, -0.0586],\n",
      "        [ 1.9453, -0.9414, -0.4824,  0.1914, -0.6211, -0.1719, -0.0145, -0.2891],\n",
      "        [ 1.2344, -0.3262, -0.0947,  0.8086, -0.9922, -0.2988, -0.1934, -0.6602],\n",
      "        [ 0.3125,  0.5977, -1.4922, -0.2031, -1.2266,  0.9023,  0.9805, -0.0593],\n",
      "        [ 2.8125, -1.0078, -1.0469, -0.5859,  0.3906, -0.1147, -0.6250, -0.0089],\n",
      "        [-0.8320,  0.0630,  1.0391, -0.9258, -0.7578, -0.3867,  0.0043,  1.0391],\n",
      "        [-0.1504, -0.5898, -0.5703, -0.9453,  0.1221, -0.6211,  0.0381,  2.1719],\n",
      "        [-0.0172,  0.2246,  0.0525,  0.2539, -0.2812,  0.0542,  0.0427,  0.0074],\n",
      "        [ 0.2988, -0.7891,  0.2910, -0.4570,  0.4277,  0.1797, -0.3242, -0.0586],\n",
      "        [ 1.9453, -0.9414, -0.4824,  0.1914, -0.6211, -0.1719, -0.0145, -0.2891],\n",
      "        [ 1.2344, -0.3262, -0.0947,  0.8086, -0.9922, -0.2988, -0.1934, -0.6602],\n",
      "        [ 0.3125,  0.5977, -1.4922, -0.2031, -1.2266,  0.9023,  0.9805, -0.0593],\n",
      "        [ 2.8125, -1.0078, -1.0469, -0.5859,  0.3906, -0.1147, -0.6250, -0.0089],\n",
      "        [-0.6602,  0.1787,  0.8398, -1.0312, -0.7500, -0.2695,  0.0688,  0.9961],\n",
      "        [-0.1631, -0.6133, -0.7227, -0.8750,  0.2246, -0.6914,  0.0713,  2.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[   -inf,  0.2246,    -inf,    -inf, -0.2812,  0.0542,  0.0427,  0.0074],\n",
      "        [   -inf, -0.7891,    -inf,    -inf,  0.4277,  0.1797, -0.3242, -0.0586],\n",
      "        [   -inf, -0.9414,    -inf,    -inf, -0.6211, -0.1719, -0.0145, -0.2891],\n",
      "        [   -inf, -0.3262,    -inf,    -inf, -0.9922, -0.2988, -0.1934, -0.6602],\n",
      "        [   -inf,  0.5977,    -inf,    -inf, -1.2266,  0.9023,  0.9805, -0.0593],\n",
      "        [   -inf, -1.0078,    -inf,    -inf,  0.3906, -0.1147, -0.6250, -0.0089],\n",
      "        [   -inf,  0.0630,    -inf,    -inf, -0.7578, -0.3867,  0.0043,  1.0391],\n",
      "        [   -inf, -0.5898,    -inf,    -inf,  0.1221, -0.6211,  0.0381,  2.1719],\n",
      "        [   -inf,  0.2246,    -inf,    -inf, -0.2812,  0.0542,  0.0427,  0.0074],\n",
      "        [   -inf, -0.7891,    -inf,    -inf,  0.4277,  0.1797, -0.3242, -0.0586],\n",
      "        [   -inf, -0.9414,    -inf,    -inf, -0.6211, -0.1719, -0.0145, -0.2891],\n",
      "        [   -inf, -0.3262,    -inf,    -inf, -0.9922, -0.2988, -0.1934, -0.6602],\n",
      "        [   -inf,  0.5977,    -inf,    -inf, -1.2266,  0.9023,  0.9805, -0.0593],\n",
      "        [   -inf, -1.0078,    -inf,    -inf,  0.3906, -0.1147, -0.6250, -0.0089],\n",
      "        [   -inf,  0.1787,    -inf,    -inf, -0.7500, -0.2695,  0.0688,  0.9961],\n",
      "        [   -inf, -0.6133,    -inf,    -inf,  0.2246, -0.6914,  0.0713,  2.1406]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 1, 3, 5, 6])\n",
      "router_logits is tensor([[-0.0957, -0.0613, -0.1279, -0.0352, -0.1309,  0.0693, -0.1338,  0.0703],\n",
      "        [ 0.9219, -0.7148,  1.4141, -0.7422,  0.3555, -0.1973, -0.0229, -0.5273],\n",
      "        [-0.7500, -0.3047,  1.7812, -2.1562, -0.0645,  0.5117, -0.2773,  1.0156],\n",
      "        [-0.8398, -0.6562,  2.5781, -2.2969, -0.5508, -0.1162, -0.9180,  2.4688],\n",
      "        [-1.0312, -0.6992,  1.4297, -0.3242, -0.7656, -0.2734,  0.8633,  0.1699],\n",
      "        [-1.3438,  1.6641,  1.6719, -1.1562, -1.7812,  0.8828, -0.1797, -0.1357],\n",
      "        [-0.3613, -0.2246,  0.5352,  0.9102, -1.0000, -0.2539, -0.1621, -0.8008],\n",
      "        [ 1.3516,  0.0356,  0.9102, -0.6289,  0.4102, -0.5469, -1.1875, -1.0156],\n",
      "        [-0.0957, -0.0613, -0.1279, -0.0352, -0.1309,  0.0693, -0.1338,  0.0703],\n",
      "        [ 0.9219, -0.7148,  1.4141, -0.7422,  0.3555, -0.1973, -0.0229, -0.5273],\n",
      "        [-0.7500, -0.3047,  1.7812, -2.1562, -0.0645,  0.5117, -0.2773,  1.0156],\n",
      "        [-0.8398, -0.6562,  2.5781, -2.2969, -0.5508, -0.1162, -0.9180,  2.4688],\n",
      "        [-1.0312, -0.6992,  1.4297, -0.3242, -0.7656, -0.2734,  0.8633,  0.1699],\n",
      "        [-1.3438,  1.6641,  1.6719, -1.1562, -1.7812,  0.8828, -0.1797, -0.1357],\n",
      "        [-0.5703, -0.2656,  0.5742,  0.9258, -0.9258, -0.1523, -0.0131, -0.8047],\n",
      "        [ 1.2500, -0.0649,  0.7227, -0.5078,  0.3340, -0.5234, -1.0781, -0.8477]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[-0.0957, -0.0613,    -inf, -0.0352,    -inf,  0.0693, -0.1338,    -inf],\n",
      "        [ 0.9219, -0.7148,    -inf, -0.7422,    -inf, -0.1973, -0.0229,    -inf],\n",
      "        [-0.7500, -0.3047,    -inf, -2.1562,    -inf,  0.5117, -0.2773,    -inf],\n",
      "        [-0.8398, -0.6562,    -inf, -2.2969,    -inf, -0.1162, -0.9180,    -inf],\n",
      "        [-1.0312, -0.6992,    -inf, -0.3242,    -inf, -0.2734,  0.8633,    -inf],\n",
      "        [-1.3438,  1.6641,    -inf, -1.1562,    -inf,  0.8828, -0.1797,    -inf],\n",
      "        [-0.3613, -0.2246,    -inf,  0.9102,    -inf, -0.2539, -0.1621,    -inf],\n",
      "        [ 1.3516,  0.0356,    -inf, -0.6289,    -inf, -0.5469, -1.1875,    -inf],\n",
      "        [-0.0957, -0.0613,    -inf, -0.0352,    -inf,  0.0693, -0.1338,    -inf],\n",
      "        [ 0.9219, -0.7148,    -inf, -0.7422,    -inf, -0.1973, -0.0229,    -inf],\n",
      "        [-0.7500, -0.3047,    -inf, -2.1562,    -inf,  0.5117, -0.2773,    -inf],\n",
      "        [-0.8398, -0.6562,    -inf, -2.2969,    -inf, -0.1162, -0.9180,    -inf],\n",
      "        [-1.0312, -0.6992,    -inf, -0.3242,    -inf, -0.2734,  0.8633,    -inf],\n",
      "        [-1.3438,  1.6641,    -inf, -1.1562,    -inf,  0.8828, -0.1797,    -inf],\n",
      "        [-0.5703, -0.2656,    -inf,  0.9258,    -inf, -0.1523, -0.0131,    -inf],\n",
      "        [ 1.2500, -0.0649,    -inf, -0.5078,    -inf, -0.5234, -1.0781,    -inf]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 4, 5, 6, 7])\n",
      "router_logits is tensor([[-0.1436, -0.0796, -0.0796, -0.0164, -0.0099, -0.0610, -0.0110, -0.0762],\n",
      "        [-1.1094,  0.6758,  0.9414, -0.8750,  0.2852, -0.8594,  0.3770,  0.4453],\n",
      "        [-0.1934,  1.5625,  1.0234,  0.6211, -1.0000, -1.2344,  0.2715, -1.5703],\n",
      "        [ 2.4062,  1.0625, -0.0928,  3.8281, -0.2402, -2.3125, -1.3750, -2.4688],\n",
      "        [-1.2578,  0.7070,  0.5352,  0.1406,  1.9062, -1.7109, -0.8711,  0.3438],\n",
      "        [-0.5664,  0.3730, -0.0398, -1.8047, -0.2031,  0.3125,  1.5078, -1.0703],\n",
      "        [-0.2793,  0.4180, -0.0894, -0.5664,  1.0625, -1.3125, -1.3359,  1.3750],\n",
      "        [ 0.5898, -0.8438,  0.9531,  0.4160,  0.8242, -0.1562, -0.8633, -1.2422],\n",
      "        [-0.1436, -0.0796, -0.0796, -0.0164, -0.0099, -0.0610, -0.0110, -0.0762],\n",
      "        [-1.1094,  0.6758,  0.9414, -0.8750,  0.2852, -0.8594,  0.3770,  0.4453],\n",
      "        [-0.1934,  1.5625,  1.0234,  0.6211, -1.0000, -1.2344,  0.2715, -1.5703],\n",
      "        [ 2.4062,  1.0625, -0.0928,  3.8281, -0.2402, -2.3125, -1.3750, -2.4688],\n",
      "        [-1.2578,  0.7070,  0.5352,  0.1406,  1.9062, -1.7109, -0.8711,  0.3438],\n",
      "        [-0.5664,  0.3730, -0.0398, -1.8047, -0.2031,  0.3125,  1.5078, -1.0703],\n",
      "        [-0.1836,  0.4590, -0.2148, -0.8906,  1.0000, -1.0859, -1.2578,  1.3203],\n",
      "        [ 0.8906, -0.8750,  0.7070,  0.3320,  0.7852, -0.1235, -0.6875, -1.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[-0.1436,    -inf,    -inf,    -inf, -0.0099, -0.0610, -0.0110, -0.0762],\n",
      "        [-1.1094,    -inf,    -inf,    -inf,  0.2852, -0.8594,  0.3770,  0.4453],\n",
      "        [-0.1934,    -inf,    -inf,    -inf, -1.0000, -1.2344,  0.2715, -1.5703],\n",
      "        [ 2.4062,    -inf,    -inf,    -inf, -0.2402, -2.3125, -1.3750, -2.4688],\n",
      "        [-1.2578,    -inf,    -inf,    -inf,  1.9062, -1.7109, -0.8711,  0.3438],\n",
      "        [-0.5664,    -inf,    -inf,    -inf, -0.2031,  0.3125,  1.5078, -1.0703],\n",
      "        [-0.2793,    -inf,    -inf,    -inf,  1.0625, -1.3125, -1.3359,  1.3750],\n",
      "        [ 0.5898,    -inf,    -inf,    -inf,  0.8242, -0.1562, -0.8633, -1.2422],\n",
      "        [-0.1436,    -inf,    -inf,    -inf, -0.0099, -0.0610, -0.0110, -0.0762],\n",
      "        [-1.1094,    -inf,    -inf,    -inf,  0.2852, -0.8594,  0.3770,  0.4453],\n",
      "        [-0.1934,    -inf,    -inf,    -inf, -1.0000, -1.2344,  0.2715, -1.5703],\n",
      "        [ 2.4062,    -inf,    -inf,    -inf, -0.2402, -2.3125, -1.3750, -2.4688],\n",
      "        [-1.2578,    -inf,    -inf,    -inf,  1.9062, -1.7109, -0.8711,  0.3438],\n",
      "        [-0.5664,    -inf,    -inf,    -inf, -0.2031,  0.3125,  1.5078, -1.0703],\n",
      "        [-0.1836,    -inf,    -inf,    -inf,  1.0000, -1.0859, -1.2578,  1.3203],\n",
      "        [ 0.8906,    -inf,    -inf,    -inf,  0.7852, -0.1235, -0.6875, -1.3281]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([1, 2, 3, 4, 5])\n",
      "router_logits is tensor([[ 0.0811,  0.0928, -0.1611,  0.0085, -0.0396, -0.0033, -0.0454, -0.1943],\n",
      "        [-0.6406,  1.6641,  0.6641, -0.0457,  0.9688, -0.8750, -0.7617, -0.6172],\n",
      "        [-1.0625, -0.1025, -0.9570, -0.8477,  0.5430,  1.3906,  0.2969,  0.4785],\n",
      "        [-0.5234,  1.9219, -1.0312,  2.0469, -0.5000, -0.5859, -0.7266, -0.5547],\n",
      "        [ 0.3340,  2.7500, -0.2871, -0.0972, -0.8203, -1.8281, -0.5430, -0.0310],\n",
      "        [-1.4844, -0.8633, -1.3125, -1.3594,  0.0295,  1.0938,  1.1016,  2.0156],\n",
      "        [ 1.7266,  0.5820, -0.8242, -0.9727, -0.4004, -0.9961,  0.0177,  0.7930],\n",
      "        [-1.3594, -0.4844, -0.9258, -1.7422,  0.3223,  2.1719,  0.8477,  0.1235],\n",
      "        [ 0.0811,  0.0928, -0.1611,  0.0085, -0.0396, -0.0033, -0.0454, -0.1943],\n",
      "        [-0.6406,  1.6641,  0.6641, -0.0457,  0.9688, -0.8750, -0.7617, -0.6172],\n",
      "        [-1.0625, -0.1025, -0.9570, -0.8477,  0.5430,  1.3906,  0.2969,  0.4785],\n",
      "        [-0.5234,  1.9219, -1.0312,  2.0469, -0.5000, -0.5859, -0.7266, -0.5547],\n",
      "        [ 0.3340,  2.7500, -0.2871, -0.0972, -0.8203, -1.8281, -0.5430, -0.0310],\n",
      "        [-1.4844, -0.8633, -1.3125, -1.3594,  0.0295,  1.0938,  1.1016,  2.0156],\n",
      "        [ 1.6484,  0.6367, -0.6680, -0.8398, -0.5000, -1.1641,  0.0102,  0.6758],\n",
      "        [-1.6094, -0.4629, -0.8750, -1.5156,  0.2412,  2.0781,  1.0000,  0.0649]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[   -inf,  0.0928, -0.1611,  0.0085, -0.0396, -0.0033,    -inf,    -inf],\n",
      "        [   -inf,  1.6641,  0.6641, -0.0457,  0.9688, -0.8750,    -inf,    -inf],\n",
      "        [   -inf, -0.1025, -0.9570, -0.8477,  0.5430,  1.3906,    -inf,    -inf],\n",
      "        [   -inf,  1.9219, -1.0312,  2.0469, -0.5000, -0.5859,    -inf,    -inf],\n",
      "        [   -inf,  2.7500, -0.2871, -0.0972, -0.8203, -1.8281,    -inf,    -inf],\n",
      "        [   -inf, -0.8633, -1.3125, -1.3594,  0.0295,  1.0938,    -inf,    -inf],\n",
      "        [   -inf,  0.5820, -0.8242, -0.9727, -0.4004, -0.9961,    -inf,    -inf],\n",
      "        [   -inf, -0.4844, -0.9258, -1.7422,  0.3223,  2.1719,    -inf,    -inf],\n",
      "        [   -inf,  0.0928, -0.1611,  0.0085, -0.0396, -0.0033,    -inf,    -inf],\n",
      "        [   -inf,  1.6641,  0.6641, -0.0457,  0.9688, -0.8750,    -inf,    -inf],\n",
      "        [   -inf, -0.1025, -0.9570, -0.8477,  0.5430,  1.3906,    -inf,    -inf],\n",
      "        [   -inf,  1.9219, -1.0312,  2.0469, -0.5000, -0.5859,    -inf,    -inf],\n",
      "        [   -inf,  2.7500, -0.2871, -0.0972, -0.8203, -1.8281,    -inf,    -inf],\n",
      "        [   -inf, -0.8633, -1.3125, -1.3594,  0.0295,  1.0938,    -inf,    -inf],\n",
      "        [   -inf,  0.6367, -0.6680, -0.8398, -0.5000, -1.1641,    -inf,    -inf],\n",
      "        [   -inf, -0.4629, -0.8750, -1.5156,  0.2412,  2.0781,    -inf,    -inf]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 1, 3, 4, 5, 7])\n",
      "router_logits is tensor([[ 2.1851e-02,  1.0059e-01, -1.3184e-02,  7.6660e-02, -5.0537e-02,\n",
      "          8.2520e-02,  1.0757e-03,  1.0205e-01],\n",
      "        [-9.7266e-01, -5.8984e-01, -2.3535e-01,  4.7852e-01, -1.1084e-01,\n",
      "         -1.9824e-01,  1.2500e+00,  7.6953e-01],\n",
      "        [-7.0703e-01, -9.1797e-02, -7.8906e-01, -2.4121e-01,  9.8828e-01,\n",
      "         -3.2227e-01, -6.7578e-01,  1.6016e+00],\n",
      "        [-2.6953e-01, -1.3047e+00,  1.0234e+00, -1.0156e+00, -2.1875e-01,\n",
      "          1.6250e+00, -2.9492e-01,  3.2422e-01],\n",
      "        [-2.1094e-01, -7.5781e-01,  7.1484e-01, -6.2109e-01, -7.3828e-01,\n",
      "          8.5938e-01, -1.5234e+00,  1.5938e+00],\n",
      "        [-3.6328e-01,  7.6953e-01, -1.0547e+00,  1.2158e-01, -2.7734e-01,\n",
      "          1.2422e+00, -1.0312e+00,  4.9414e-01],\n",
      "        [ 2.1406e+00, -2.6953e-01,  8.3594e-01, -1.1406e+00, -1.2266e+00,\n",
      "          1.0547e+00, -1.7109e+00, -8.0859e-01],\n",
      "        [ 1.1658e-02,  3.8330e-02, -1.9727e-01, -4.3555e-01,  3.2422e-01,\n",
      "         -6.7969e-01, -5.1953e-01,  1.1094e+00],\n",
      "        [ 2.1851e-02,  1.0059e-01, -1.3184e-02,  7.6660e-02, -5.0537e-02,\n",
      "          8.2520e-02,  1.0757e-03,  1.0205e-01],\n",
      "        [-9.7266e-01, -5.8984e-01, -2.3535e-01,  4.7852e-01, -1.1084e-01,\n",
      "         -1.9824e-01,  1.2500e+00,  7.6953e-01],\n",
      "        [-7.0703e-01, -9.1797e-02, -7.8906e-01, -2.4121e-01,  9.8828e-01,\n",
      "         -3.2227e-01, -6.7578e-01,  1.6016e+00],\n",
      "        [-2.6953e-01, -1.3047e+00,  1.0234e+00, -1.0156e+00, -2.1875e-01,\n",
      "          1.6250e+00, -2.9492e-01,  3.2422e-01],\n",
      "        [-2.1094e-01, -7.5781e-01,  7.1484e-01, -6.2109e-01, -7.3828e-01,\n",
      "          8.5938e-01, -1.5234e+00,  1.5938e+00],\n",
      "        [-3.6328e-01,  7.6953e-01, -1.0547e+00,  1.2158e-01, -2.7734e-01,\n",
      "          1.2422e+00, -1.0312e+00,  4.9414e-01],\n",
      "        [ 2.1406e+00, -3.3398e-01,  9.3359e-01, -9.4531e-01, -1.3984e+00,\n",
      "          9.7266e-01, -1.6562e+00, -7.9688e-01],\n",
      "        [-9.0332e-02, -8.3496e-02, -1.1670e-01, -5.7031e-01,  5.9375e-01,\n",
      "         -5.8594e-01, -5.8594e-01,  1.1250e+00]], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[ 0.0219,  0.1006,    -inf,  0.0767, -0.0505,  0.0825,    -inf,  0.1021],\n",
      "        [-0.9727, -0.5898,    -inf,  0.4785, -0.1108, -0.1982,    -inf,  0.7695],\n",
      "        [-0.7070, -0.0918,    -inf, -0.2412,  0.9883, -0.3223,    -inf,  1.6016],\n",
      "        [-0.2695, -1.3047,    -inf, -1.0156, -0.2188,  1.6250,    -inf,  0.3242],\n",
      "        [-0.2109, -0.7578,    -inf, -0.6211, -0.7383,  0.8594,    -inf,  1.5938],\n",
      "        [-0.3633,  0.7695,    -inf,  0.1216, -0.2773,  1.2422,    -inf,  0.4941],\n",
      "        [ 2.1406, -0.2695,    -inf, -1.1406, -1.2266,  1.0547,    -inf, -0.8086],\n",
      "        [ 0.0117,  0.0383,    -inf, -0.4355,  0.3242, -0.6797,    -inf,  1.1094],\n",
      "        [ 0.0219,  0.1006,    -inf,  0.0767, -0.0505,  0.0825,    -inf,  0.1021],\n",
      "        [-0.9727, -0.5898,    -inf,  0.4785, -0.1108, -0.1982,    -inf,  0.7695],\n",
      "        [-0.7070, -0.0918,    -inf, -0.2412,  0.9883, -0.3223,    -inf,  1.6016],\n",
      "        [-0.2695, -1.3047,    -inf, -1.0156, -0.2188,  1.6250,    -inf,  0.3242],\n",
      "        [-0.2109, -0.7578,    -inf, -0.6211, -0.7383,  0.8594,    -inf,  1.5938],\n",
      "        [-0.3633,  0.7695,    -inf,  0.1216, -0.2773,  1.2422,    -inf,  0.4941],\n",
      "        [ 2.1406, -0.3340,    -inf, -0.9453, -1.3984,  0.9727,    -inf, -0.7969],\n",
      "        [-0.0903, -0.0835,    -inf, -0.5703,  0.5938, -0.5859,    -inf,  1.1250]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 2, 3, 4, 5])\n",
      "router_logits is tensor([[-0.2715, -0.1816, -0.0498, -0.0569, -0.3008, -0.1816, -0.0723, -0.2598],\n",
      "        [ 0.8633, -1.3750,  2.6094, -0.4531, -0.3438, -0.1846, -0.0884, -0.5586],\n",
      "        [-0.3594,  0.3418,  0.4199, -0.0593, -0.8711,  2.1406,  0.5938, -1.9297],\n",
      "        [ 2.0000, -1.0703,  3.1250, -0.9102, -1.1719, -0.6406, -0.5352, -1.3984],\n",
      "        [-0.2539, -0.5820,  0.7383,  0.9297, -0.2520,  0.4453, -0.5312, -0.8906],\n",
      "        [-1.0625,  2.6250,  0.2373,  0.8281, -0.9414, -0.8516,  1.1797, -1.7422],\n",
      "        [-1.1953, -0.7734,  2.6250, -1.4688,  0.6719, -0.3906,  0.1211,  0.1230],\n",
      "        [-0.5625,  2.7031, -0.8984, -0.7344, -0.3184,  1.0234,  0.4746, -0.8984],\n",
      "        [-0.2715, -0.1816, -0.0498, -0.0569, -0.3008, -0.1816, -0.0723, -0.2598],\n",
      "        [ 0.8633, -1.3750,  2.6094, -0.4531, -0.3438, -0.1846, -0.0884, -0.5586],\n",
      "        [-0.3594,  0.3418,  0.4199, -0.0593, -0.8711,  2.1406,  0.5938, -1.9297],\n",
      "        [ 2.0000, -1.0703,  3.1250, -0.9102, -1.1719, -0.6406, -0.5352, -1.3984],\n",
      "        [-0.2539, -0.5820,  0.7383,  0.9297, -0.2520,  0.4453, -0.5312, -0.8906],\n",
      "        [-1.0625,  2.6250,  0.2373,  0.8281, -0.9414, -0.8516,  1.1797, -1.7422],\n",
      "        [-1.2031, -0.7344,  2.4062, -1.1484,  0.8047, -0.4727, -0.1172,  0.1973],\n",
      "        [-0.0645,  2.3750, -0.7852, -0.7656, -0.2832,  0.8320,  0.3594, -0.8320]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[-0.2715,    -inf, -0.0498, -0.0569, -0.3008, -0.1816,    -inf,    -inf],\n",
      "        [ 0.8633,    -inf,  2.6094, -0.4531, -0.3438, -0.1846,    -inf,    -inf],\n",
      "        [-0.3594,    -inf,  0.4199, -0.0593, -0.8711,  2.1406,    -inf,    -inf],\n",
      "        [ 2.0000,    -inf,  3.1250, -0.9102, -1.1719, -0.6406,    -inf,    -inf],\n",
      "        [-0.2539,    -inf,  0.7383,  0.9297, -0.2520,  0.4453,    -inf,    -inf],\n",
      "        [-1.0625,    -inf,  0.2373,  0.8281, -0.9414, -0.8516,    -inf,    -inf],\n",
      "        [-1.1953,    -inf,  2.6250, -1.4688,  0.6719, -0.3906,    -inf,    -inf],\n",
      "        [-0.5625,    -inf, -0.8984, -0.7344, -0.3184,  1.0234,    -inf,    -inf],\n",
      "        [-0.2715,    -inf, -0.0498, -0.0569, -0.3008, -0.1816,    -inf,    -inf],\n",
      "        [ 0.8633,    -inf,  2.6094, -0.4531, -0.3438, -0.1846,    -inf,    -inf],\n",
      "        [-0.3594,    -inf,  0.4199, -0.0593, -0.8711,  2.1406,    -inf,    -inf],\n",
      "        [ 2.0000,    -inf,  3.1250, -0.9102, -1.1719, -0.6406,    -inf,    -inf],\n",
      "        [-0.2539,    -inf,  0.7383,  0.9297, -0.2520,  0.4453,    -inf,    -inf],\n",
      "        [-1.0625,    -inf,  0.2373,  0.8281, -0.9414, -0.8516,    -inf,    -inf],\n",
      "        [-1.2031,    -inf,  2.4062, -1.1484,  0.8047, -0.4727,    -inf,    -inf],\n",
      "        [-0.0645,    -inf, -0.7852, -0.7656, -0.2832,  0.8320,    -inf,    -inf]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([2, 4, 5, 7])\n",
      "router_logits is tensor([[-0.0275, -0.1216,  0.1079,  0.0815,  0.0654,  0.0085,  0.5469,  0.1465],\n",
      "        [-0.2773,  1.5078, -0.7617, -0.6914,  0.3223, -0.2871, -0.5078,  1.0781],\n",
      "        [-1.3672, -1.1484,  1.9531, -1.3516,  2.0312, -0.3398,  0.1680,  0.0205],\n",
      "        [ 0.0131, -0.0092, -0.9844, -0.3125,  1.7031, -1.3750,  0.1943, -0.3984],\n",
      "        [-0.4199,  1.3359,  2.0625,  0.5508, -1.0703, -1.6641, -1.0156, -0.1826],\n",
      "        [ 0.1338, -0.2793,  1.9766, -0.4531,  0.9297, -1.5469, -0.9570, -0.3340],\n",
      "        [ 1.1328, -0.8203,  1.8125, -0.1895, -1.0859,  0.5820, -0.5547, -1.0859],\n",
      "        [-0.4941, -1.3359,  1.5156, -1.5938, -0.0334,  1.5234,  0.4238,  0.3301],\n",
      "        [-0.0275, -0.1216,  0.1079,  0.0815,  0.0654,  0.0085,  0.5469,  0.1465],\n",
      "        [-0.2773,  1.5078, -0.7617, -0.6914,  0.3223, -0.2871, -0.5078,  1.0781],\n",
      "        [-1.3672, -1.1484,  1.9531, -1.3516,  2.0312, -0.3398,  0.1680,  0.0205],\n",
      "        [ 0.0131, -0.0092, -0.9844, -0.3125,  1.7031, -1.3750,  0.1943, -0.3984],\n",
      "        [-0.4199,  1.3359,  2.0625,  0.5508, -1.0703, -1.6641, -1.0156, -0.1826],\n",
      "        [ 0.1338, -0.2793,  1.9766, -0.4531,  0.9297, -1.5469, -0.9570, -0.3340],\n",
      "        [ 1.1172, -0.4180,  1.8438, -0.2578, -1.1250,  0.4844, -0.8750, -0.8477],\n",
      "        [-0.3672, -1.4766,  1.3750, -1.5234, -0.1738,  1.2969,  0.2930,  0.8164]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[   -inf,    -inf,  0.1079,    -inf,  0.0654,  0.0085,    -inf,  0.1465],\n",
      "        [   -inf,    -inf, -0.7617,    -inf,  0.3223, -0.2871,    -inf,  1.0781],\n",
      "        [   -inf,    -inf,  1.9531,    -inf,  2.0312, -0.3398,    -inf,  0.0205],\n",
      "        [   -inf,    -inf, -0.9844,    -inf,  1.7031, -1.3750,    -inf, -0.3984],\n",
      "        [   -inf,    -inf,  2.0625,    -inf, -1.0703, -1.6641,    -inf, -0.1826],\n",
      "        [   -inf,    -inf,  1.9766,    -inf,  0.9297, -1.5469,    -inf, -0.3340],\n",
      "        [   -inf,    -inf,  1.8125,    -inf, -1.0859,  0.5820,    -inf, -1.0859],\n",
      "        [   -inf,    -inf,  1.5156,    -inf, -0.0334,  1.5234,    -inf,  0.3301],\n",
      "        [   -inf,    -inf,  0.1079,    -inf,  0.0654,  0.0085,    -inf,  0.1465],\n",
      "        [   -inf,    -inf, -0.7617,    -inf,  0.3223, -0.2871,    -inf,  1.0781],\n",
      "        [   -inf,    -inf,  1.9531,    -inf,  2.0312, -0.3398,    -inf,  0.0205],\n",
      "        [   -inf,    -inf, -0.9844,    -inf,  1.7031, -1.3750,    -inf, -0.3984],\n",
      "        [   -inf,    -inf,  2.0625,    -inf, -1.0703, -1.6641,    -inf, -0.1826],\n",
      "        [   -inf,    -inf,  1.9766,    -inf,  0.9297, -1.5469,    -inf, -0.3340],\n",
      "        [   -inf,    -inf,  1.8438,    -inf, -1.1250,  0.4844,    -inf, -0.8477],\n",
      "        [   -inf,    -inf,  1.3750,    -inf, -0.1738,  1.2969,    -inf,  0.8164]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 2, 5, 7])\n",
      "router_logits is tensor([[ 3.3398e-01,  1.3281e-01, -1.0193e-02, -8.9844e-02,  2.1875e-01,\n",
      "          2.6562e-01, -5.5859e-01,  1.3281e-01],\n",
      "        [-5.0000e-01,  3.7598e-02,  6.6406e-01,  2.0469e+00,  7.9297e-01,\n",
      "         -6.6016e-01, -5.8984e-01, -1.0391e+00],\n",
      "        [ 1.9629e-01, -5.5078e-01, -9.5312e-01,  4.9609e-01, -5.1953e-01,\n",
      "          3.6328e-01, -5.0000e-01,  1.5938e+00],\n",
      "        [-1.0107e-01, -5.8203e-01, -2.0117e-01,  2.3438e+00, -1.2031e+00,\n",
      "          1.8594e+00, -1.0391e+00, -1.0938e+00],\n",
      "        [-1.5391e+00,  1.8203e+00, -2.2461e-01,  1.4688e+00, -9.2188e-01,\n",
      "         -1.7578e+00, -1.2344e+00,  2.4062e+00],\n",
      "        [ 1.3359e+00,  9.3750e-02, -4.1992e-01, -1.1768e-01, -3.1250e-01,\n",
      "          4.3555e-01, -4.5395e-04, -1.0781e+00],\n",
      "        [-3.2812e-01,  1.4688e+00, -3.9844e-01,  1.6562e+00, -9.5703e-01,\n",
      "         -1.3125e+00, -1.1797e+00,  1.1250e+00],\n",
      "        [ 4.8242e-01,  7.8906e-01,  1.2188e+00, -1.2734e+00, -7.1289e-02,\n",
      "         -1.2598e-01,  5.6250e-01, -1.0469e+00],\n",
      "        [ 3.3398e-01,  1.3281e-01, -1.0193e-02, -8.9844e-02,  2.1875e-01,\n",
      "          2.6562e-01, -5.5859e-01,  1.3281e-01],\n",
      "        [-5.0000e-01,  3.7598e-02,  6.6406e-01,  2.0469e+00,  7.9297e-01,\n",
      "         -6.6016e-01, -5.8984e-01, -1.0391e+00],\n",
      "        [ 1.9629e-01, -5.5078e-01, -9.5312e-01,  4.9609e-01, -5.1953e-01,\n",
      "          3.6328e-01, -5.0000e-01,  1.5938e+00],\n",
      "        [-1.0107e-01, -5.8203e-01, -2.0117e-01,  2.3438e+00, -1.2031e+00,\n",
      "          1.8594e+00, -1.0391e+00, -1.0938e+00],\n",
      "        [-1.5391e+00,  1.8203e+00, -2.2461e-01,  1.4688e+00, -9.2188e-01,\n",
      "         -1.7578e+00, -1.2344e+00,  2.4062e+00],\n",
      "        [ 1.3359e+00,  9.3750e-02, -4.1992e-01, -1.1768e-01, -3.1250e-01,\n",
      "          4.3555e-01, -4.5395e-04, -1.0781e+00],\n",
      "        [-9.8047e-01,  1.7734e+00, -1.5527e-01,  1.1562e+00, -5.8594e-01,\n",
      "         -9.5703e-01, -1.2266e+00,  9.7656e-01],\n",
      "        [ 6.4844e-01,  3.2031e-01,  1.3125e+00, -8.3594e-01, -1.0315e-02,\n",
      "         -6.6895e-02,  8.0859e-01, -1.4609e+00]], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[ 0.3340,    -inf, -0.0102,    -inf,    -inf,  0.2656,    -inf,  0.1328],\n",
      "        [-0.5000,    -inf,  0.6641,    -inf,    -inf, -0.6602,    -inf, -1.0391],\n",
      "        [ 0.1963,    -inf, -0.9531,    -inf,    -inf,  0.3633,    -inf,  1.5938],\n",
      "        [-0.1011,    -inf, -0.2012,    -inf,    -inf,  1.8594,    -inf, -1.0938],\n",
      "        [-1.5391,    -inf, -0.2246,    -inf,    -inf, -1.7578,    -inf,  2.4062],\n",
      "        [ 1.3359,    -inf, -0.4199,    -inf,    -inf,  0.4355,    -inf, -1.0781],\n",
      "        [-0.3281,    -inf, -0.3984,    -inf,    -inf, -1.3125,    -inf,  1.1250],\n",
      "        [ 0.4824,    -inf,  1.2188,    -inf,    -inf, -0.1260,    -inf, -1.0469],\n",
      "        [ 0.3340,    -inf, -0.0102,    -inf,    -inf,  0.2656,    -inf,  0.1328],\n",
      "        [-0.5000,    -inf,  0.6641,    -inf,    -inf, -0.6602,    -inf, -1.0391],\n",
      "        [ 0.1963,    -inf, -0.9531,    -inf,    -inf,  0.3633,    -inf,  1.5938],\n",
      "        [-0.1011,    -inf, -0.2012,    -inf,    -inf,  1.8594,    -inf, -1.0938],\n",
      "        [-1.5391,    -inf, -0.2246,    -inf,    -inf, -1.7578,    -inf,  2.4062],\n",
      "        [ 1.3359,    -inf, -0.4199,    -inf,    -inf,  0.4355,    -inf, -1.0781],\n",
      "        [-0.9805,    -inf, -0.1553,    -inf,    -inf, -0.9570,    -inf,  0.9766],\n",
      "        [ 0.6484,    -inf,  1.3125,    -inf,    -inf, -0.0669,    -inf, -1.4609]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([1, 3, 5, 6, 7])\n",
      "router_logits is tensor([[ 0.2617, -0.0562,  0.2217,  0.1406, -0.2207, -0.1128, -0.1206, -0.2363],\n",
      "        [ 1.0938, -0.6484, -0.3691,  0.9805, -0.5195,  0.4277, -0.3887, -0.0996],\n",
      "        [ 1.1719,  0.4316, -0.8945, -0.8086, -0.5273,  0.6211,  1.0312, -1.1562],\n",
      "        [ 2.7969, -0.7891, -1.5938, -1.4844, -0.2256,  1.8984, -0.8047,  0.3145],\n",
      "        [ 0.3691,  0.1299, -2.5156, -0.5352, -0.0547,  1.8906, -0.7891,  1.4766],\n",
      "        [ 0.1182,  2.1406, -2.6406, -0.1914, -0.3359,  0.9648,  1.1172, -1.2422],\n",
      "        [ 0.0437,  0.1396, -1.2109,  1.1172,  0.0618, -1.5000,  1.3750, -0.3477],\n",
      "        [-0.9336,  2.1562, -0.0184, -0.8516,  3.0938, -0.5352, -0.4746, -1.8594],\n",
      "        [ 0.2617, -0.0562,  0.2217,  0.1406, -0.2207, -0.1128, -0.1206, -0.2363],\n",
      "        [ 1.0938, -0.6484, -0.3691,  0.9805, -0.5195,  0.4277, -0.3887, -0.0996],\n",
      "        [ 1.1719,  0.4316, -0.8945, -0.8086, -0.5273,  0.6211,  1.0312, -1.1562],\n",
      "        [ 2.7969, -0.7891, -1.5938, -1.4844, -0.2256,  1.8984, -0.8047,  0.3145],\n",
      "        [ 0.3691,  0.1299, -2.5156, -0.5352, -0.0547,  1.8906, -0.7891,  1.4766],\n",
      "        [ 0.1182,  2.1406, -2.6406, -0.1914, -0.3359,  0.9648,  1.1172, -1.2422],\n",
      "        [ 0.1553,  0.5742, -1.1641,  1.0234,  0.0076, -1.2891,  1.1641, -0.6836],\n",
      "        [-1.0547,  2.0469, -0.1670, -0.5078,  2.2188, -0.1123, -0.6836, -1.1172]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[   -inf, -0.0562,    -inf,  0.1406,    -inf, -0.1128, -0.1206, -0.2363],\n",
      "        [   -inf, -0.6484,    -inf,  0.9805,    -inf,  0.4277, -0.3887, -0.0996],\n",
      "        [   -inf,  0.4316,    -inf, -0.8086,    -inf,  0.6211,  1.0312, -1.1562],\n",
      "        [   -inf, -0.7891,    -inf, -1.4844,    -inf,  1.8984, -0.8047,  0.3145],\n",
      "        [   -inf,  0.1299,    -inf, -0.5352,    -inf,  1.8906, -0.7891,  1.4766],\n",
      "        [   -inf,  2.1406,    -inf, -0.1914,    -inf,  0.9648,  1.1172, -1.2422],\n",
      "        [   -inf,  0.1396,    -inf,  1.1172,    -inf, -1.5000,  1.3750, -0.3477],\n",
      "        [   -inf,  2.1562,    -inf, -0.8516,    -inf, -0.5352, -0.4746, -1.8594],\n",
      "        [   -inf, -0.0562,    -inf,  0.1406,    -inf, -0.1128, -0.1206, -0.2363],\n",
      "        [   -inf, -0.6484,    -inf,  0.9805,    -inf,  0.4277, -0.3887, -0.0996],\n",
      "        [   -inf,  0.4316,    -inf, -0.8086,    -inf,  0.6211,  1.0312, -1.1562],\n",
      "        [   -inf, -0.7891,    -inf, -1.4844,    -inf,  1.8984, -0.8047,  0.3145],\n",
      "        [   -inf,  0.1299,    -inf, -0.5352,    -inf,  1.8906, -0.7891,  1.4766],\n",
      "        [   -inf,  2.1406,    -inf, -0.1914,    -inf,  0.9648,  1.1172, -1.2422],\n",
      "        [   -inf,  0.5742,    -inf,  1.0234,    -inf, -1.2891,  1.1641, -0.6836],\n",
      "        [   -inf,  2.0469,    -inf, -0.5078,    -inf, -0.1123, -0.6836, -1.1172]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 3, 5, 6, 7])\n",
      "router_logits is tensor([[ 1.7188e-01,  2.9688e-01, -8.0078e-02,  7.6599e-03, -1.0010e-02,\n",
      "          2.6172e-01,  2.1387e-01, -2.0874e-02],\n",
      "        [-1.1084e-01,  3.6328e-01, -9.0332e-02,  1.5234e+00,  1.2500e+00,\n",
      "         -4.4336e-01, -1.4375e+00, -4.7656e-01],\n",
      "        [-2.7930e-01, -3.3008e-01, -9.6191e-02, -5.4688e-01, -8.3203e-01,\n",
      "          7.6562e-01,  1.9062e+00,  2.4023e-01],\n",
      "        [ 1.0234e+00, -1.1328e+00, -5.8594e-01,  1.7734e+00, -4.2188e-01,\n",
      "          1.5717e-03,  5.4297e-01, -6.4453e-01],\n",
      "        [-2.5469e+00,  3.1875e+00,  1.0781e+00, -1.1016e+00, -6.7188e-01,\n",
      "         -1.9375e+00,  2.2500e+00, -5.3125e-01],\n",
      "        [-1.0625e+00,  2.6406e+00,  1.3672e-01, -1.3906e+00, -3.4961e-01,\n",
      "          9.1797e-01, -2.3633e-01, -7.2656e-01],\n",
      "        [-1.7266e+00,  7.3047e-01, -3.8477e-01,  1.6875e+00, -9.4238e-02,\n",
      "         -5.0391e-01,  6.2891e-01, -3.4961e-01],\n",
      "        [-1.6484e+00,  1.6094e+00,  1.0391e+00, -7.2266e-01,  1.0312e+00,\n",
      "          1.8555e-01,  7.9590e-02, -1.1641e+00],\n",
      "        [ 1.7188e-01,  2.9688e-01, -8.0078e-02,  7.6599e-03, -1.0010e-02,\n",
      "          2.6172e-01,  2.1387e-01, -2.0874e-02],\n",
      "        [-1.1084e-01,  3.6328e-01, -9.0332e-02,  1.5234e+00,  1.2500e+00,\n",
      "         -4.4336e-01, -1.4375e+00, -4.7656e-01],\n",
      "        [-2.7930e-01, -3.3008e-01, -9.6191e-02, -5.4688e-01, -8.3203e-01,\n",
      "          7.6562e-01,  1.9062e+00,  2.4023e-01],\n",
      "        [ 1.0234e+00, -1.1328e+00, -5.8594e-01,  1.7734e+00, -4.2188e-01,\n",
      "          1.5717e-03,  5.4297e-01, -6.4453e-01],\n",
      "        [-2.5469e+00,  3.1875e+00,  1.0781e+00, -1.1016e+00, -6.7188e-01,\n",
      "         -1.9375e+00,  2.2500e+00, -5.3125e-01],\n",
      "        [-1.0625e+00,  2.6406e+00,  1.3672e-01, -1.3906e+00, -3.4961e-01,\n",
      "          9.1797e-01, -2.3633e-01, -7.2656e-01],\n",
      "        [-1.4062e+00,  4.8828e-01, -7.8125e-01,  1.1406e+00,  5.9375e-01,\n",
      "         -4.1406e-01,  3.5352e-01, -4.4922e-02],\n",
      "        [-1.6406e+00,  1.6484e+00,  6.1328e-01, -5.0781e-01,  7.2266e-01,\n",
      "          3.0469e-01, -1.3965e-01, -6.0156e-01]], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[ 1.7188e-01,        -inf,        -inf,  7.6599e-03,        -inf,\n",
      "          2.6172e-01,  2.1387e-01, -2.0874e-02],\n",
      "        [-1.1084e-01,        -inf,        -inf,  1.5234e+00,        -inf,\n",
      "         -4.4336e-01, -1.4375e+00, -4.7656e-01],\n",
      "        [-2.7930e-01,        -inf,        -inf, -5.4688e-01,        -inf,\n",
      "          7.6562e-01,  1.9062e+00,  2.4023e-01],\n",
      "        [ 1.0234e+00,        -inf,        -inf,  1.7734e+00,        -inf,\n",
      "          1.5717e-03,  5.4297e-01, -6.4453e-01],\n",
      "        [-2.5469e+00,        -inf,        -inf, -1.1016e+00,        -inf,\n",
      "         -1.9375e+00,  2.2500e+00, -5.3125e-01],\n",
      "        [-1.0625e+00,        -inf,        -inf, -1.3906e+00,        -inf,\n",
      "          9.1797e-01, -2.3633e-01, -7.2656e-01],\n",
      "        [-1.7266e+00,        -inf,        -inf,  1.6875e+00,        -inf,\n",
      "         -5.0391e-01,  6.2891e-01, -3.4961e-01],\n",
      "        [-1.6484e+00,        -inf,        -inf, -7.2266e-01,        -inf,\n",
      "          1.8555e-01,  7.9590e-02, -1.1641e+00],\n",
      "        [ 1.7188e-01,        -inf,        -inf,  7.6599e-03,        -inf,\n",
      "          2.6172e-01,  2.1387e-01, -2.0874e-02],\n",
      "        [-1.1084e-01,        -inf,        -inf,  1.5234e+00,        -inf,\n",
      "         -4.4336e-01, -1.4375e+00, -4.7656e-01],\n",
      "        [-2.7930e-01,        -inf,        -inf, -5.4688e-01,        -inf,\n",
      "          7.6562e-01,  1.9062e+00,  2.4023e-01],\n",
      "        [ 1.0234e+00,        -inf,        -inf,  1.7734e+00,        -inf,\n",
      "          1.5717e-03,  5.4297e-01, -6.4453e-01],\n",
      "        [-2.5469e+00,        -inf,        -inf, -1.1016e+00,        -inf,\n",
      "         -1.9375e+00,  2.2500e+00, -5.3125e-01],\n",
      "        [-1.0625e+00,        -inf,        -inf, -1.3906e+00,        -inf,\n",
      "          9.1797e-01, -2.3633e-01, -7.2656e-01],\n",
      "        [-1.4062e+00,        -inf,        -inf,  1.1406e+00,        -inf,\n",
      "         -4.1406e-01,  3.5352e-01, -4.4922e-02],\n",
      "        [-1.6406e+00,        -inf,        -inf, -5.0781e-01,        -inf,\n",
      "          3.0469e-01, -1.3965e-01, -6.0156e-01]], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([4, 5, 6, 7])\n",
      "router_logits is tensor([[ 0.0586,  0.1680, -0.0481,  0.3652,  0.0264,  0.2637, -0.0349,  0.2275],\n",
      "        [-0.4316,  0.4043,  0.9180, -0.3711, -0.0302,  0.4121, -0.4785,  0.2109],\n",
      "        [-1.1016,  0.1895,  0.8516, -0.7695, -0.4434, -0.6562,  0.9805,  1.7734],\n",
      "        [-1.4844,  1.7734, -0.6211, -0.5508,  1.4844, -0.5938, -1.3672,  1.5781],\n",
      "        [-1.2734,  2.4688, -0.7969,  1.1641, -0.2354, -0.1602,  0.8125, -1.6797],\n",
      "        [-0.7461,  0.0080,  1.4141, -0.8438,  0.1650,  0.2949, -0.2891,  0.1128],\n",
      "        [-0.0046,  0.5781, -0.2871, -1.2109, -0.2480, -0.2617,  1.8281, -0.7812],\n",
      "        [-0.5703, -0.4727, -0.3242,  0.1465,  0.7070,  0.8906,  1.1094, -0.9922],\n",
      "        [ 0.0586,  0.1680, -0.0481,  0.3652,  0.0264,  0.2637, -0.0349,  0.2275],\n",
      "        [-0.4316,  0.4043,  0.9180, -0.3711, -0.0302,  0.4121, -0.4785,  0.2109],\n",
      "        [-1.1016,  0.1895,  0.8516, -0.7695, -0.4434, -0.6562,  0.9805,  1.7734],\n",
      "        [-1.4844,  1.7734, -0.6211, -0.5508,  1.4844, -0.5938, -1.3672,  1.5781],\n",
      "        [-1.2734,  2.4688, -0.7969,  1.1641, -0.2354, -0.1602,  0.8125, -1.6797],\n",
      "        [-0.7461,  0.0080,  1.4141, -0.8438,  0.1650,  0.2949, -0.2891,  0.1128],\n",
      "        [-0.4160,  0.9453, -0.4414, -0.9375,  0.5547, -0.4492,  1.6797, -0.9453],\n",
      "        [-0.6250, -0.2832,  0.2754,  0.0693,  0.2715,  0.6523,  0.6055, -0.3379]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[   -inf,    -inf,    -inf,    -inf,  0.0264,  0.2637, -0.0349,  0.2275],\n",
      "        [   -inf,    -inf,    -inf,    -inf, -0.0302,  0.4121, -0.4785,  0.2109],\n",
      "        [   -inf,    -inf,    -inf,    -inf, -0.4434, -0.6562,  0.9805,  1.7734],\n",
      "        [   -inf,    -inf,    -inf,    -inf,  1.4844, -0.5938, -1.3672,  1.5781],\n",
      "        [   -inf,    -inf,    -inf,    -inf, -0.2354, -0.1602,  0.8125, -1.6797],\n",
      "        [   -inf,    -inf,    -inf,    -inf,  0.1650,  0.2949, -0.2891,  0.1128],\n",
      "        [   -inf,    -inf,    -inf,    -inf, -0.2480, -0.2617,  1.8281, -0.7812],\n",
      "        [   -inf,    -inf,    -inf,    -inf,  0.7070,  0.8906,  1.1094, -0.9922],\n",
      "        [   -inf,    -inf,    -inf,    -inf,  0.0264,  0.2637, -0.0349,  0.2275],\n",
      "        [   -inf,    -inf,    -inf,    -inf, -0.0302,  0.4121, -0.4785,  0.2109],\n",
      "        [   -inf,    -inf,    -inf,    -inf, -0.4434, -0.6562,  0.9805,  1.7734],\n",
      "        [   -inf,    -inf,    -inf,    -inf,  1.4844, -0.5938, -1.3672,  1.5781],\n",
      "        [   -inf,    -inf,    -inf,    -inf, -0.2354, -0.1602,  0.8125, -1.6797],\n",
      "        [   -inf,    -inf,    -inf,    -inf,  0.1650,  0.2949, -0.2891,  0.1128],\n",
      "        [   -inf,    -inf,    -inf,    -inf,  0.5547, -0.4492,  1.6797, -0.9453],\n",
      "        [   -inf,    -inf,    -inf,    -inf,  0.2715,  0.6523,  0.6055, -0.3379]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 1, 3, 4, 5, 6])\n",
      "router_logits is tensor([[ 0.0118,  0.0574, -0.2295,  0.0767, -0.2256,  0.1235,  0.1729, -0.4219],\n",
      "        [-0.3398,  0.3027,  0.5469, -0.6914,  1.7422,  0.0913, -0.4258, -0.4961],\n",
      "        [-0.3652, -0.9180, -0.4570,  1.9766,  1.0938, -1.2969,  0.0625,  1.0781],\n",
      "        [ 0.7305,  1.4062,  0.7305,  0.8672, -0.3711, -0.5312, -1.0859, -1.1641],\n",
      "        [-0.9297, -1.6328,  0.3359,  0.4414, -1.7188, -1.1562,  4.2188,  0.7930],\n",
      "        [ 0.8203, -0.3066, -0.5430, -0.8320,  0.3906, -0.5781, -0.3184,  2.2500],\n",
      "        [-0.5234, -0.4648,  0.2148, -1.1484,  0.6719,  0.3770, -0.2285,  1.7109],\n",
      "        [-0.4922, -0.0894, -0.8164, -0.2197,  0.2793,  0.6367, -0.2617,  1.8438],\n",
      "        [ 0.0118,  0.0574, -0.2295,  0.0767, -0.2256,  0.1235,  0.1729, -0.4219],\n",
      "        [-0.3398,  0.3027,  0.5469, -0.6914,  1.7422,  0.0913, -0.4258, -0.4961],\n",
      "        [-0.3652, -0.9180, -0.4570,  1.9766,  1.0938, -1.2969,  0.0625,  1.0781],\n",
      "        [ 0.7305,  1.4062,  0.7305,  0.8672, -0.3711, -0.5312, -1.0859, -1.1641],\n",
      "        [-0.9297, -1.6328,  0.3359,  0.4414, -1.7188, -1.1562,  4.2188,  0.7930],\n",
      "        [ 0.8203, -0.3066, -0.5430, -0.8320,  0.3906, -0.5781, -0.3184,  2.2500],\n",
      "        [-1.0547, -0.4219,  0.3398, -0.8047,  0.3867,  0.6758,  0.2871,  1.3516],\n",
      "        [ 0.1016, -0.2578, -0.5469, -0.3477,  0.3984,  0.6211, -0.8633,  1.8438]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[ 0.0118,  0.0574,    -inf,  0.0767, -0.2256,  0.1235,  0.1729,    -inf],\n",
      "        [-0.3398,  0.3027,    -inf, -0.6914,  1.7422,  0.0913, -0.4258,    -inf],\n",
      "        [-0.3652, -0.9180,    -inf,  1.9766,  1.0938, -1.2969,  0.0625,    -inf],\n",
      "        [ 0.7305,  1.4062,    -inf,  0.8672, -0.3711, -0.5312, -1.0859,    -inf],\n",
      "        [-0.9297, -1.6328,    -inf,  0.4414, -1.7188, -1.1562,  4.2188,    -inf],\n",
      "        [ 0.8203, -0.3066,    -inf, -0.8320,  0.3906, -0.5781, -0.3184,    -inf],\n",
      "        [-0.5234, -0.4648,    -inf, -1.1484,  0.6719,  0.3770, -0.2285,    -inf],\n",
      "        [-0.4922, -0.0894,    -inf, -0.2197,  0.2793,  0.6367, -0.2617,    -inf],\n",
      "        [ 0.0118,  0.0574,    -inf,  0.0767, -0.2256,  0.1235,  0.1729,    -inf],\n",
      "        [-0.3398,  0.3027,    -inf, -0.6914,  1.7422,  0.0913, -0.4258,    -inf],\n",
      "        [-0.3652, -0.9180,    -inf,  1.9766,  1.0938, -1.2969,  0.0625,    -inf],\n",
      "        [ 0.7305,  1.4062,    -inf,  0.8672, -0.3711, -0.5312, -1.0859,    -inf],\n",
      "        [-0.9297, -1.6328,    -inf,  0.4414, -1.7188, -1.1562,  4.2188,    -inf],\n",
      "        [ 0.8203, -0.3066,    -inf, -0.8320,  0.3906, -0.5781, -0.3184,    -inf],\n",
      "        [-1.0547, -0.4219,    -inf, -0.8047,  0.3867,  0.6758,  0.2871,    -inf],\n",
      "        [ 0.1016, -0.2578,    -inf, -0.3477,  0.3984,  0.6211, -0.8633,    -inf]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 1, 4, 5])\n",
      "router_logits is tensor([[-9.9121e-02,  2.5977e-01, -1.6016e-01, -1.3965e-01, -1.6504e-01,\n",
      "         -1.0254e-01,  2.3438e-01, -3.9258e-01],\n",
      "        [ 2.7100e-02,  3.1445e-01, -5.5469e-01,  1.1914e-01,  2.2852e-01,\n",
      "          3.0859e-01, -1.2891e-01,  3.7695e-01],\n",
      "        [-9.6875e-01,  1.0625e+00, -1.8652e-01,  3.2196e-03, -1.0312e+00,\n",
      "          2.7812e+00, -1.3438e+00,  3.5742e-01],\n",
      "        [-7.5781e-01,  3.0781e+00, -1.3047e+00, -1.6094e+00,  2.0801e-01,\n",
      "          1.1406e+00, -2.8516e-01, -5.5469e-01],\n",
      "        [ 4.2188e+00, -6.7969e-01,  5.8203e-01, -1.3203e+00,  2.3145e-01,\n",
      "         -6.0547e-01, -4.8828e-01, -2.6562e+00],\n",
      "        [ 4.8584e-02, -2.0996e-01, -2.5391e-01,  2.1406e+00, -1.9238e-01,\n",
      "          5.7422e-01, -5.9766e-01, -7.1094e-01],\n",
      "        [-3.1055e-01,  1.2891e+00,  5.6396e-02, -1.2266e+00,  1.2422e+00,\n",
      "         -3.5547e-01,  1.7480e-01, -2.6758e-01],\n",
      "        [ 1.7734e+00,  5.1953e-01,  5.2344e-01,  6.6406e-02, -1.0781e+00,\n",
      "          3.4375e-01,  6.7188e-01, -1.6172e+00],\n",
      "        [-9.9121e-02,  2.5977e-01, -1.6016e-01, -1.3965e-01, -1.6504e-01,\n",
      "         -1.0254e-01,  2.3438e-01, -3.9258e-01],\n",
      "        [ 2.7100e-02,  3.1445e-01, -5.5469e-01,  1.1914e-01,  2.2852e-01,\n",
      "          3.0859e-01, -1.2891e-01,  3.7695e-01],\n",
      "        [-9.6875e-01,  1.0625e+00, -1.8652e-01,  3.2196e-03, -1.0312e+00,\n",
      "          2.7812e+00, -1.3438e+00,  3.5742e-01],\n",
      "        [-7.5781e-01,  3.0781e+00, -1.3047e+00, -1.6094e+00,  2.0801e-01,\n",
      "          1.1406e+00, -2.8516e-01, -5.5469e-01],\n",
      "        [ 4.2188e+00, -6.7969e-01,  5.8203e-01, -1.3203e+00,  2.3145e-01,\n",
      "         -6.0547e-01, -4.8828e-01, -2.6562e+00],\n",
      "        [ 4.8584e-02, -2.0996e-01, -2.5391e-01,  2.1406e+00, -1.9238e-01,\n",
      "          5.7422e-01, -5.9766e-01, -7.1094e-01],\n",
      "        [-9.7656e-02,  7.1484e-01, -4.8242e-01, -6.8750e-01,  1.5859e+00,\n",
      "         -6.4453e-01, -1.3770e-01,  5.2734e-01],\n",
      "        [ 1.6172e+00,  3.5547e-01,  4.5312e-01,  2.4121e-01, -5.6641e-01,\n",
      "          7.0312e-02,  9.7656e-02, -1.1875e+00]], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[-0.0991,  0.2598,    -inf,    -inf, -0.1650, -0.1025,    -inf,    -inf],\n",
      "        [ 0.0271,  0.3145,    -inf,    -inf,  0.2285,  0.3086,    -inf,    -inf],\n",
      "        [-0.9688,  1.0625,    -inf,    -inf, -1.0312,  2.7812,    -inf,    -inf],\n",
      "        [-0.7578,  3.0781,    -inf,    -inf,  0.2080,  1.1406,    -inf,    -inf],\n",
      "        [ 4.2188, -0.6797,    -inf,    -inf,  0.2314, -0.6055,    -inf,    -inf],\n",
      "        [ 0.0486, -0.2100,    -inf,    -inf, -0.1924,  0.5742,    -inf,    -inf],\n",
      "        [-0.3105,  1.2891,    -inf,    -inf,  1.2422, -0.3555,    -inf,    -inf],\n",
      "        [ 1.7734,  0.5195,    -inf,    -inf, -1.0781,  0.3438,    -inf,    -inf],\n",
      "        [-0.0991,  0.2598,    -inf,    -inf, -0.1650, -0.1025,    -inf,    -inf],\n",
      "        [ 0.0271,  0.3145,    -inf,    -inf,  0.2285,  0.3086,    -inf,    -inf],\n",
      "        [-0.9688,  1.0625,    -inf,    -inf, -1.0312,  2.7812,    -inf,    -inf],\n",
      "        [-0.7578,  3.0781,    -inf,    -inf,  0.2080,  1.1406,    -inf,    -inf],\n",
      "        [ 4.2188, -0.6797,    -inf,    -inf,  0.2314, -0.6055,    -inf,    -inf],\n",
      "        [ 0.0486, -0.2100,    -inf,    -inf, -0.1924,  0.5742,    -inf,    -inf],\n",
      "        [-0.0977,  0.7148,    -inf,    -inf,  1.5859, -0.6445,    -inf,    -inf],\n",
      "        [ 1.6172,  0.3555,    -inf,    -inf, -0.5664,  0.0703,    -inf,    -inf]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([1, 2, 3, 4, 5, 7])\n",
      "router_logits is tensor([[-0.2471, -0.2988,  0.2070,  0.3867,  0.1338,  0.1533, -0.6289,  0.0923],\n",
      "        [ 1.2656, -0.2949, -0.7344, -0.8008, -0.7305,  0.6562,  1.3594, -0.6836],\n",
      "        [ 1.2578, -1.1094, -0.4844, -0.0496, -1.0156,  0.3516,  1.5000,  0.1079],\n",
      "        [-0.6445, -1.5469,  0.2393,  3.0156, -2.0312,  0.4668,  2.2188, -1.9141],\n",
      "        [-0.2393, -0.1504, -2.0312, -0.2402,  2.5156, -1.0000,  0.0496, -0.0718],\n",
      "        [ 0.5430, -0.0449, -0.6328,  0.9414, -0.2988, -0.0996, -0.4375,  0.2812],\n",
      "        [ 0.0188,  2.1562, -0.3984,  0.0258, -0.8008, -0.1699,  0.2080, -1.6094],\n",
      "        [ 1.7344, -1.1016,  0.7695,  0.3125, -0.4043,  0.6875, -0.6445, -0.5859],\n",
      "        [-0.2471, -0.2988,  0.2070,  0.3867,  0.1338,  0.1533, -0.6289,  0.0923],\n",
      "        [ 1.2656, -0.2949, -0.7344, -0.8008, -0.7305,  0.6562,  1.3594, -0.6836],\n",
      "        [ 1.2578, -1.1094, -0.4844, -0.0496, -1.0156,  0.3516,  1.5000,  0.1079],\n",
      "        [-0.6445, -1.5469,  0.2393,  3.0156, -2.0312,  0.4668,  2.2188, -1.9141],\n",
      "        [-0.2393, -0.1504, -2.0312, -0.2402,  2.5156, -1.0000,  0.0496, -0.0718],\n",
      "        [ 0.5430, -0.0449, -0.6328,  0.9414, -0.2988, -0.0996, -0.4375,  0.2812],\n",
      "        [-0.1729,  2.3281, -0.5664, -0.4961, -0.0908, -0.0771,  0.2383, -1.5547],\n",
      "        [ 0.6953, -0.7852,  0.5430,  0.3301, -0.1455,  1.1328, -0.4785, -0.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[   -inf, -0.2988,  0.2070,  0.3867,  0.1338,  0.1533,    -inf,  0.0923],\n",
      "        [   -inf, -0.2949, -0.7344, -0.8008, -0.7305,  0.6562,    -inf, -0.6836],\n",
      "        [   -inf, -1.1094, -0.4844, -0.0496, -1.0156,  0.3516,    -inf,  0.1079],\n",
      "        [   -inf, -1.5469,  0.2393,  3.0156, -2.0312,  0.4668,    -inf, -1.9141],\n",
      "        [   -inf, -0.1504, -2.0312, -0.2402,  2.5156, -1.0000,    -inf, -0.0718],\n",
      "        [   -inf, -0.0449, -0.6328,  0.9414, -0.2988, -0.0996,    -inf,  0.2812],\n",
      "        [   -inf,  2.1562, -0.3984,  0.0258, -0.8008, -0.1699,    -inf, -1.6094],\n",
      "        [   -inf, -1.1016,  0.7695,  0.3125, -0.4043,  0.6875,    -inf, -0.5859],\n",
      "        [   -inf, -0.2988,  0.2070,  0.3867,  0.1338,  0.1533,    -inf,  0.0923],\n",
      "        [   -inf, -0.2949, -0.7344, -0.8008, -0.7305,  0.6562,    -inf, -0.6836],\n",
      "        [   -inf, -1.1094, -0.4844, -0.0496, -1.0156,  0.3516,    -inf,  0.1079],\n",
      "        [   -inf, -1.5469,  0.2393,  3.0156, -2.0312,  0.4668,    -inf, -1.9141],\n",
      "        [   -inf, -0.1504, -2.0312, -0.2402,  2.5156, -1.0000,    -inf, -0.0718],\n",
      "        [   -inf, -0.0449, -0.6328,  0.9414, -0.2988, -0.0996,    -inf,  0.2812],\n",
      "        [   -inf,  2.3281, -0.5664, -0.4961, -0.0908, -0.0771,    -inf, -1.5547],\n",
      "        [   -inf, -0.7852,  0.5430,  0.3301, -0.1455,  1.1328,    -inf, -0.3359]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 1, 2, 5, 7])\n",
      "router_logits is tensor([[-0.2539, -0.0869,  0.1982,  0.0952,  0.0830,  0.1309,  0.0957,  0.1543],\n",
      "        [ 1.4453, -0.0201,  1.2031, -0.1670, -0.2832, -0.2988, -0.6523, -0.5195],\n",
      "        [ 1.7422,  1.0469, -0.4727,  0.0508, -0.4395, -0.4238, -0.1582, -0.2441],\n",
      "        [ 0.5352,  0.1138, -0.1826, -0.6602, -0.7773,  1.7812,  0.0864, -0.5430],\n",
      "        [ 1.5234,  0.1357, -0.9609, -1.1016, -1.8359, -0.1934,  0.5469,  2.0156],\n",
      "        [-0.7734, -0.6406, -1.2422, -0.0295,  0.8633, -0.3887,  1.7969,  1.1094],\n",
      "        [ 1.3438,  0.0713,  0.7227,  1.0391, -1.2734, -0.5469, -0.6523, -0.8047],\n",
      "        [-1.1641,  1.2734, -0.8945, -0.2354,  0.5195, -0.8125,  0.1157,  2.0000],\n",
      "        [-0.2539, -0.0869,  0.1982,  0.0952,  0.0830,  0.1309,  0.0957,  0.1543],\n",
      "        [ 1.4453, -0.0201,  1.2031, -0.1670, -0.2832, -0.2988, -0.6523, -0.5195],\n",
      "        [ 1.7422,  1.0469, -0.4727,  0.0508, -0.4395, -0.4238, -0.1582, -0.2441],\n",
      "        [ 0.5352,  0.1138, -0.1826, -0.6602, -0.7773,  1.7812,  0.0864, -0.5430],\n",
      "        [ 1.5234,  0.1357, -0.9609, -1.1016, -1.8359, -0.1934,  0.5469,  2.0156],\n",
      "        [-0.7734, -0.6406, -1.2422, -0.0295,  0.8633, -0.3887,  1.7969,  1.1094],\n",
      "        [ 1.5078, -0.0062,  0.1045,  1.0938, -1.5312, -0.0374, -0.1699, -0.7031],\n",
      "        [-0.7852,  0.8945, -0.6055, -0.3672,  0.0486, -1.2188,  0.8164,  1.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[-0.2539, -0.0869,  0.1982,    -inf,    -inf,  0.1309,    -inf,  0.1543],\n",
      "        [ 1.4453, -0.0201,  1.2031,    -inf,    -inf, -0.2988,    -inf, -0.5195],\n",
      "        [ 1.7422,  1.0469, -0.4727,    -inf,    -inf, -0.4238,    -inf, -0.2441],\n",
      "        [ 0.5352,  0.1138, -0.1826,    -inf,    -inf,  1.7812,    -inf, -0.5430],\n",
      "        [ 1.5234,  0.1357, -0.9609,    -inf,    -inf, -0.1934,    -inf,  2.0156],\n",
      "        [-0.7734, -0.6406, -1.2422,    -inf,    -inf, -0.3887,    -inf,  1.1094],\n",
      "        [ 1.3438,  0.0713,  0.7227,    -inf,    -inf, -0.5469,    -inf, -0.8047],\n",
      "        [-1.1641,  1.2734, -0.8945,    -inf,    -inf, -0.8125,    -inf,  2.0000],\n",
      "        [-0.2539, -0.0869,  0.1982,    -inf,    -inf,  0.1309,    -inf,  0.1543],\n",
      "        [ 1.4453, -0.0201,  1.2031,    -inf,    -inf, -0.2988,    -inf, -0.5195],\n",
      "        [ 1.7422,  1.0469, -0.4727,    -inf,    -inf, -0.4238,    -inf, -0.2441],\n",
      "        [ 0.5352,  0.1138, -0.1826,    -inf,    -inf,  1.7812,    -inf, -0.5430],\n",
      "        [ 1.5234,  0.1357, -0.9609,    -inf,    -inf, -0.1934,    -inf,  2.0156],\n",
      "        [-0.7734, -0.6406, -1.2422,    -inf,    -inf, -0.3887,    -inf,  1.1094],\n",
      "        [ 1.5078, -0.0062,  0.1045,    -inf,    -inf, -0.0374,    -inf, -0.7031],\n",
      "        [-0.7852,  0.8945, -0.6055,    -inf,    -inf, -1.2188,    -inf,  1.9844]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([1, 3, 4, 5, 7])\n",
      "router_logits is tensor([[-0.1177, -0.3086,  0.9141, -0.4375,  0.3809, -0.6211,  0.0859, -0.0369],\n",
      "        [-0.6484,  0.3926,  1.4609, -1.1172,  0.2656,  0.5781,  0.6641, -1.0156],\n",
      "        [ 0.5156,  0.7227,  0.0757,  0.6172, -1.2188, -1.4922,  1.7109, -0.7930],\n",
      "        [ 1.1328,  2.1094,  0.6953,  0.2656, -1.6797, -2.1719,  1.0703, -1.2578],\n",
      "        [ 1.1250, -0.7930, -0.2080, -1.3359,  1.0234,  2.3125, -0.2119, -1.5078],\n",
      "        [ 0.3789,  0.5039,  1.5547,  0.3867, -1.5703, -0.2773, -0.5469, -0.3672],\n",
      "        [ 0.3730, -0.3184, -0.2363, -0.1279,  1.1641,  0.5664, -1.3203, -0.6172],\n",
      "        [ 0.4297, -0.4082,  0.0063,  3.0625, -2.0781,  0.7852, -1.1797, -0.0225],\n",
      "        [-0.1177, -0.3086,  0.9141, -0.4375,  0.3809, -0.6211,  0.0859, -0.0369],\n",
      "        [-0.6484,  0.3926,  1.4609, -1.1172,  0.2656,  0.5781,  0.6641, -1.0156],\n",
      "        [ 0.5156,  0.7227,  0.0757,  0.6172, -1.2188, -1.4922,  1.7109, -0.7930],\n",
      "        [ 1.1328,  2.1094,  0.6953,  0.2656, -1.6797, -2.1719,  1.0703, -1.2578],\n",
      "        [ 1.1250, -0.7930, -0.2080, -1.3359,  1.0234,  2.3125, -0.2119, -1.5078],\n",
      "        [ 0.3789,  0.5039,  1.5547,  0.3867, -1.5703, -0.2773, -0.5469, -0.3672],\n",
      "        [ 0.3535, -0.1816, -0.2793,  0.0845,  1.0859,  0.1084, -0.7617, -0.6289],\n",
      "        [ 0.6289, -0.4785,  0.0820,  2.8281, -2.3125,  0.3770, -1.0859,  0.2422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[   -inf, -0.3086,    -inf, -0.4375,  0.3809, -0.6211,    -inf, -0.0369],\n",
      "        [   -inf,  0.3926,    -inf, -1.1172,  0.2656,  0.5781,    -inf, -1.0156],\n",
      "        [   -inf,  0.7227,    -inf,  0.6172, -1.2188, -1.4922,    -inf, -0.7930],\n",
      "        [   -inf,  2.1094,    -inf,  0.2656, -1.6797, -2.1719,    -inf, -1.2578],\n",
      "        [   -inf, -0.7930,    -inf, -1.3359,  1.0234,  2.3125,    -inf, -1.5078],\n",
      "        [   -inf,  0.5039,    -inf,  0.3867, -1.5703, -0.2773,    -inf, -0.3672],\n",
      "        [   -inf, -0.3184,    -inf, -0.1279,  1.1641,  0.5664,    -inf, -0.6172],\n",
      "        [   -inf, -0.4082,    -inf,  3.0625, -2.0781,  0.7852,    -inf, -0.0225],\n",
      "        [   -inf, -0.3086,    -inf, -0.4375,  0.3809, -0.6211,    -inf, -0.0369],\n",
      "        [   -inf,  0.3926,    -inf, -1.1172,  0.2656,  0.5781,    -inf, -1.0156],\n",
      "        [   -inf,  0.7227,    -inf,  0.6172, -1.2188, -1.4922,    -inf, -0.7930],\n",
      "        [   -inf,  2.1094,    -inf,  0.2656, -1.6797, -2.1719,    -inf, -1.2578],\n",
      "        [   -inf, -0.7930,    -inf, -1.3359,  1.0234,  2.3125,    -inf, -1.5078],\n",
      "        [   -inf,  0.5039,    -inf,  0.3867, -1.5703, -0.2773,    -inf, -0.3672],\n",
      "        [   -inf, -0.1816,    -inf,  0.0845,  1.0859,  0.1084,    -inf, -0.6289],\n",
      "        [   -inf, -0.4785,    -inf,  2.8281, -2.3125,  0.3770,    -inf,  0.2422]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 1, 2, 4, 5, 6, 7])\n",
      "router_logits is tensor([[-0.7188, -0.4629, -0.7891,  0.9883,  0.4570,  0.4023, -0.4629, -0.0806],\n",
      "        [-0.3223, -0.8047, -0.0781,  0.2402,  0.6953, -0.0283,  1.0312, -0.7188],\n",
      "        [-0.7695, -1.0078, -0.7930,  0.1865,  1.6328,  0.1846, -0.6875, -1.4062],\n",
      "        [-1.4531, -1.0312, -1.4453,  1.5938, -0.9258, -0.5664,  2.3906, -0.2070],\n",
      "        [-0.8203,  2.1719,  0.2285, -0.3848, -1.5859, -1.2422, -0.2441,  0.7500],\n",
      "        [-1.2344, -1.2266, -1.3672,  0.7461,  2.8438,  0.4219, -0.9414, -0.8320],\n",
      "        [-0.3320,  1.0312,  0.0723, -0.2148, -0.6797, -0.3418, -0.1738,  0.1865],\n",
      "        [-0.5820,  0.2432, -1.1016,  0.2363,  0.6094,  2.4375, -1.0703, -0.5430],\n",
      "        [-0.7188, -0.4629, -0.7891,  0.9883,  0.4570,  0.4023, -0.4629, -0.0806],\n",
      "        [-0.3223, -0.8047, -0.0781,  0.2402,  0.6953, -0.0283,  1.0312, -0.7188],\n",
      "        [-0.7695, -1.0078, -0.7930,  0.1865,  1.6328,  0.1846, -0.6875, -1.4062],\n",
      "        [-1.4531, -1.0312, -1.4453,  1.5938, -0.9258, -0.5664,  2.3906, -0.2070],\n",
      "        [-0.8203,  2.1719,  0.2285, -0.3848, -1.5859, -1.2422, -0.2441,  0.7500],\n",
      "        [-1.2344, -1.2266, -1.3672,  0.7461,  2.8438,  0.4219, -0.9414, -0.8320],\n",
      "        [-0.5117,  1.2812,  0.0366, -0.3301, -0.5391, -0.2051,  0.0366,  0.0120],\n",
      "        [-0.5898,  0.3047, -1.1641,  0.2021,  0.9492,  2.2031, -1.0078, -0.8789]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[-0.7188, -0.4629, -0.7891,    -inf,  0.4570,  0.4023, -0.4629, -0.0806],\n",
      "        [-0.3223, -0.8047, -0.0781,    -inf,  0.6953, -0.0283,  1.0312, -0.7188],\n",
      "        [-0.7695, -1.0078, -0.7930,    -inf,  1.6328,  0.1846, -0.6875, -1.4062],\n",
      "        [-1.4531, -1.0312, -1.4453,    -inf, -0.9258, -0.5664,  2.3906, -0.2070],\n",
      "        [-0.8203,  2.1719,  0.2285,    -inf, -1.5859, -1.2422, -0.2441,  0.7500],\n",
      "        [-1.2344, -1.2266, -1.3672,    -inf,  2.8438,  0.4219, -0.9414, -0.8320],\n",
      "        [-0.3320,  1.0312,  0.0723,    -inf, -0.6797, -0.3418, -0.1738,  0.1865],\n",
      "        [-0.5820,  0.2432, -1.1016,    -inf,  0.6094,  2.4375, -1.0703, -0.5430],\n",
      "        [-0.7188, -0.4629, -0.7891,    -inf,  0.4570,  0.4023, -0.4629, -0.0806],\n",
      "        [-0.3223, -0.8047, -0.0781,    -inf,  0.6953, -0.0283,  1.0312, -0.7188],\n",
      "        [-0.7695, -1.0078, -0.7930,    -inf,  1.6328,  0.1846, -0.6875, -1.4062],\n",
      "        [-1.4531, -1.0312, -1.4453,    -inf, -0.9258, -0.5664,  2.3906, -0.2070],\n",
      "        [-0.8203,  2.1719,  0.2285,    -inf, -1.5859, -1.2422, -0.2441,  0.7500],\n",
      "        [-1.2344, -1.2266, -1.3672,    -inf,  2.8438,  0.4219, -0.9414, -0.8320],\n",
      "        [-0.5117,  1.2812,  0.0366,    -inf, -0.5391, -0.2051,  0.0366,  0.0120],\n",
      "        [-0.5898,  0.3047, -1.1641,    -inf,  0.9492,  2.2031, -1.0078, -0.8789]],\n",
      "       device='cuda:0', dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 1, 2, 5, 6, 7])\n",
      "router_logits is tensor([[ 2.5625e+00,  3.0625e+00,  2.4531e+00,  1.9531e+00,  4.7500e+00,\n",
      "          2.0469e+00,  2.8281e+00,  2.8438e+00],\n",
      "        [-2.6953e-01, -3.6523e-01,  2.1719e+00, -3.5156e-01,  8.8672e-01,\n",
      "         -6.5234e-01, -3.3398e-01, -9.4531e-01],\n",
      "        [ 1.4453e-01,  3.2227e-01, -5.4321e-03,  6.6406e-01,  1.5078e+00,\n",
      "         -8.6328e-01, -4.3945e-01, -4.4189e-02],\n",
      "        [ 1.1094e+00,  2.0625e+00, -1.4551e-01,  2.3926e-01, -7.4219e-02,\n",
      "         -1.2500e+00, -8.1250e-01, -3.3984e-01],\n",
      "        [-5.8105e-02, -1.8047e+00,  1.8125e+00,  1.1250e+00, -2.5977e-01,\n",
      "         -8.6328e-01, -3.9062e-01, -1.6602e-01],\n",
      "        [ 3.4961e-01,  2.9297e-03, -1.0000e+00,  1.5391e+00,  1.1250e+00,\n",
      "         -5.9766e-01, -1.8047e+00,  8.2422e-01],\n",
      "        [-2.4902e-01, -2.5625e+00,  1.9922e+00, -1.4609e+00,  4.5117e-01,\n",
      "         -1.4375e+00,  1.8281e+00,  2.1484e-01],\n",
      "        [ 2.2656e+00, -3.0312e+00,  1.4160e-01, -1.2891e+00,  1.2109e+00,\n",
      "         -4.6484e-01,  3.5742e-01,  7.6172e-01],\n",
      "        [ 2.5625e+00,  3.0625e+00,  2.4531e+00,  1.9531e+00,  4.7500e+00,\n",
      "          2.0469e+00,  2.8281e+00,  2.8438e+00],\n",
      "        [-2.6953e-01, -3.6523e-01,  2.1719e+00, -3.5156e-01,  8.8672e-01,\n",
      "         -6.5234e-01, -3.3398e-01, -9.4531e-01],\n",
      "        [ 1.4453e-01,  3.2227e-01, -5.4321e-03,  6.6406e-01,  1.5078e+00,\n",
      "         -8.6328e-01, -4.3945e-01, -4.4189e-02],\n",
      "        [ 1.1094e+00,  2.0625e+00, -1.4551e-01,  2.3926e-01, -7.4219e-02,\n",
      "         -1.2500e+00, -8.1250e-01, -3.3984e-01],\n",
      "        [-5.8105e-02, -1.8047e+00,  1.8125e+00,  1.1250e+00, -2.5977e-01,\n",
      "         -8.6328e-01, -3.9062e-01, -1.6602e-01],\n",
      "        [ 3.4961e-01,  2.9297e-03, -1.0000e+00,  1.5391e+00,  1.1250e+00,\n",
      "         -5.9766e-01, -1.8047e+00,  8.2422e-01],\n",
      "        [-1.9531e-01, -2.7969e+00,  2.0469e+00, -1.5156e+00,  4.1992e-01,\n",
      "         -1.6719e+00,  1.8281e+00,  4.5703e-01],\n",
      "        [ 2.3594e+00, -2.7656e+00,  3.3203e-01, -1.2188e+00,  1.4688e+00,\n",
      "         -8.5547e-01, -1.6211e-01,  5.3125e-01]], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[ 2.5625e+00,  3.0625e+00,  2.4531e+00,        -inf,        -inf,\n",
      "          2.0469e+00,  2.8281e+00,  2.8438e+00],\n",
      "        [-2.6953e-01, -3.6523e-01,  2.1719e+00,        -inf,        -inf,\n",
      "         -6.5234e-01, -3.3398e-01, -9.4531e-01],\n",
      "        [ 1.4453e-01,  3.2227e-01, -5.4321e-03,        -inf,        -inf,\n",
      "         -8.6328e-01, -4.3945e-01, -4.4189e-02],\n",
      "        [ 1.1094e+00,  2.0625e+00, -1.4551e-01,        -inf,        -inf,\n",
      "         -1.2500e+00, -8.1250e-01, -3.3984e-01],\n",
      "        [-5.8105e-02, -1.8047e+00,  1.8125e+00,        -inf,        -inf,\n",
      "         -8.6328e-01, -3.9062e-01, -1.6602e-01],\n",
      "        [ 3.4961e-01,  2.9297e-03, -1.0000e+00,        -inf,        -inf,\n",
      "         -5.9766e-01, -1.8047e+00,  8.2422e-01],\n",
      "        [-2.4902e-01, -2.5625e+00,  1.9922e+00,        -inf,        -inf,\n",
      "         -1.4375e+00,  1.8281e+00,  2.1484e-01],\n",
      "        [ 2.2656e+00, -3.0312e+00,  1.4160e-01,        -inf,        -inf,\n",
      "         -4.6484e-01,  3.5742e-01,  7.6172e-01],\n",
      "        [ 2.5625e+00,  3.0625e+00,  2.4531e+00,        -inf,        -inf,\n",
      "          2.0469e+00,  2.8281e+00,  2.8438e+00],\n",
      "        [-2.6953e-01, -3.6523e-01,  2.1719e+00,        -inf,        -inf,\n",
      "         -6.5234e-01, -3.3398e-01, -9.4531e-01],\n",
      "        [ 1.4453e-01,  3.2227e-01, -5.4321e-03,        -inf,        -inf,\n",
      "         -8.6328e-01, -4.3945e-01, -4.4189e-02],\n",
      "        [ 1.1094e+00,  2.0625e+00, -1.4551e-01,        -inf,        -inf,\n",
      "         -1.2500e+00, -8.1250e-01, -3.3984e-01],\n",
      "        [-5.8105e-02, -1.8047e+00,  1.8125e+00,        -inf,        -inf,\n",
      "         -8.6328e-01, -3.9062e-01, -1.6602e-01],\n",
      "        [ 3.4961e-01,  2.9297e-03, -1.0000e+00,        -inf,        -inf,\n",
      "         -5.9766e-01, -1.8047e+00,  8.2422e-01],\n",
      "        [-1.9531e-01, -2.7969e+00,  2.0469e+00,        -inf,        -inf,\n",
      "         -1.6719e+00,  1.8281e+00,  4.5703e-01],\n",
      "        [ 2.3594e+00, -2.7656e+00,  3.3203e-01,        -inf,        -inf,\n",
      "         -8.5547e-01, -1.6211e-01,  5.3125e-01]], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n",
      "layer_expert_mask is tensor([0, 1, 2, 3, 4])\n",
      "router_logits is tensor([[ 5.4688e-01,  8.3594e-01,  1.6875e+00, -4.1562e+00,  7.8125e-01,\n",
      "          9.2969e-01, -3.3750e+00,  8.3984e-01],\n",
      "        [-1.0840e-01, -2.4609e-01,  4.1199e-03,  1.3379e-01, -5.1562e-01,\n",
      "         -1.6562e+00,  1.1953e+00, -9.2578e-01],\n",
      "        [-2.0469e+00, -3.2617e-01,  1.9062e+00,  3.2812e-01, -9.6094e-01,\n",
      "         -7.8906e-01,  1.2734e+00,  1.0469e+00],\n",
      "        [-1.9922e+00,  1.0625e+00, -2.5781e-01,  1.7188e+00, -1.1328e+00,\n",
      "          2.4844e+00, -1.2988e-01,  8.6719e-01],\n",
      "        [-2.7734e-01,  2.5312e+00, -1.3594e+00,  1.1328e+00, -2.0117e-01,\n",
      "          8.2422e-01, -1.0703e+00, -7.7734e-01],\n",
      "        [-1.8047e+00, -9.8438e-01,  2.8281e+00,  7.9956e-03, -1.5469e+00,\n",
      "         -8.3203e-01,  1.5918e-01,  1.9531e+00],\n",
      "        [ 1.2266e+00, -8.0078e-01, -7.6562e-01, -5.3125e-01,  5.1172e-01,\n",
      "         -1.3438e+00, -6.7578e-01, -7.5391e-01],\n",
      "        [-1.1016e+00, -2.5781e-01,  2.8594e+00, -1.8984e+00, -9.8828e-01,\n",
      "         -5.5859e-01, -1.3438e+00,  1.6016e+00],\n",
      "        [ 5.4688e-01,  8.3594e-01,  1.6875e+00, -4.1562e+00,  7.8125e-01,\n",
      "          9.2969e-01, -3.3750e+00,  8.3984e-01],\n",
      "        [-1.0840e-01, -2.4609e-01,  4.1199e-03,  1.3379e-01, -5.1562e-01,\n",
      "         -1.6562e+00,  1.1953e+00, -9.2578e-01],\n",
      "        [-2.0469e+00, -3.2617e-01,  1.9062e+00,  3.2812e-01, -9.6094e-01,\n",
      "         -7.8906e-01,  1.2734e+00,  1.0469e+00],\n",
      "        [-1.9922e+00,  1.0625e+00, -2.5781e-01,  1.7188e+00, -1.1328e+00,\n",
      "          2.4844e+00, -1.2988e-01,  8.6719e-01],\n",
      "        [-2.7734e-01,  2.5312e+00, -1.3594e+00,  1.1328e+00, -2.0117e-01,\n",
      "          8.2422e-01, -1.0703e+00, -7.7734e-01],\n",
      "        [-1.8047e+00, -9.8438e-01,  2.8281e+00,  7.9956e-03, -1.5469e+00,\n",
      "         -8.3203e-01,  1.5918e-01,  1.9531e+00],\n",
      "        [ 1.1875e+00, -7.8906e-01, -9.4531e-01, -6.2500e-01,  3.3789e-01,\n",
      "         -1.4141e+00, -8.2422e-01, -7.4609e-01],\n",
      "        [-1.4062e+00, -5.9375e-01,  2.4062e+00, -1.5625e+00, -1.4688e+00,\n",
      "         -6.2891e-01, -1.4688e+00,  1.3516e+00]], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n",
      "router_logits shape is torch.Size([16, 8])\n",
      "After mask router_logits is tensor([[ 5.4688e-01,  8.3594e-01,  1.6875e+00, -4.1562e+00,  7.8125e-01,\n",
      "                -inf,        -inf,        -inf],\n",
      "        [-1.0840e-01, -2.4609e-01,  4.1199e-03,  1.3379e-01, -5.1562e-01,\n",
      "                -inf,        -inf,        -inf],\n",
      "        [-2.0469e+00, -3.2617e-01,  1.9062e+00,  3.2812e-01, -9.6094e-01,\n",
      "                -inf,        -inf,        -inf],\n",
      "        [-1.9922e+00,  1.0625e+00, -2.5781e-01,  1.7188e+00, -1.1328e+00,\n",
      "                -inf,        -inf,        -inf],\n",
      "        [-2.7734e-01,  2.5312e+00, -1.3594e+00,  1.1328e+00, -2.0117e-01,\n",
      "                -inf,        -inf,        -inf],\n",
      "        [-1.8047e+00, -9.8438e-01,  2.8281e+00,  7.9956e-03, -1.5469e+00,\n",
      "                -inf,        -inf,        -inf],\n",
      "        [ 1.2266e+00, -8.0078e-01, -7.6562e-01, -5.3125e-01,  5.1172e-01,\n",
      "                -inf,        -inf,        -inf],\n",
      "        [-1.1016e+00, -2.5781e-01,  2.8594e+00, -1.8984e+00, -9.8828e-01,\n",
      "                -inf,        -inf,        -inf],\n",
      "        [ 5.4688e-01,  8.3594e-01,  1.6875e+00, -4.1562e+00,  7.8125e-01,\n",
      "                -inf,        -inf,        -inf],\n",
      "        [-1.0840e-01, -2.4609e-01,  4.1199e-03,  1.3379e-01, -5.1562e-01,\n",
      "                -inf,        -inf,        -inf],\n",
      "        [-2.0469e+00, -3.2617e-01,  1.9062e+00,  3.2812e-01, -9.6094e-01,\n",
      "                -inf,        -inf,        -inf],\n",
      "        [-1.9922e+00,  1.0625e+00, -2.5781e-01,  1.7188e+00, -1.1328e+00,\n",
      "                -inf,        -inf,        -inf],\n",
      "        [-2.7734e-01,  2.5312e+00, -1.3594e+00,  1.1328e+00, -2.0117e-01,\n",
      "                -inf,        -inf,        -inf],\n",
      "        [-1.8047e+00, -9.8438e-01,  2.8281e+00,  7.9956e-03, -1.5469e+00,\n",
      "                -inf,        -inf,        -inf],\n",
      "        [ 1.1875e+00, -7.8906e-01, -9.4531e-01, -6.2500e-01,  3.3789e-01,\n",
      "                -inf,        -inf,        -inf],\n",
      "        [-1.4062e+00, -5.9375e-01,  2.4062e+00, -1.5625e+00, -1.4688e+00,\n",
      "                -inf,        -inf,        -inf]], device='cuda:0',\n",
      "       dtype=torch.bfloat16)\n",
      "After mask router_logits shape is torch.Size([16, 8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 2/2 [00:26<00:00, 13.27s/it, est. speed input: 0.60 toks/s, output: 78.68 toks/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[RequestOutput(request_id=0, prompt='What is the capital of France?', prompt_token_ids=[1, 1824, 349, 272, 5565, 302, 4843, 28804], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='\\n\\nParis is the capital of France.\\n\\nWhat is the population of France?\\n\\nThe population of France is 66,991,000.\\n\\nWhat is the area of France?\\n\\nThe area of France is 248,573 square miles.\\n\\nWhat is the official language of France?\\n\\nThe official language of France is French.\\n\\nWhat is the currency of France?\\n\\nThe currency of France is the euro.\\n\\nHow did France get its name?\\n\\nThe name France comes from the Latin word Francia, which means “land of the Franks.”\\n\\nWhat is the history of France?\\n\\nFrance has a long and complex history. It was originally inhabited by the Gauls, who were conquered by the Romans in the 1st century BC. The Franks, a Germanic tribe, invaded the country in the 5th century AD and established the Frankish kingdom. The kingdom was later divided into several smaller kingdoms, which were eventually united under the rule of the Capetian dynasty in the 10th century.\\n\\nFrance became a major power in Europe during the 16th and 17th centuries. It was involved in a number of wars, including the Hundred Years’ War with England and the Thirty Years’ War. In the 18th century, France was ruled by the Bourbon dynasty, which was overthrown in the French Revolution of 1789.\\n\\nFrance was a major player in the Napoleonic Wars of the early 19th century. It was defeated by the British in the Battle of Waterloo in 1815. France was later involved in the Franco-Prussian War of 1870-1871 and the First World War of 1914-1918.\\n\\nFrance was occupied by Nazi Germany during the Second World War. It was liberated by the Allies in 1944. France was a founding member of the United Nations and the European Union.\\n\\nWhat is the geography of France?\\n\\nFrance is a country located in Western Europe. It is bordered by the English Channel to the north, the Atlantic Ocean to the west, the Mediterranean Sea to the south, and the Pyrenees Mountains to the southwest. France is the largest country in Western Europe and the third largest in Europe.\\n\\nWhat is the climate of France?\\n\\nThe climate of France is temperate, with cool winters and warm summers.\\n\\nWhat is the economy of France?\\n\\nThe economy of France is the fifth largest in the world. It is a developed country with a high standard of living. France is a major exporter of agricultural products, wine, and luxury goods.\\n\\nWhat is the culture of France?\\n\\nThe culture of France is rich and diverse. It is influenced by the country’s long history and its location in Western Europe. France is known for its art, literature, music, and cuisine.\\n\\n## What is the capital of France and its population?\\n\\nThe capital of France is Paris, and its population is 2.2 million.\\n\\n## What is the capital of France and its currency?\\n\\nThe capital of France is Paris, and its currency is the euro.\\n\\n## What is the capital of France and its language?\\n\\nThe capital of France is Paris, and its language is French.\\n\\n## What is the capital of France and its flag?\\n\\nThe capital of France is Paris, and its flag is the tricolor.\\n\\n## What is the capital of France and its government?\\n\\nThe capital of France is Paris, and its government is a republic.\\n\\n## What is the capital of France and its history?\\n\\nThe capital of France is Paris, and its history is long and complex. The city has been the site of many important events in French history, including the French Revolution and the World Wars.\\n\\n## What is the capital of France and its culture?\\n\\nThe capital of France is Paris, and its culture is rich and diverse. The city is home to many world-renowned museums, theaters, and restaurants, and it is a popular tourist destination.\\n\\n## What is the capital of France and its people?\\n\\nThe capital of France is Paris, and its people are called the French.\\n\\n## What is the capital of France and its food?\\n\\nThe capital of France is Paris, and its food is some of the best in the world. The city is home to many world-renowned restaurants, and its cuisine is a mix of French and international flavors.\\n\\n## What is the capital of France and its weather?\\n\\nThe capital of France is Paris, and its weather is temperate.\\n\\n## What is the capital of France and its climate?\\n\\nThe capital of France is Paris, and its climate is temperate.\\n\\n## What is the capital of France and its geography?\\n\\nThe capital of France is Paris, and its geography is diverse. The city is located in the north-central part of the country, and it is surrounded by the Seine River.\\n\\n## What is the capital of France and its economy?\\n\\nThe capital of France is Paris, and its economy is strong. The city is home to many world-renowned businesses, and it is a major tourist destination.\\n\\n## What is the capital of France and its tourism?\\n\\nThe capital of France is Paris, and its tourism is world-renowned. The city is home to many famous landmarks, including the Eiffel Tower, the Louvre Museum, and the Notre Dame Cathedral.\\n\\n## What is the capital of France and its history?\\n\\nThe capital of France is Paris, and its history is long and complex. The city has been the site of many important events in French history, including the French Revolution and the World Wars.\\n\\n## What is the capital of France and its culture?\\n\\nThe capital of France is Paris, and its culture is rich and diverse. The city is home to many world-renowned museums, theaters, and restaurants, and it is a popular tourist destination.\\n\\n## What is the capital of France and its people?\\n\\nThe capital of France is Paris, and its people are called the French.\\n\\n## What is the capital of France and its food?\\n\\nThe capital of France is Paris, and its food is some of the best in the world. The city is home to many world-renowned restaurants, and its cuisine is a mix of French and international flavors.\\n\\n## What is the capital of France and its weather?\\n\\nThe capital of France is Paris, and its weather is temperate.\\n\\n## What is the capital of France and its climate?\\n\\nThe capital of France is Paris, and its climate is temperate.\\n\\n## What is the capital of France and its geography?\\n\\nThe capital of France is Paris, and its geography is diverse. The city is located in the north-central part of the country, and it is surrounded by the Seine River.\\n\\n## What is the capital of France and its economy?\\n\\nThe capital of France is Paris, and its economy is strong. The city is home to many world-renowned businesses, and it is a major tourist destination.\\n\\n## What is the capital of France and its tourism?\\n\\nThe capital of France is Paris, and its tourism is world-renowned. The city is home to many famous landmarks, including the Eiffel Tower, the Louvre Museum, and the Notre Dame Cathedral.', token_ids=(13, 13, 3916, 278, 349, 272, 5565, 302, 4843, 28723, 13, 13, 3195, 349, 272, 4889, 302, 4843, 28804, 13, 13, 1014, 4889, 302, 4843, 349, 28705, 28784, 28784, 28725, 28774, 28774, 28740, 28725, 28734, 28734, 28734, 28723, 13, 13, 3195, 349, 272, 2698, 302, 4843, 28804, 13, 13, 1014, 2698, 302, 4843, 349, 28705, 28750, 28781, 28783, 28725, 28782, 28787, 28770, 7930, 6052, 28723, 13, 13, 3195, 349, 272, 5189, 3842, 302, 4843, 28804, 13, 13, 1014, 5189, 3842, 302, 4843, 349, 4949, 28723, 13, 13, 3195, 349, 272, 15547, 302, 4843, 28804, 13, 13, 1014, 15547, 302, 4843, 349, 272, 317, 2138, 28723, 13, 13, 5660, 863, 4843, 625, 871, 1141, 28804, 13, 13, 1014, 1141, 4843, 3435, 477, 272, 13729, 1707, 19852, 28725, 690, 2825, 981, 1207, 302, 272, 1361, 3750, 2435, 13, 13, 3195, 349, 272, 3340, 302, 4843, 28804, 13, 13, 2642, 617, 659, 264, 1043, 304, 4630, 3340, 28723, 661, 403, 10806, 15734, 1345, 486, 272, 420, 2857, 28713, 28725, 693, 654, 17095, 2092, 486, 272, 28282, 297, 272, 28705, 28740, 303, 5445, 13779, 28723, 415, 1361, 3750, 28725, 264, 5567, 294, 25315, 28725, 1304, 8744, 272, 2939, 297, 272, 28705, 28782, 362, 5445, 10004, 304, 6740, 272, 4790, 789, 17782, 28723, 415, 17782, 403, 2062, 13570, 778, 2856, 7000, 17782, 28713, 28725, 690, 654, 6959, 27434, 916, 272, 5918, 302, 272, 6275, 299, 753, 16150, 11136, 297, 272, 28705, 28740, 28734, 362, 5445, 28723, 13, 13, 2642, 617, 3246, 264, 3014, 1982, 297, 3401, 1938, 272, 28705, 28740, 28784, 362, 304, 28705, 28740, 28787, 362, 14997, 28723, 661, 403, 5290, 297, 264, 1474, 302, 19270, 28725, 2490, 272, 382, 4381, 16886, 28809, 3273, 395, 5783, 304, 272, 542, 7485, 16886, 28809, 3273, 28723, 560, 272, 28705, 28740, 28783, 362, 5445, 28725, 4843, 403, 20080, 486, 272, 16078, 5997, 16150, 11136, 28725, 690, 403, 754, 362, 3329, 297, 272, 4949, 13850, 302, 28705, 28740, 28787, 28783, 28774, 28723, 13, 13, 2642, 617, 403, 264, 3014, 4385, 297, 272, 22204, 9011, 12096, 302, 272, 2935, 28705, 28740, 28774, 362, 5445, 28723, 661, 403, 16231, 486, 272, 4409, 297, 272, 13711, 302, 8632, 731, 28709, 297, 28705, 28740, 28783, 28740, 28782, 28723, 4843, 403, 2062, 5290, 297, 272, 28289, 28733, 3393, 12897, 3273, 302, 28705, 28740, 28783, 28787, 28734, 28733, 28740, 28783, 28787, 28740, 304, 272, 4205, 3304, 3273, 302, 28705, 28740, 28774, 28740, 28781, 28733, 28740, 28774, 28740, 28783, 28723, 13, 13, 2642, 617, 403, 16512, 486, 21217, 7293, 1938, 272, 7052, 3304, 3273, 28723, 661, 403, 7172, 601, 486, 272, 1682, 497, 297, 28705, 28740, 28774, 28781, 28781, 28723, 4843, 403, 264, 24750, 4292, 302, 272, 2969, 16419, 304, 272, 6392, 7085, 28723, 13, 13, 3195, 349, 272, 2970, 5064, 302, 4843, 28804, 13, 13, 2642, 617, 349, 264, 2939, 5651, 297, 8307, 3401, 28723, 661, 349, 287, 17029, 486, 272, 4300, 14250, 298, 272, 6120, 28725, 272, 16343, 18608, 298, 272, 7635, 28725, 272, 26848, 11759, 298, 272, 6287, 28725, 304, 272, 5961, 267, 485, 274, 26425, 298, 272, 6287, 7471, 28723, 4843, 349, 272, 7639, 2939, 297, 8307, 3401, 304, 272, 4008, 7639, 297, 3401, 28723, 13, 13, 3195, 349, 272, 11259, 302, 4843, 28804, 13, 13, 1014, 11259, 302, 4843, 349, 5026, 380, 28725, 395, 5106, 3108, 1532, 304, 6100, 2648, 14448, 28723, 13, 13, 3195, 349, 272, 8725, 302, 4843, 28804, 13, 13, 1014, 8725, 302, 4843, 349, 272, 14969, 7639, 297, 272, 1526, 28723, 661, 349, 264, 6202, 2939, 395, 264, 1486, 4787, 302, 3687, 28723, 4843, 349, 264, 3014, 439, 17175, 302, 22815, 4076, 28725, 8188, 28725, 304, 17211, 11282, 28723, 13, 13, 3195, 349, 272, 5679, 302, 4843, 28804, 13, 13, 1014, 5679, 302, 4843, 349, 6708, 304, 12836, 28723, 661, 349, 19927, 486, 272, 2939, 28809, 28713, 1043, 3340, 304, 871, 4723, 297, 8307, 3401, 28723, 4843, 349, 2651, 354, 871, 1524, 28725, 11354, 28725, 3427, 28725, 304, 4014, 26704, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 4889, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 4889, 349, 28705, 28750, 28723, 28750, 3841, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 15547, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 15547, 349, 272, 317, 2138, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 3842, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 3842, 349, 4949, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 6673, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 6673, 349, 272, 467, 8176, 271, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 3058, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 3058, 349, 264, 19988, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 3340, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 3340, 349, 1043, 304, 4630, 28723, 415, 2990, 659, 750, 272, 3455, 302, 1287, 2278, 3926, 297, 4949, 3340, 28725, 2490, 272, 4949, 13850, 304, 272, 3304, 12096, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 5679, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 5679, 349, 6708, 304, 12836, 28723, 415, 2990, 349, 1611, 298, 1287, 1526, 28733, 951, 19589, 13041, 28713, 28725, 272, 17244, 28725, 304, 14666, 28725, 304, 378, 349, 264, 4387, 23254, 10316, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 905, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 905, 460, 1987, 272, 4949, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 2887, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 2887, 349, 741, 302, 272, 1489, 297, 272, 1526, 28723, 415, 2990, 349, 1611, 298, 1287, 1526, 28733, 951, 19589, 14666, 28725, 304, 871, 4014, 26704, 349, 264, 6750, 302, 4949, 304, 5611, 15637, 734, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 8086, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 8086, 349, 5026, 380, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 11259, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 11259, 349, 5026, 380, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 2970, 5064, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 2970, 5064, 349, 12836, 28723, 415, 2990, 349, 5651, 297, 272, 6120, 28733, 1476, 1650, 744, 302, 272, 2939, 28725, 304, 378, 349, 14161, 486, 272, 25517, 6396, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 8725, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 8725, 349, 2967, 28723, 415, 2990, 349, 1611, 298, 1287, 1526, 28733, 951, 19589, 8689, 28725, 304, 378, 349, 264, 3014, 23254, 10316, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 3884, 1443, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 3884, 1443, 349, 1526, 28733, 951, 19589, 28723, 415, 2990, 349, 1611, 298, 1287, 8376, 2533, 17181, 28725, 2490, 272, 413, 2728, 301, 19895, 28725, 272, 5105, 19465, 8770, 28725, 304, 272, 2280, 267, 384, 433, 10758, 19749, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 3340, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 3340, 349, 1043, 304, 4630, 28723, 415, 2990, 659, 750, 272, 3455, 302, 1287, 2278, 3926, 297, 4949, 3340, 28725, 2490, 272, 4949, 13850, 304, 272, 3304, 12096, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 5679, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 5679, 349, 6708, 304, 12836, 28723, 415, 2990, 349, 1611, 298, 1287, 1526, 28733, 951, 19589, 13041, 28713, 28725, 272, 17244, 28725, 304, 14666, 28725, 304, 378, 349, 264, 4387, 23254, 10316, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 905, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 905, 460, 1987, 272, 4949, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 2887, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 2887, 349, 741, 302, 272, 1489, 297, 272, 1526, 28723, 415, 2990, 349, 1611, 298, 1287, 1526, 28733, 951, 19589, 14666, 28725, 304, 871, 4014, 26704, 349, 264, 6750, 302, 4949, 304, 5611, 15637, 734, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 8086, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 8086, 349, 5026, 380, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 11259, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 11259, 349, 5026, 380, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 2970, 5064, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 2970, 5064, 349, 12836, 28723, 415, 2990, 349, 5651, 297, 272, 6120, 28733, 1476, 1650, 744, 302, 272, 2939, 28725, 304, 378, 349, 14161, 486, 272, 25517, 6396, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 8725, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 8725, 349, 2967, 28723, 415, 2990, 349, 1611, 298, 1287, 1526, 28733, 951, 19589, 8689, 28725, 304, 378, 349, 264, 3014, 23254, 10316, 28723, 13, 13, 1064, 1824, 349, 272, 5565, 302, 4843, 304, 871, 3884, 1443, 28804, 13, 13, 1014, 5565, 302, 4843, 349, 5465, 28725, 304, 871, 3884, 1443, 349, 1526, 28733, 951, 19589, 28723, 415, 2990, 349, 1611, 298, 1287, 8376, 2533, 17181, 28725, 2490, 272, 413, 2728, 301, 19895, 28725, 272, 5105, 19465, 8770, 28725, 304, 272, 2280, 267, 384, 433, 10758, 19749, 28723, 2), cumulative_logprob=None, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1731665293.6171355, last_token_time=1731665293.6171355, first_scheduled_time=1731665293.642577, first_token_time=1731665293.9947813, time_in_queue=0.025441408157348633, finished_time=1731665320.1680655, scheduler_time=0.388791186735034, model_forward_time=None, model_execute_time=None), lora_request=None),\n",
       " RequestOutput(request_id=1, prompt='What is the capital of China?', prompt_token_ids=[1, 1824, 349, 272, 5565, 302, 5077, 28804], encoder_prompt=None, encoder_prompt_token_ids=None, prompt_logprobs=None, outputs=[CompletionOutput(index=0, text='\\n\\nBeijing is the capital of China.\\n\\nWhat is the population of China?\\n\\nThe population of China is 1,382,710,000.\\n\\nWhat is the area of China?\\n\\nThe area of China is 9,596,960 square kilometers.\\n\\nWhat is the official national language of China?\\n\\nThe official national language of China is Standard Chinese.\\n\\nWhat is the currency of China?\\n\\nThe currency of China is Chinese yuan.\\n\\nHow many provinces are there in China?\\n\\nThere are 23 provinces in China.\\n\\nWhat is the religion of China?\\n\\nThe religion of China is Buddhism.\\n\\nWhat is the largest city of China?\\n\\nShanghai is the largest city of China.\\n\\nWhat is the GDP of China?\\n\\nThe GDP of China is $11.2 trillion.\\n\\nWhat is the FDI of China?\\n\\nThe FDI of China is $134 billion.\\n\\nWhat is the ethnicity of China?\\n\\nThe ethnicity of China is Han Chinese.\\n\\nWhat is the climate of China?\\n\\nThe climate of China is temperate.\\n\\nWhat is the largest airport in China?\\n\\nBeijing Capital International Airport is the largest airport in China.\\n\\nWhat is the largest company in China?\\n\\nSinopec Group is the largest company in China.\\n\\nWhat is the national bird of China?\\n\\nRed-crowned crane is the national bird of China.\\n\\nWhat is the national flower of China?\\n\\nPlum blossom is the national flower of China.\\n\\nWhat is the national fruit of China?\\n\\nPear is the national fruit of China.\\n\\nWhat is the national vegetable of China?\\n\\nCabbage is the national vegetable of China.\\n\\nWhat is the national animal of China?\\n\\nGiant panda is the national animal of China.', token_ids=(13, 13, 3574, 25168, 349, 272, 5565, 302, 5077, 28723, 13, 13, 3195, 349, 272, 4889, 302, 5077, 28804, 13, 13, 1014, 4889, 302, 5077, 349, 28705, 28740, 28725, 28770, 28783, 28750, 28725, 28787, 28740, 28734, 28725, 28734, 28734, 28734, 28723, 13, 13, 3195, 349, 272, 2698, 302, 5077, 28804, 13, 13, 1014, 2698, 302, 5077, 349, 28705, 28774, 28725, 28782, 28774, 28784, 28725, 28774, 28784, 28734, 7930, 22230, 2612, 28723, 13, 13, 3195, 349, 272, 5189, 4282, 3842, 302, 5077, 28804, 13, 13, 1014, 5189, 4282, 3842, 302, 5077, 349, 12623, 6707, 28723, 13, 13, 3195, 349, 272, 15547, 302, 5077, 28804, 13, 13, 1014, 15547, 302, 5077, 349, 6707, 337, 6882, 28723, 13, 13, 5660, 1287, 24899, 1377, 460, 736, 297, 5077, 28804, 13, 13, 5816, 460, 28705, 28750, 28770, 24899, 1377, 297, 5077, 28723, 13, 13, 3195, 349, 272, 10048, 302, 5077, 28804, 13, 13, 1014, 10048, 302, 5077, 349, 13772, 28716, 1443, 28723, 13, 13, 3195, 349, 272, 7639, 2990, 302, 5077, 28804, 13, 13, 1981, 276, 25801, 349, 272, 7639, 2990, 302, 5077, 28723, 13, 13, 3195, 349, 272, 420, 10485, 302, 5077, 28804, 13, 13, 1014, 420, 10485, 302, 5077, 349, 429, 28740, 28740, 28723, 28750, 467, 23202, 28723, 13, 13, 3195, 349, 272, 401, 3284, 302, 5077, 28804, 13, 13, 1014, 401, 3284, 302, 5077, 349, 429, 28740, 28770, 28781, 8737, 28723, 13, 13, 3195, 349, 272, 18433, 472, 302, 5077, 28804, 13, 13, 1014, 18433, 472, 302, 5077, 349, 8225, 6707, 28723, 13, 13, 3195, 349, 272, 11259, 302, 5077, 28804, 13, 13, 1014, 11259, 302, 5077, 349, 5026, 380, 28723, 13, 13, 3195, 349, 272, 7639, 14400, 297, 5077, 28804, 13, 13, 3574, 25168, 17053, 5440, 16795, 349, 272, 7639, 14400, 297, 5077, 28723, 13, 13, 3195, 349, 272, 7639, 2496, 297, 5077, 28804, 13, 13, 28735, 2164, 841, 5926, 349, 272, 7639, 2496, 297, 5077, 28723, 13, 13, 3195, 349, 272, 4282, 7727, 302, 5077, 28804, 13, 13, 7516, 28733, 28717, 14335, 1439, 1564, 349, 272, 4282, 7727, 302, 5077, 28723, 13, 13, 3195, 349, 272, 4282, 14994, 302, 5077, 28804, 13, 13, 2249, 383, 843, 2158, 300, 349, 272, 4282, 14994, 302, 5077, 28723, 13, 13, 3195, 349, 272, 4282, 10607, 302, 5077, 28804, 13, 13, 28753, 644, 349, 272, 4282, 10607, 302, 5077, 28723, 13, 13, 3195, 349, 272, 4282, 10035, 522, 302, 5077, 28804, 13, 13, 28743, 13277, 465, 349, 272, 4282, 10035, 522, 302, 5077, 28723, 13, 13, 3195, 349, 272, 4282, 8527, 302, 5077, 28804, 13, 13, 28777, 3906, 284, 5904, 349, 272, 4282, 8527, 302, 5077, 28723, 2), cumulative_logprob=None, logprobs=None, finish_reason=stop, stop_reason=None)], finished=True, metrics=RequestMetrics(arrival_time=1731665293.6334066, last_token_time=1731665293.6334066, first_scheduled_time=1731665293.642577, first_token_time=1731665293.9947813, time_in_queue=0.009170293807983398, finished_time=1731665302.3102934, scheduler_time=0.11462379060685635, model_forward_time=None, model_execute_time=None), lora_request=None)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_batch = [\"What is the capital of France?\", \"What is the capital of China?\"]\n",
    "llm.generate(inference_batch, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LLM.generate of <vllm.entrypoints.llm.LLM object at 0x785b400ee470>>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看generate函数的源码\n",
    "import inspect\n",
    "print(inspect.getsource(llm.generate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = llm.llm_engine.model_executor.driver_worker.model_runner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixtralForCausalLM(\n",
       "  (model): MixtralModel(\n",
       "    (embed_tokens): VocabParallelEmbedding(num_embeddings=16000, embedding_dim=4096, org_vocab_size=32000, num_embeddings_padded=32000, tp_size=2)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MixtralDecoderLayer(\n",
       "        (self_attn): MixtralAttention(\n",
       "          (qkv_proj): QKVParallelLinear(in_features=4096, output_features=3072, bias=False, tp_size=2, gather_output=False)\n",
       "          (o_proj): RowParallelLinear(input_features=2048, output_features=4096, bias=False, tp_size=2, reduce_results=True)\n",
       "          (rotary_emb): RotaryEmbedding(head_size=128, rotary_dim=128, max_position_embeddings=32768, base=1000000, is_neox_style=True)\n",
       "          (attn): Attention(head_size=128, num_heads=16, num_kv_heads=4, scale=0.08838834764831845, backend=FlashAttentionImpl)\n",
       "        )\n",
       "        (block_sparse_moe): MixtralMoE(\n",
       "          (gate): ReplicatedLinear(in_features=4096, output_features=8, bias=False)\n",
       "          (experts): FusedMoE(\n",
       "            (quant_method): UnquantizedFusedMoEMethod()\n",
       "          )\n",
       "        )\n",
       "        (input_layernorm): RMSNorm(hidden_size=4096, eps=1e-05)\n",
       "        (post_attention_layernorm): RMSNorm(hidden_size=4096, eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): RMSNorm(hidden_size=4096, eps=1e-05)\n",
       "  )\n",
       "  (lm_head): ParallelLMHead(num_embeddings=16000, embedding_dim=4096, org_vocab_size=32000, num_embeddings_padded=32000, tp_size=2)\n",
       "  (logits_processor): LogitsProcessor(vocab_size=32000, forg_vocab_size=32000, scale=1.0, logits_as_input=False)\n",
       "  (sampler): Sampler()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eedi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
